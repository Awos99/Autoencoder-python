{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1_t4V9bnt-hB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f42f4bbff55b6ed8f147fa5ebeaea4e",
     "grade": false,
     "grade_id": "cell-e911fa75d4ae6ea9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Autoencoder implementation\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The dataset consists of data about 1000 customers, encompassing 84 features extracted from their financial transactions and current financial status. The main aim is to utilize this dataset for credit risk assessment and forecasting potential defaults.\n",
    "\n",
    "Included within are two target variables, one designed for classification and the other for regression analysis:\n",
    "\n",
    "- **DEFAULT**: Binary target variable indicating if the customer has defaulted (1) or not (0)\n",
    "- **CREDIT_SCORE**: Numerical target variable representing the customer's credit score (integer)\n",
    "\n",
    "and these features:\n",
    "\n",
    "- **INCOME**: Total income in the last 12 months\n",
    "- **SAVINGS**: Total savings in the last 12 months\n",
    "- **DEBT**: Total existing debt\n",
    "- **R_SAVINGS_INCOME**: Ratio of savings to income\n",
    "- **R_DEBT_INCOME**: Ratio of debt to income\n",
    "- **R_DEBT_SAVINGS**: Ratio of debt to savings\n",
    "\n",
    "Transaction groups (**GROCERIES**, **CLOTHING**, **HOUSING**, **EDUCATION**, **HEALTH**, **TRAVEL**, **ENTERTAINMENT**, **GAMBLING**, **UTILITIES**, **TAX**, **FINES**) are categorized.\n",
    "\n",
    "- **T_{GROUP}_6**: Total expenditure in that group in the last 6 months\n",
    "- **T_GROUP_12**: Total expenditure in that group in the last 12 months\n",
    "- **R_[GROUP]**: Ratio of T_[GROUP]6 to T[GROUP]_12\n",
    "- **R_[GROUP]INCOME**: Ratio of T[GROUP]_12 to INCOME\n",
    "- **R_[GROUP]SAVINGS**: Ratio of T[GROUP]_12 to SAVINGS\n",
    "- **R_[GROUP]DEBT**: Ratio of T[GROUP]_12 to DEBT\n",
    "\n",
    "Categorical Features:\n",
    "\n",
    "- **CAT_GAMBLING**: Gambling category (none, low, high)\n",
    "- **CAT_DEBT**: 1 if the customer has debt; 0 otherwise\n",
    "- **CAT_CREDIT_CARD**: 1 if the customer has a credit card; 0 otherwise\n",
    "- **CAT_MORTGAGE**: 1 if the customer has a mortgage; 0 otherwise\n",
    "- **CAT_SAVINGS_ACCOUNT**: 1 if the customer has a savings account; 0 otherwise\n",
    "- **CAT_DEPENDENTS**: 1 if the customer has any dependents; 0 otherwise\n",
    "- **CAT_LOCATION**: Location (San Francisco, Philadelphia, Los Angeles, etc.)\n",
    "- **CAT_MARITAL_STATUS**: Marital status (Married, Widowed, Divorced or Single)\n",
    "- **CAT_EDUCATION**: Level of Education (Postgraduate, College, High School or Graduate)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7871551e55faf200ca6bfe8177b9d4b1",
     "grade": false,
     "grade_id": "cell-0d9a7d4e70c072c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JdETeU66gS1E",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74e0c5a58148f881bca835027488e33f",
     "grade": false,
     "grade_id": "cell-8f995c9cdf882820",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Loading Data</b>\n",
    "\n",
    "We load the data in a DataFrame called ```df```.\n",
    "    \n",
    "Then, we create the feature matrix ```X``` and the target array ```y``` (```DEFAULT```), then we split them into separate training and test sets with a relative size of 0.75 and 0.25.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3416f03882927817c5373de161fb4a59",
     "grade": false,
     "grade_id": "ex1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv(\"data.csv\")\n",
    "df.drop(columns=[\"CUST_ID\"],inplace=True)\n",
    "y=df[\"DEFAULT\"]\n",
    "X=df.drop(columns=[\"DEFAULT\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0afa9b188450a92f7d4005d0a9c8ee17",
     "grade": false,
     "grade_id": "cell-d86a46bf35ed7c3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Pipeline for Model</b>\n",
    "\n",
    "We construct a two-branched `Pipeline` – one branch for categorical attributes and another for numerical attributes. For categorical variables, we employ a `SimpleImputer` with the most frequent strategy and an `OneHotEncoder`. For numerical attributes, we use a `SimpleImputer` with the mean and a `StandardScaler`. The pipeline concludes with the training of an `MLPClassifier`, with the early_stopping criteria set to `True`, and the training restricted to a maximum of 250 iterations.\n",
    "\n",
    "We will use this model results to test the autoencoder.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e312a6da82f8c4bc37df98d9182e9662",
     "grade": false,
     "grade_id": "ex2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_ED...\n",
       "       &#x27;CAT_DEPENDENTS&#x27;, &#x27;CREDIT_SCORE&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MLPClassifier(early_stopping=True, max_iter=250))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_ED...\n",
       "       &#x27;CAT_DEPENDENTS&#x27;, &#x27;CREDIT_SCORE&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MLPClassifier(early_stopping=True, max_iter=250))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_EDUCATION_12&#x27;, &#x27;T_EDUCATION_6&#x27;, &#x27;R_E...\n",
       "       &#x27;R_EXPENDITURE_SAVINGS&#x27;, &#x27;R_EXPENDITURE_DEBT&#x27;, &#x27;CAT_DEBT&#x27;,\n",
       "       &#x27;CAT_CREDIT_CARD&#x27;, &#x27;CAT_MORTGAGE&#x27;, &#x27;CAT_SAVINGS_ACCOUNT&#x27;,\n",
       "       &#x27;CAT_DEPENDENTS&#x27;, &#x27;CREDIT_SCORE&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_EDUCATION_12&#x27;, &#x27;T_EDUCATION_6&#x27;, &#x27;R_EDUCATION&#x27;,\n",
       "       &#x27;R_EDUCATION_INCOME&#x27;, &#x27;R_EDUCATION_SAVINGS&#x27;, &#x27;R_EDUCATION_DEBT&#x27;,\n",
       "       &#x27;T_ENTERTAINMENT_12&#x27;, &#x27;T_ENTERTAINMENT_6&#x27;, &#x27;R_ENTERTAINMENT&#x27;,\n",
       "       &#x27;R_ENTERTAINMENT_INCOME&#x27;, &#x27;R_ENTERTAINMENT_SAVINGS&#x27;,\n",
       "       &#x27;R_ENTERTAINMENT_DEBT&#x27;, &#x27;T_FINES_12&#x27;, &#x27;T_FINES_6&#x27;, &#x27;R_FINES&#x27;,\n",
       "       &#x27;R_FINES_INCOME&#x27;, &#x27;R_FINES_SAVINGS&#x27;, &#x27;R_FINES_DEBT&#x27;, &#x27;T_GAMBLING_12&#x27;,\n",
       "       &#x27;T_GAMBLING_6&#x27;, &#x27;R_GAMBLING&#x27;, &#x27;R_GAMBLING_INCOME&#x27;, &#x27;R_GAMBLING_SAVINGS&#x27;,\n",
       "       &#x27;R_GAMBLING_DEBT&#x27;, &#x27;T_GROCERIES_12&#x27;, &#x27;T_GROCERIES_6&#x27;, &#x27;R_GROCERIES&#x27;,\n",
       "       &#x27;R_GROCERIES_INCOME&#x27;, &#x27;R_GROCERIES_SAVINGS&#x27;, &#x27;R_GROCERIES_DEBT&#x27;,\n",
       "       &#x27;T_HEALTH_12&#x27;, &#x27;T_HEALTH_6&#x27;, &#x27;R_HEALTH&#x27;, &#x27;R_HEALTH_INCOME&#x27;,\n",
       "       &#x27;R_HEALTH_SAVINGS&#x27;, &#x27;R_HEALTH_DEBT&#x27;, &#x27;T_HOUSING_12&#x27;, &#x27;T_HOUSING_6&#x27;,\n",
       "       &#x27;R_HOUSING&#x27;, &#x27;R_HOUSING_INCOME&#x27;, &#x27;R_HOUSING_SAVINGS&#x27;, &#x27;R_HOUSING_DEBT&#x27;,\n",
       "       &#x27;T_TAX_12&#x27;, &#x27;T_TAX_6&#x27;, &#x27;R_TAX&#x27;, &#x27;R_TAX_INCOME&#x27;, &#x27;R_TAX_SAVINGS&#x27;,\n",
       "       &#x27;R_TAX_DEBT&#x27;, &#x27;T_TRAVEL_12&#x27;, &#x27;T_TRAVEL_6&#x27;, &#x27;R_TRAVEL&#x27;,\n",
       "       &#x27;R_TRAVEL_INCOME&#x27;, &#x27;R_TRAVEL_SAVINGS&#x27;, &#x27;R_TRAVEL_DEBT&#x27;,\n",
       "       &#x27;T_UTILITIES_12&#x27;, &#x27;T_UTILITIES_6&#x27;, &#x27;R_UTILITIES&#x27;, &#x27;R_UTILITIES_INCOME&#x27;,\n",
       "       &#x27;R_UTILITIES_SAVINGS&#x27;, &#x27;R_UTILITIES_DEBT&#x27;, &#x27;T_EXPENDITURE_12&#x27;,\n",
       "       &#x27;T_EXPENDITURE_6&#x27;, &#x27;R_EXPENDITURE&#x27;, &#x27;R_EXPENDITURE_INCOME&#x27;,\n",
       "       &#x27;R_EXPENDITURE_SAVINGS&#x27;, &#x27;R_EXPENDITURE_DEBT&#x27;, &#x27;CAT_DEBT&#x27;,\n",
       "       &#x27;CAT_CREDIT_CARD&#x27;, &#x27;CAT_MORTGAGE&#x27;, &#x27;CAT_SAVINGS_ACCOUNT&#x27;,\n",
       "       &#x27;CAT_DEPENDENTS&#x27;, &#x27;CREDIT_SCORE&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, max_iter=250)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['Unnamed: 0', 'INCOME', 'SAVINGS', 'DEBT', 'R_SAVINGS_INCOME',\n",
       "       'R_DEBT_INCOME', 'R_DEBT_SAVINGS', 'T_CLOTHING_12', 'T_CLOTHING_6',\n",
       "       'R_CLOTHING', 'R_CLOTHING_INCOME', 'R_CLOTHING_SAVINGS',\n",
       "       'R_CLOTHING_DEBT', 'T_ED...\n",
       "       'CAT_DEPENDENTS', 'CREDIT_SCORE'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index(['CAT_GAMBLING', 'CAT_LOCATION', 'CAT_MARITAL_STATUS', 'CAT_EDUCATION'], dtype='object'))])),\n",
       "                ('classifier',\n",
       "                 MLPClassifier(early_stopping=True, max_iter=250))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "pipe_steps=[('preprocessor', preprocessor), ('classifier', MLPClassifier(max_iter=250, early_stopping=True))]\n",
    "\n",
    "pipe = Pipeline(steps=pipe_steps)\n",
    "pipe.fit(X_train, y_train) # Not needed as we do a grid search later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c15a9200070c5921862f1c371b5d2aed",
     "grade": false,
     "grade_id": "cell-f9006c08477ea833",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Grid Search</b>\n",
    "    \n",
    "We try to enhance the predictive capability of the previous neural networkthrough a GridSearchCV.\n",
    "\n",
    "Finally, we store the score (accuracy) achieved by the best hyperparameter combination in a variable called ```training_score```.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69b315830f2239f6d81c0964227610ff",
     "grade": false,
     "grade_id": "ex3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025848592685334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'classifier__hidden_layer_sizes': [(100,), (50, 50), (25, 25, 25)], # very different structures to be tested\n",
    "    'classifier__activation': ['relu', 'tanh', 'logistic'], # each activation function aloows for different ranges of output\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01] # this is a regularization term that could lead to simpler models\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=3, scoring='roc_auc')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "training_score = grid.best_score_\n",
    "training_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcb1fc4b8ef85895a1f429ced889e0de",
     "grade": false,
     "grade_id": "cell-20e9cb05aa0911f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Generalization Score</b>\n",
    "    \n",
    "We compute the generalization score of the previous grid search, to assess whether the model is exhibiting signs of overfitting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00ef2091bcd0c6ccc4ed66e901f1fff9",
     "grade": false,
     "grade_id": "ex4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658338812184966 0.7396096937167351\n"
     ]
    }
   ],
   "source": [
    "score = grid.score(X_test, y_test)\n",
    "print(score, grid.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results which don't show big signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "965ab2d4a5360befd7119288fa634f86",
     "grade": false,
     "grade_id": "cell-c04afc7d0628c615",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Autoencoder Implementation</b>\n",
    "\n",
    "We construct a stacked denoising autoencoder using Keras with a scikit-learn wrapper. The objective of the autoencoder is to compress the feature matrix into three dimensions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amosw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The method chosen allows to input the autoencoder in a pipeline and do a grid search\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, epochs=100, batch_size=5, verbose=0, structure=[[70, 'relu'], [30, 'relu'], [3, 'sigmoid']], learning_rate=0.001, loss='mse'):\n",
    "        # Initializing values that will set the hyperparameters later on\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "        self.encoder = None\n",
    "        self.structure = structure\n",
    "        self.learning_rate=learning_rate\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)  # Set learning rate here\n",
    "        self.loss = loss\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        #This function creates the internal structure of the encoder, we chose to keep it symmetrical for ease of use\n",
    "        input_img = Input(shape=(X.shape[1],))\n",
    "        i=0\n",
    "        for combination in self.structure:\n",
    "            if i==0:\n",
    "                encoded = Dense(combination[0], activation=combination[1])(input_img)\n",
    "            else:\n",
    "                encoded = Dense(combination[0], activation=combination[1])(encoded)\n",
    "            i=1\n",
    "        \n",
    "        i=0\n",
    "        for combination in reversed(self.structure[:-1]):\n",
    "            if i==0:\n",
    "                decoded=Dense(combination[0], activation=combination[1])(encoded)\n",
    "            else:\n",
    "                decoded=Dense(combination[0], activation=combination[1])(decoded)\n",
    "            i=1\n",
    "        \n",
    "        decoded = Dense(X.shape[1])(decoded)  # Linear output\n",
    "\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True) # Set early stopping to reduce the length of training and overfitting\n",
    "        self.model = Model(input_img, decoded)\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "        self.history = self.model.fit(X, X, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose, validation_split=0.1, callbacks=[early_stopping]) # the validation split allows for early stopping but reduces also the training data\n",
    "\n",
    "        # this model maps an input to its encoded representation\n",
    "        self.encoder = Model(input_img, encoded)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # returns the embeddings\n",
    "        return self.encoder.predict(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # This function will be used with the scoring of a grid search\n",
    "        return self.model.predict(X), X # We are returning the prediction and X transformed as it is needed in the scoring method later on\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33dc5fd4c6ec0c5bb34286fe212ab190",
     "grade": false,
     "grade_id": "cell-22575100e6c65ef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Creating the Pipeline for the Autoencoder</b>\n",
    "\n",
    "We construct a pipeline for preparing the feature matrix to be used with the previous autoencoder.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class GaussianNoiseTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Adds noise to the data\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        noise = np.random.normal(self.mean, self.std, X.shape)\n",
    "        return X + 0.0001*noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e26176a4def8e2d9192753daad16c30e",
     "grade": true,
     "grade_id": "ex6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "pipe_steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('add_noise', GaussianNoiseTransformer()),\n",
    "    ('autoencoder', AutoencoderTransformer())\n",
    "]\n",
    "pipeline = Pipeline(pipe_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[200, 'elu'], [8, 'softplus'], [3, None]], [[200, None], [80, None], [60, None], [20, None], [8, None], [3, 'elu']], [[500, 'elu'], [200, 'elu'], [80, None], [60, 'elu'], [40, 'softplus'], [20, 'softplus'], [8, None], [3, 'softplus']], [[200, 'elu'], [80, 'softplus'], [60, 'elu'], [40, None], [20, None], [8, None], [3, 'softplus']], [[500, None], [200, 'elu'], [80, 'elu'], [60, None], [40, None], [8, 'softplus'], [3, None]], [[200, None], [8, None], [3, 'elu']], [[500, None], [200, None], [80, 'elu'], [60, 'elu'], [40, None], [8, 'softplus'], [3, None]], [[500, 'softplus'], [200, None], [80, 'softplus'], [40, 'elu'], [20, None], [8, 'elu'], [3, 'softplus']], [[500, 'elu'], [80, 'elu'], [3, None]], [[80, None], [8, 'elu'], [3, 'softplus']]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Optional - we create a function that creates possible combinations of architecture for the autoencoder\n",
    "def generate_combinations(neurons, activations=['relu', 'softplus', None], n_combinations=10, min_hidden=4):\n",
    "    # set seed\n",
    "    random.seed(123)\n",
    "    # function to create random combination of structures\n",
    "    neurons=list(set(neurons))\n",
    "    structure=[]\n",
    "    for i in range(n_combinations):\n",
    "        neurons_i=neurons.copy()\n",
    "        encoding_dim=min(neurons_i) # the encoding dimension will always be the smallest value inputted\n",
    "        neurons_i.remove(encoding_dim)\n",
    "        k=random.randint(min_hidden, len(neurons_i))\n",
    "        \n",
    "        random_sample = random.sample(neurons_i, k=k) # gettind a random number of hidden layers and random sample of neurons per layer\n",
    "        \n",
    "        random_sample.sort(reverse=True)\n",
    "        structure.append(random_sample)\n",
    "    \n",
    "    combinations=[]\n",
    "    for structure_i in structure:\n",
    "        combination=[]\n",
    "        for value in structure_i:\n",
    "            activation=random.sample(activations, k=1)[0]\n",
    "            combination.append([value, activation])\n",
    "        activation=random.sample(activations, k=1)[0]\n",
    "        combination.append([encoding_dim, activation]) # creating combination of layer and activation function\n",
    "        combinations.append(combination)\n",
    "\n",
    "    combinations = [list(map(list, item)) for item in set(tuple(map(tuple, item)) for item in combinations)]  \n",
    "\n",
    "    return combinations\n",
    "\n",
    "neurons = [500, 200, 80, 60, 40, 20, 8, 3]\n",
    "combinations = generate_combinations(neurons, n_combinations=10, min_hidden=2, activations=['softplus', 'elu', None]) # based on trials a more gradual approach ensures a better result\n",
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'autoencoder__epochs': [250], # max epochs\n",
    "    'autoencoder__structure': combinations,\n",
    "    'autoencoder__learning_rate':[0.001, 0.01], # testing different learning rates\n",
    "    'autoencoder__verbose':[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amosw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "WARNING:tensorflow:From C:\\Users\\amosw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "90/90 [==============================] - 3s 8ms/step - loss: 0.8944 - val_loss: 0.7248\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7782 - val_loss: 0.6674\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.6283\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6824 - val_loss: 0.6090\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6587 - val_loss: 0.6066\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6419 - val_loss: 0.5930\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6332 - val_loss: 0.5892\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6245 - val_loss: 0.5772\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5816\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6086 - val_loss: 0.5818\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.5741\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6007 - val_loss: 0.5670\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5976 - val_loss: 0.5766\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5929 - val_loss: 0.5716\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5880 - val_loss: 0.5733\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 0.5985\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5930 - val_loss: 0.5663\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5775 - val_loss: 0.5713\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5734 - val_loss: 0.5531\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5710 - val_loss: 0.5632\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5642 - val_loss: 0.5553\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5593 - val_loss: 0.5555\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5590 - val_loss: 0.5538\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5555 - val_loss: 0.5546\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5512 - val_loss: 0.5581\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5471 - val_loss: 0.5541\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5436 - val_loss: 0.5456\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5428 - val_loss: 0.5434\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5371 - val_loss: 0.5521\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5381 - val_loss: 0.5438\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5320 - val_loss: 0.5594\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5365 - val_loss: 0.5460\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5281 - val_loss: 0.5534\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5232 - val_loss: 0.5323\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5210 - val_loss: 0.5458\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5154 - val_loss: 0.5369\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5157 - val_loss: 0.5426\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5138 - val_loss: 0.5469\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5125 - val_loss: 0.5444\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5114 - val_loss: 0.5367\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5075 - val_loss: 0.5363\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5058 - val_loss: 0.5413\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5062 - val_loss: 0.5456\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5038 - val_loss: 0.5446\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4974 - val_loss: 0.5387\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4948 - val_loss: 0.5367\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4911 - val_loss: 0.5448\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4918 - val_loss: 0.5341\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4935 - val_loss: 0.5496\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4886 - val_loss: 0.5382\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4882 - val_loss: 0.5398\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4905 - val_loss: 0.5233\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4933 - val_loss: 0.5338\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4829 - val_loss: 0.5332\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4806 - val_loss: 0.5404\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4835 - val_loss: 0.5290\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4798 - val_loss: 0.5432\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4752 - val_loss: 0.5364\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4767 - val_loss: 0.5380\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4743 - val_loss: 0.5307\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4742 - val_loss: 0.5374\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4721 - val_loss: 0.5286\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4684 - val_loss: 0.5338\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4636 - val_loss: 0.5350\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4605 - val_loss: 0.5394\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4680 - val_loss: 0.5286\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4645 - val_loss: 0.5332\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4587 - val_loss: 0.5260\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4582 - val_loss: 0.5378\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4584 - val_loss: 0.5329\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4578 - val_loss: 0.5352\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4620 - val_loss: 0.5406\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9039 - val_loss: 0.7311\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7709 - val_loss: 0.6816\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7159 - val_loss: 0.6383\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6803 - val_loss: 0.6047\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6515 - val_loss: 0.6026\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6374 - val_loss: 0.6095\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 0.5990\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6233 - val_loss: 0.5966\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.5921\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6131 - val_loss: 0.5939\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.5982\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6034 - val_loss: 0.6007\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6026 - val_loss: 0.5889\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 0.5949\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5929 - val_loss: 0.5864\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.5921\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 0.5846\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5775 - val_loss: 0.5886\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5722 - val_loss: 0.5818\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5721 - val_loss: 0.5889\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5669 - val_loss: 0.5760\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5641 - val_loss: 0.5930\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5613 - val_loss: 0.5850\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5602 - val_loss: 0.5868\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5551 - val_loss: 0.5851\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5532 - val_loss: 0.5795\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.5900\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5473 - val_loss: 0.5685\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5416 - val_loss: 0.5747\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5395 - val_loss: 0.5703\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5334 - val_loss: 0.5773\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5311 - val_loss: 0.5727\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5285 - val_loss: 0.5734\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5266 - val_loss: 0.5660\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5218 - val_loss: 0.5681\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5195 - val_loss: 0.5638\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5210 - val_loss: 0.5679\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5190 - val_loss: 0.5753\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5158 - val_loss: 0.5588\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5129 - val_loss: 0.5713\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5037 - val_loss: 0.5709\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5028 - val_loss: 0.5592\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4988 - val_loss: 0.5503\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4994 - val_loss: 0.5630\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4950 - val_loss: 0.5528\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4946 - val_loss: 0.5553\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4939 - val_loss: 0.5565\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4986 - val_loss: 0.5527\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4893 - val_loss: 0.5558\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4873 - val_loss: 0.5507\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4821 - val_loss: 0.5535\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4783 - val_loss: 0.5385\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4770 - val_loss: 0.5609\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4792 - val_loss: 0.5543\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4772 - val_loss: 0.5487\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4764 - val_loss: 0.5463\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4725 - val_loss: 0.5498\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4720 - val_loss: 0.5492\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4710 - val_loss: 0.5775\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4681 - val_loss: 0.5479\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4698 - val_loss: 0.5492\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4660 - val_loss: 0.5630\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4665 - val_loss: 0.5508\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4610 - val_loss: 0.5391\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4600 - val_loss: 0.5614\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4610 - val_loss: 0.5463\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4579 - val_loss: 0.5878\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4763 - val_loss: 0.5449\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4605 - val_loss: 0.5536\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4563 - val_loss: 0.5407\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4559 - val_loss: 0.5506\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4531 - val_loss: 0.5598\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9001 - val_loss: 0.7732\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7980 - val_loss: 0.7295\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7246 - val_loss: 0.7098\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6975 - val_loss: 0.6996\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6726 - val_loss: 0.6847\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6590 - val_loss: 0.6764\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6436 - val_loss: 0.6692\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6294 - val_loss: 0.6538\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 0.6474\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6116 - val_loss: 0.6417\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6357\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.6257\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5927 - val_loss: 0.6262\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5878 - val_loss: 0.6289\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 0.6257\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5807 - val_loss: 0.6198\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5743 - val_loss: 0.6129\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5694 - val_loss: 0.6198\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5673 - val_loss: 0.6279\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5635 - val_loss: 0.6166\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5616 - val_loss: 0.6111\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5577 - val_loss: 0.6102\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5521 - val_loss: 0.6089\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5489 - val_loss: 0.6119\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5461 - val_loss: 0.6095\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5429 - val_loss: 0.6050\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5411 - val_loss: 0.6147\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5373 - val_loss: 0.6102\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5375 - val_loss: 0.6083\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5366 - val_loss: 0.6141\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5360 - val_loss: 0.6063\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5256 - val_loss: 0.6061\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 0.6078\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5185 - val_loss: 0.6076\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5138 - val_loss: 0.6061\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5125 - val_loss: 0.6036\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5105 - val_loss: 0.6013\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5077 - val_loss: 0.6044\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5027 - val_loss: 0.6042\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5018 - val_loss: 0.6000\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4978 - val_loss: 0.5939\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4969 - val_loss: 0.6021\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4962 - val_loss: 0.6007\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4929 - val_loss: 0.5997\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4927 - val_loss: 0.5996\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4884 - val_loss: 0.5961\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4857 - val_loss: 0.5923\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4819 - val_loss: 0.5951\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4821 - val_loss: 0.5966\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4838 - val_loss: 0.6004\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4799 - val_loss: 0.5902\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4749 - val_loss: 0.6076\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4815 - val_loss: 0.5939\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4770 - val_loss: 0.5981\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4775 - val_loss: 0.5863\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4761 - val_loss: 0.5995\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4704 - val_loss: 0.5826\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4662 - val_loss: 0.5941\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4650 - val_loss: 0.5843\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4637 - val_loss: 0.5972\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4652 - val_loss: 0.5931\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4627 - val_loss: 0.5976\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4625 - val_loss: 0.5952\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4607 - val_loss: 0.5970\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4617 - val_loss: 0.5956\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4623 - val_loss: 0.6001\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4570 - val_loss: 0.5893\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4511 - val_loss: 0.5958\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4519 - val_loss: 0.5948\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4499 - val_loss: 0.5916\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4492 - val_loss: 0.5923\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4493 - val_loss: 0.5968\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4479 - val_loss: 0.5974\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4430 - val_loss: 0.5956\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4460 - val_loss: 0.5898\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4464 - val_loss: 0.5958\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4464 - val_loss: 0.5932\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 7ms/step - loss: 0.8719 - val_loss: 0.7190\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7900 - val_loss: 0.6963\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7642 - val_loss: 0.6785\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.6964\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7564 - val_loss: 0.6782\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7481 - val_loss: 0.6827\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7433 - val_loss: 0.6685\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7400 - val_loss: 0.6623\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7348 - val_loss: 0.6589\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7353 - val_loss: 0.6533\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7333 - val_loss: 0.6513\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7297 - val_loss: 0.6580\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7365 - val_loss: 0.6572\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7430 - val_loss: 0.6476\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7319 - val_loss: 0.6422\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7290 - val_loss: 0.6419\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7266 - val_loss: 0.6443\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7267 - val_loss: 0.6447\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7253 - val_loss: 0.6392\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7241 - val_loss: 0.6433\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7237 - val_loss: 0.6399\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7223 - val_loss: 0.6436\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7214 - val_loss: 0.6418\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7218 - val_loss: 0.6427\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7234 - val_loss: 0.6424\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7246 - val_loss: 0.6570\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7273 - val_loss: 0.6441\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7286 - val_loss: 0.6854\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7368 - val_loss: 0.6470\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7298 - val_loss: 0.6739\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7271 - val_loss: 0.6417\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7198 - val_loss: 0.6406\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7196 - val_loss: 0.6385\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7187 - val_loss: 0.6438\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7184 - val_loss: 0.6412\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7196 - val_loss: 0.6442\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7194 - val_loss: 0.6405\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7216 - val_loss: 0.6401\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7209 - val_loss: 0.6451\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7217 - val_loss: 0.6626\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7228 - val_loss: 0.6457\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7225 - val_loss: 0.6435\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7197 - val_loss: 0.6390\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7177 - val_loss: 0.6392\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7186 - val_loss: 0.6392\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7174 - val_loss: 0.6393\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7184 - val_loss: 0.6414\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7217 - val_loss: 0.6397\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7244 - val_loss: 0.6483\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.6474\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7214 - val_loss: 0.6429\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7192 - val_loss: 0.6448\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7203 - val_loss: 0.6414\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 7ms/step - loss: 0.9124 - val_loss: 0.7691\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8069 - val_loss: 0.7265\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7696 - val_loss: 0.6985\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7683 - val_loss: 0.7146\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7537 - val_loss: 0.6891\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7429 - val_loss: 0.6866\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7405 - val_loss: 0.6832\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7398 - val_loss: 0.6928\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7423 - val_loss: 0.6866\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7367 - val_loss: 0.6861\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7316 - val_loss: 0.6870\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7431 - val_loss: 0.6827\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7337 - val_loss: 0.6870\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7310 - val_loss: 0.6756\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7307 - val_loss: 0.6759\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7268 - val_loss: 0.6724\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7274 - val_loss: 0.6742\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7303 - val_loss: 0.6787\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7316 - val_loss: 0.6760\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7347 - val_loss: 0.6836\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7347 - val_loss: 0.6724\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7263 - val_loss: 0.6732\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7274 - val_loss: 0.6751\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7274 - val_loss: 0.6780\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7287 - val_loss: 0.6862\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7304 - val_loss: 0.6811\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7292 - val_loss: 0.6773\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7239 - val_loss: 0.6742\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7237 - val_loss: 0.6729\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7322 - val_loss: 0.6832\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7290 - val_loss: 0.6772\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7390 - val_loss: 0.6830\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7306 - val_loss: 0.6773\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7284 - val_loss: 0.6773\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7252 - val_loss: 0.6741\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7275 - val_loss: 0.6749\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7248 - val_loss: 0.6731\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 0.6733\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 0.6728\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7213 - val_loss: 0.6734\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7214 - val_loss: 0.6724\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 7ms/step - loss: 0.9277 - val_loss: 0.7886\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7949 - val_loss: 0.7682\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8022 - val_loss: 0.7474\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7807 - val_loss: 0.7392\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7685 - val_loss: 0.7328\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.7282\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7504 - val_loss: 0.7318\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7456 - val_loss: 0.7254\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7541 - val_loss: 0.7338\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7424 - val_loss: 0.7376\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7520 - val_loss: 0.7364\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7673 - val_loss: 0.7510\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7457 - val_loss: 0.7362\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7987 - val_loss: 0.7422\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7647 - val_loss: 0.7347\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7440 - val_loss: 0.7442\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7389 - val_loss: 0.7281\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7291 - val_loss: 0.7263\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7263 - val_loss: 0.7242\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7412 - val_loss: 0.7365\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7406 - val_loss: 0.7380\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7528 - val_loss: 0.7312\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7319 - val_loss: 0.7253\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7300 - val_loss: 0.7269\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7271 - val_loss: 0.7257\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7250 - val_loss: 0.7259\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7258 - val_loss: 0.7265\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7254 - val_loss: 0.7263\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7227 - val_loss: 0.7251\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7240 - val_loss: 0.7247\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7246 - val_loss: 0.7245\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7263 - val_loss: 0.7261\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7273 - val_loss: 0.7248\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7269 - val_loss: 0.7287\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7266 - val_loss: 0.7287\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7289 - val_loss: 0.7266\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7311 - val_loss: 0.7343\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7321 - val_loss: 0.7362\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7671 - val_loss: 0.7369\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 10ms/step - loss: 0.8929 - val_loss: 0.7713\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8031 - val_loss: 0.7160\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7486 - val_loss: 0.6920\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7204 - val_loss: 0.6686\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7014 - val_loss: 0.6560\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7011 - val_loss: 0.6479\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6973 - val_loss: 0.6730\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6839 - val_loss: 0.6312\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6551\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6702 - val_loss: 0.6580\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6860 - val_loss: 0.6910\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6413 - val_loss: 0.6223\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6349 - val_loss: 0.6103\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6385 - val_loss: 0.5894\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6227 - val_loss: 0.5969\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6053 - val_loss: 0.5901\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6111\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6166 - val_loss: 0.6094\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6127 - val_loss: 0.6479\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6279 - val_loss: 0.5821\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5795 - val_loss: 0.5885\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6054 - val_loss: 0.6203\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.5824\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.5809\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5665 - val_loss: 0.5756\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5591 - val_loss: 0.5884\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5691 - val_loss: 0.5806\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5961 - val_loss: 0.5906\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6026 - val_loss: 0.5996\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5988 - val_loss: 0.5764\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5667 - val_loss: 0.5706\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5653 - val_loss: 0.5956\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5486 - val_loss: 0.5707\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5467 - val_loss: 0.5775\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5448 - val_loss: 0.5682\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5408 - val_loss: 0.5582\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5421 - val_loss: 0.5627\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5342 - val_loss: 0.5557\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5363 - val_loss: 0.5582\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5478 - val_loss: 0.5709\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5378 - val_loss: 0.5619\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5475 - val_loss: 0.5641\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5436 - val_loss: 0.5585\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5302 - val_loss: 0.5713\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5210 - val_loss: 0.5486\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5138 - val_loss: 0.6002\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5248 - val_loss: 0.5549\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5266 - val_loss: 0.5553\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5392 - val_loss: 0.5670\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5346 - val_loss: 0.5634\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5437 - val_loss: 0.5495\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5212 - val_loss: 0.5753\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5183 - val_loss: 0.5514\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5055 - val_loss: 0.5560\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5364 - val_loss: 0.5678\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5348 - val_loss: 0.5919\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5192 - val_loss: 0.5419\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5187 - val_loss: 0.5430\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5066 - val_loss: 0.5312\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4996 - val_loss: 0.5818\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5256 - val_loss: 0.5775\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5707 - val_loss: 0.5644\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5625 - val_loss: 0.5596\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5301 - val_loss: 0.5595\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5334 - val_loss: 0.5918\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5313 - val_loss: 0.5627\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5230 - val_loss: 0.5602\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5278 - val_loss: 0.6052\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5800 - val_loss: 0.5915\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5627 - val_loss: 0.5614\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5265 - val_loss: 0.5918\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5318 - val_loss: 0.5860\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5179 - val_loss: 0.5640\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5113 - val_loss: 0.5507\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5086 - val_loss: 0.5391\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4904 - val_loss: 0.5449\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4877 - val_loss: 0.5617\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4831 - val_loss: 0.5400\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4862 - val_loss: 0.5738\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 9ms/step - loss: 0.9188 - val_loss: 0.8097\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8238 - val_loss: 0.7365\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7684 - val_loss: 0.7038\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7378 - val_loss: 0.6653\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7160 - val_loss: 0.6830\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7276 - val_loss: 0.6950\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7094 - val_loss: 0.6594\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6823 - val_loss: 0.6551\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6773 - val_loss: 0.6558\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6700 - val_loss: 0.6601\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6722 - val_loss: 0.6546\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.6614\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6363\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6784\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6906 - val_loss: 0.6392\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6708 - val_loss: 0.6236\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6298 - val_loss: 0.6093\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6155 - val_loss: 0.6104\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6378\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6020\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.6248\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6104 - val_loss: 0.6102\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6259\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.6310\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6140 - val_loss: 0.6234\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6325 - val_loss: 0.6004\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6105\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6318\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5914 - val_loss: 0.6267\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5941 - val_loss: 0.6079\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5965 - val_loss: 0.6228\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6065 - val_loss: 0.6122\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6005 - val_loss: 0.5989\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5810 - val_loss: 0.6052\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.6313\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.6229\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.5907\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5690 - val_loss: 0.5921\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5686 - val_loss: 0.5833\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.6187\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5714 - val_loss: 0.6035\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5579 - val_loss: 0.6085\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5620 - val_loss: 0.6003\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5527 - val_loss: 0.6001\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5492 - val_loss: 0.5772\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5399 - val_loss: 0.5799\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5479 - val_loss: 0.5992\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5602 - val_loss: 0.6261\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5629 - val_loss: 0.6030\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5525 - val_loss: 0.5669\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5344 - val_loss: 0.5623\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5417 - val_loss: 0.5662\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5364 - val_loss: 0.5760\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5495 - val_loss: 0.5673\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5436 - val_loss: 0.5622\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5405 - val_loss: 0.5586\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5262 - val_loss: 0.5694\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5254 - val_loss: 0.5525\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5181 - val_loss: 0.5715\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5261 - val_loss: 0.5673\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5238 - val_loss: 0.5640\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5334 - val_loss: 0.5496\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5296 - val_loss: 0.5563\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5332 - val_loss: 0.5569\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5530 - val_loss: 0.5987\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5945 - val_loss: 0.5965\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5342 - val_loss: 0.5592\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5164 - val_loss: 0.5504\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5152 - val_loss: 0.5679\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5128 - val_loss: 0.5651\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5371 - val_loss: 0.5699\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5091 - val_loss: 0.5459\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4996 - val_loss: 0.5570\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5004 - val_loss: 0.5520\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4936 - val_loss: 0.5439\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4899 - val_loss: 0.5428\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4946 - val_loss: 0.5309\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4960 - val_loss: 0.5590\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5427 - val_loss: 0.5378\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5297 - val_loss: 0.5445\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5224 - val_loss: 0.5774\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5116 - val_loss: 0.5569\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5119 - val_loss: 0.5780\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4989 - val_loss: 0.5350\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4931 - val_loss: 0.5484\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5054 - val_loss: 0.5646\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5270 - val_loss: 0.5892\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5090 - val_loss: 0.5748\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5127 - val_loss: 0.5449\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5160 - val_loss: 0.5308\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5069 - val_loss: 0.5408\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5131 - val_loss: 0.5484\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5244 - val_loss: 0.5309\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4946 - val_loss: 0.5461\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5130 - val_loss: 0.5248\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5163 - val_loss: 0.5244\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5030 - val_loss: 0.5195\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5018 - val_loss: 0.5151\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4898 - val_loss: 0.5233\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5176 - val_loss: 0.5382\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5032 - val_loss: 0.5192\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4883 - val_loss: 0.5365\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4904 - val_loss: 0.5267\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4813 - val_loss: 0.5312\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4837 - val_loss: 0.5180\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4715 - val_loss: 0.5509\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4689 - val_loss: 0.5406\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4683 - val_loss: 0.5141\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4654 - val_loss: 0.5446\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4741 - val_loss: 0.5544\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4725 - val_loss: 0.5344\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4897 - val_loss: 0.5440\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4884 - val_loss: 0.5616\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4807 - val_loss: 0.5259\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4849 - val_loss: 0.5441\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4780 - val_loss: 0.5753\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5054 - val_loss: 0.5774\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5645 - val_loss: 0.5790\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5269 - val_loss: 0.5647\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5075 - val_loss: 0.5812\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5440 - val_loss: 0.5453\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5001 - val_loss: 0.5396\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4729 - val_loss: 0.5492\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4748 - val_loss: 0.5428\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4766 - val_loss: 0.5535\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4612 - val_loss: 0.5457\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4537 - val_loss: 0.5468\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4431 - val_loss: 0.5307\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.8962 - val_loss: 0.7557\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7939 - val_loss: 0.7793\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7506 - val_loss: 0.7219\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7172 - val_loss: 0.6952\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7161 - val_loss: 0.7104\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7032 - val_loss: 0.6909\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6787 - val_loss: 0.6892\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6686 - val_loss: 0.6648\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6968 - val_loss: 0.6874\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6822 - val_loss: 0.6833\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6575 - val_loss: 0.6567\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6762 - val_loss: 0.7026\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6597 - val_loss: 0.6606\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6214 - val_loss: 0.6534\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6195 - val_loss: 0.6413\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6251 - val_loss: 0.6756\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6339 - val_loss: 0.6608\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6430\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.6400\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6012 - val_loss: 0.6493\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6089 - val_loss: 0.6420\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 0.6422\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6068 - val_loss: 0.6359\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5880 - val_loss: 0.6203\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6018 - val_loss: 0.6253\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5998 - val_loss: 0.6249\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5858 - val_loss: 0.6626\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6038 - val_loss: 0.6373\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5881 - val_loss: 0.6203\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5713 - val_loss: 0.6426\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5817 - val_loss: 0.6247\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5898 - val_loss: 0.6448\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5774 - val_loss: 0.6265\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5672 - val_loss: 0.6339\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6040 - val_loss: 0.6408\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5909 - val_loss: 0.6113\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5842 - val_loss: 0.6558\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5669 - val_loss: 0.6273\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5885 - val_loss: 0.6084\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5609 - val_loss: 0.6240\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5656 - val_loss: 0.6353\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5714 - val_loss: 0.6116\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5700 - val_loss: 0.6218\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5976 - val_loss: 0.6345\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5750 - val_loss: 0.6524\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6067 - val_loss: 0.6293\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6031 - val_loss: 0.6276\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5996 - val_loss: 0.6182\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5871 - val_loss: 0.6342\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5475 - val_loss: 0.6134\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5380 - val_loss: 0.6114\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5406 - val_loss: 0.6042\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5360 - val_loss: 0.6117\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5381 - val_loss: 0.6003\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5389 - val_loss: 0.5973\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6020 - val_loss: 0.6396\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5901 - val_loss: 0.6201\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6019 - val_loss: 0.6561\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5895 - val_loss: 0.6284\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5626 - val_loss: 0.6412\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5522 - val_loss: 0.6212\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5460 - val_loss: 0.6033\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5540 - val_loss: 0.6188\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5365 - val_loss: 0.6186\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5371 - val_loss: 0.6032\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5390 - val_loss: 0.6130\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5521 - val_loss: 0.6250\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5269 - val_loss: 0.6088\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5408 - val_loss: 0.5906\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5293 - val_loss: 0.6039\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5333 - val_loss: 0.5906\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5223 - val_loss: 0.6143\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5593 - val_loss: 0.6163\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.5901\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5062 - val_loss: 0.5763\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5014 - val_loss: 0.5832\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5117 - val_loss: 0.6027\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5211 - val_loss: 0.6037\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5332 - val_loss: 0.5842\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5090 - val_loss: 0.6088\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5437 - val_loss: 0.6190\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.6198\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6079 - val_loss: 0.6225\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5825 - val_loss: 0.5972\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5378 - val_loss: 0.5991\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5291 - val_loss: 0.5800\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5262 - val_loss: 0.5754\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5232 - val_loss: 0.5998\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5235 - val_loss: 0.5788\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5145 - val_loss: 0.5910\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5481 - val_loss: 0.6083\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5058 - val_loss: 0.5900\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5112 - val_loss: 0.5871\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5086 - val_loss: 0.6020\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4940 - val_loss: 0.5712\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4838 - val_loss: 0.5810\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4832 - val_loss: 0.5709\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4819 - val_loss: 0.5788\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4950 - val_loss: 0.5862\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4879 - val_loss: 0.5717\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5187 - val_loss: 0.5803\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5099 - val_loss: 0.5926\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5437 - val_loss: 0.6226\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5108 - val_loss: 0.5842\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4896 - val_loss: 0.5642\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4855 - val_loss: 0.5857\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4837 - val_loss: 0.5631\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4963 - val_loss: 0.5851\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4867 - val_loss: 0.5898\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5214 - val_loss: 0.6254\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.5827\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5336 - val_loss: 0.5722\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5284 - val_loss: 0.6319\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5105 - val_loss: 0.5679\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4963 - val_loss: 0.5827\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4867 - val_loss: 0.5778\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4783 - val_loss: 0.5639\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4878 - val_loss: 0.5622\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4820 - val_loss: 0.5677\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5059 - val_loss: 0.5766\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5004 - val_loss: 0.5647\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4687 - val_loss: 0.5600\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4630 - val_loss: 0.5505\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4587 - val_loss: 0.5432\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4568 - val_loss: 0.5513\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4996 - val_loss: 0.5690\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5096 - val_loss: 0.5741\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4813 - val_loss: 0.5597\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4726 - val_loss: 0.5514\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4646 - val_loss: 0.5460\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4555 - val_loss: 0.5372\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4494 - val_loss: 0.5393\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4566 - val_loss: 0.5492\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4850 - val_loss: 0.5550\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4932 - val_loss: 0.5553\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4895 - val_loss: 0.5439\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4604 - val_loss: 0.5390\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4571 - val_loss: 0.5313\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4418 - val_loss: 0.5375\n",
      "Epoch 140/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4373 - val_loss: 0.5417\n",
      "Epoch 141/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4589 - val_loss: 0.5728\n",
      "Epoch 142/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4701 - val_loss: 0.5391\n",
      "Epoch 143/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4533 - val_loss: 0.5499\n",
      "Epoch 144/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4818 - val_loss: 0.6380\n",
      "Epoch 145/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4934 - val_loss: 0.5975\n",
      "Epoch 146/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5063 - val_loss: 0.5722\n",
      "Epoch 147/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4973 - val_loss: 0.5473\n",
      "Epoch 148/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4604 - val_loss: 0.5576\n",
      "Epoch 149/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4577 - val_loss: 0.5568\n",
      "Epoch 150/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4504 - val_loss: 0.5690\n",
      "Epoch 151/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4560 - val_loss: 0.5413\n",
      "Epoch 152/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4572 - val_loss: 0.5518\n",
      "Epoch 153/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4454 - val_loss: 0.5354\n",
      "Epoch 154/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.4383 - val_loss: 0.5425\n",
      "Epoch 155/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4391 - val_loss: 0.5485\n",
      "Epoch 156/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4350 - val_loss: 0.5459\n",
      "Epoch 157/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.4406 - val_loss: 0.5678\n",
      "Epoch 158/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.4485 - val_loss: 0.5566\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 7s 18ms/step - loss: 0.9383 - val_loss: 0.7567\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7931 - val_loss: 0.6999\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7318 - val_loss: 0.6637\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6923 - val_loss: 0.6766\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6597 - val_loss: 0.5923\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6448 - val_loss: 0.6099\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6616 - val_loss: 0.5872\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6229 - val_loss: 0.5903\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6273 - val_loss: 0.5810\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6076 - val_loss: 0.5969\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6019 - val_loss: 0.5906\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5862 - val_loss: 0.5731\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5871 - val_loss: 0.6121\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5867 - val_loss: 0.5633\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5716 - val_loss: 0.5672\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5617 - val_loss: 0.5653\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5479 - val_loss: 0.5514\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5389 - val_loss: 0.5355\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5340 - val_loss: 0.5360\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5393 - val_loss: 0.5518\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5377 - val_loss: 0.5453\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5302 - val_loss: 0.5292\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5318 - val_loss: 0.5449\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5143 - val_loss: 0.5265\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5167 - val_loss: 0.5293\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5234 - val_loss: 0.5392\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5060 - val_loss: 0.5523\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5187 - val_loss: 0.5739\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5018 - val_loss: 0.5457\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5031 - val_loss: 0.6221\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5731 - val_loss: 0.5749\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6111 - val_loss: 0.5559\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5499 - val_loss: 0.5544\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5159 - val_loss: 0.5334\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5284 - val_loss: 0.5396\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5199 - val_loss: 0.5399\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5071 - val_loss: 0.5284\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5034 - val_loss: 0.5311\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4873 - val_loss: 0.5423\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4959 - val_loss: 0.5299\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4940 - val_loss: 0.5362\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5558 - val_loss: 0.5530\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5258 - val_loss: 0.5217\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5097 - val_loss: 0.5220\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4739 - val_loss: 0.5435\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4699 - val_loss: 0.5211\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4630 - val_loss: 0.5175\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4748 - val_loss: 0.5267\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4569 - val_loss: 0.5195\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4548 - val_loss: 0.5205\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4472 - val_loss: 0.5196\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4494 - val_loss: 0.5186\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4517 - val_loss: 0.5324\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4756 - val_loss: 0.5272\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4684 - val_loss: 0.5790\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4959 - val_loss: 0.5304\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4859 - val_loss: 0.5423\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4852 - val_loss: 0.5491\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5009 - val_loss: 0.5584\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4918 - val_loss: 0.5351\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4685 - val_loss: 0.5580\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4494 - val_loss: 0.5402\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4405 - val_loss: 0.5294\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4323 - val_loss: 0.5420\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4283 - val_loss: 0.5210\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4257 - val_loss: 0.5232\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4272 - val_loss: 0.5265\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 6s 12ms/step - loss: 0.9170 - val_loss: 0.8009\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8017 - val_loss: 0.7414\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7613 - val_loss: 0.6953\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7193 - val_loss: 0.6726\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7195 - val_loss: 0.6698\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7009 - val_loss: 0.6678\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6951 - val_loss: 0.6550\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6795 - val_loss: 0.6609\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6617 - val_loss: 0.6476\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6544 - val_loss: 0.6497\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6581 - val_loss: 0.6722\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6365 - val_loss: 0.6415\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6150 - val_loss: 0.6167\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5990 - val_loss: 0.6288\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6070 - val_loss: 0.6300\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5949 - val_loss: 0.6340\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6204 - val_loss: 0.6597\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6362 - val_loss: 0.6314\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6057 - val_loss: 0.6132\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6063 - val_loss: 0.6387\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.6087\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5588 - val_loss: 0.5904\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5555 - val_loss: 0.5940\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5501 - val_loss: 0.5980\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5483 - val_loss: 0.5864\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5360 - val_loss: 0.6019\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5374 - val_loss: 0.5924\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5305 - val_loss: 0.5984\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5385 - val_loss: 0.5911\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5204 - val_loss: 0.5768\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5321 - val_loss: 0.5788\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5452 - val_loss: 0.6273\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5233 - val_loss: 0.5677\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5126 - val_loss: 0.5827\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5127 - val_loss: 0.5671\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5062 - val_loss: 0.5809\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5060 - val_loss: 0.5790\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5100 - val_loss: 0.5702\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5019 - val_loss: 0.5617\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5053 - val_loss: 0.5758\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4958 - val_loss: 0.5895\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4946 - val_loss: 0.6034\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5118 - val_loss: 0.5887\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5072 - val_loss: 0.5804\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4944 - val_loss: 0.6044\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5093 - val_loss: 0.5588\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4875 - val_loss: 0.5784\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4856 - val_loss: 0.5777\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4767 - val_loss: 0.5747\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4878 - val_loss: 0.5842\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4949 - val_loss: 0.5845\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5027 - val_loss: 0.6775\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4992 - val_loss: 0.5715\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4809 - val_loss: 0.5795\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4709 - val_loss: 0.5668\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4665 - val_loss: 0.5401\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4663 - val_loss: 0.5580\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4545 - val_loss: 0.5642\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4552 - val_loss: 0.5890\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4557 - val_loss: 0.5471\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4490 - val_loss: 0.5662\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4465 - val_loss: 0.5805\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4485 - val_loss: 0.5621\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4505 - val_loss: 0.5606\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4483 - val_loss: 0.5819\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4499 - val_loss: 0.5701\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4600 - val_loss: 0.5724\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4595 - val_loss: 0.5688\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4684 - val_loss: 0.5640\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4694 - val_loss: 0.5974\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4791 - val_loss: 0.6438\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5200 - val_loss: 0.6446\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5073 - val_loss: 0.5707\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4715 - val_loss: 0.5722\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4314 - val_loss: 0.5583\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4289 - val_loss: 0.5564\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 6s 11ms/step - loss: 0.9473 - val_loss: 0.8059\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8496 - val_loss: 0.7881\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8127 - val_loss: 0.7669\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7505 - val_loss: 0.7143\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7048 - val_loss: 0.7028\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6917 - val_loss: 0.7130\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6705 - val_loss: 0.6694\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6395 - val_loss: 0.6586\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6205 - val_loss: 0.6370\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6225 - val_loss: 0.6617\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6080 - val_loss: 0.6202\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5865 - val_loss: 0.6152\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6096 - val_loss: 0.6228\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5933 - val_loss: 0.6275\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.6344\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5863 - val_loss: 0.6161\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5807 - val_loss: 0.6073\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5691 - val_loss: 0.6054\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5704 - val_loss: 0.6099\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5577 - val_loss: 0.6010\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5530 - val_loss: 0.5991\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5532 - val_loss: 0.6500\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5637 - val_loss: 0.6398\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5800 - val_loss: 0.6181\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5646 - val_loss: 0.5986\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5441 - val_loss: 0.6114\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5432 - val_loss: 0.6238\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5533 - val_loss: 0.5963\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5293 - val_loss: 0.6044\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5503 - val_loss: 0.6254\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5425 - val_loss: 0.6156\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5177 - val_loss: 0.5861\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5310 - val_loss: 0.6060\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5383 - val_loss: 0.6186\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5324 - val_loss: 0.6033\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5204 - val_loss: 0.6150\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5235 - val_loss: 0.5972\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5064 - val_loss: 0.5869\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5085 - val_loss: 0.5979\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5154 - val_loss: 0.5962\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4985 - val_loss: 0.6005\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4845 - val_loss: 0.5822\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4795 - val_loss: 0.5831\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5047 - val_loss: 0.6134\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4880 - val_loss: 0.5685\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4859 - val_loss: 0.5826\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4888 - val_loss: 0.5850\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4687 - val_loss: 0.5782\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4672 - val_loss: 0.5779\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4885 - val_loss: 0.5863\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4587 - val_loss: 0.5688\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.4676 - val_loss: 0.5788\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4493 - val_loss: 0.5691\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4439 - val_loss: 0.5853\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4421 - val_loss: 0.5698\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4550 - val_loss: 0.5690\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4525 - val_loss: 0.6042\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4586 - val_loss: 0.5799\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4640 - val_loss: 0.6010\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4654 - val_loss: 0.5999\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4774 - val_loss: 0.5653\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5260 - val_loss: 0.5881\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4667 - val_loss: 0.5662\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4475 - val_loss: 0.5876\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4405 - val_loss: 0.5584\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4386 - val_loss: 0.5656\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4258 - val_loss: 0.5505\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4175 - val_loss: 0.5571\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4218 - val_loss: 0.5595\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4207 - val_loss: 0.5543\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4231 - val_loss: 0.5627\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4236 - val_loss: 0.5763\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4347 - val_loss: 0.5577\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4295 - val_loss: 0.5628\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4240 - val_loss: 0.5628\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4594 - val_loss: 0.5955\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4392 - val_loss: 0.5933\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4209 - val_loss: 0.5529\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4135 - val_loss: 0.5542\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4181 - val_loss: 0.5545\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4516 - val_loss: 0.6083\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4670 - val_loss: 0.5943\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4331 - val_loss: 0.5640\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4418 - val_loss: 0.5789\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4211 - val_loss: 0.5742\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4081 - val_loss: 0.5619\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3984 - val_loss: 0.5542\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 6s 13ms/step - loss: 0.8847 - val_loss: 0.6754\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7878 - val_loss: 0.6723\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7508 - val_loss: 0.6659\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7243 - val_loss: 0.6448\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6997 - val_loss: 0.6316\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6824 - val_loss: 0.6298\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6936 - val_loss: 0.6430\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6755 - val_loss: 0.6290\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6819 - val_loss: 0.6280\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6625 - val_loss: 0.6204\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6660 - val_loss: 0.6726\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7029 - val_loss: 0.6226\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6567 - val_loss: 0.6061\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6449 - val_loss: 0.6137\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6577 - val_loss: 0.6323\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6441 - val_loss: 0.6092\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.6413 - val_loss: 0.6039\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 0.6265 - val_loss: 0.5988\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6190 - val_loss: 0.6041\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6212 - val_loss: 0.5804\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6017 - val_loss: 0.5880\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6453 - val_loss: 0.6043\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6343 - val_loss: 0.5984\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6123 - val_loss: 0.5977\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6336 - val_loss: 0.5786\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.5970\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6177 - val_loss: 0.5914\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5875 - val_loss: 0.5792\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5978 - val_loss: 0.5713\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5853 - val_loss: 0.5465\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5569 - val_loss: 0.5751\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5743 - val_loss: 0.5601\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5733 - val_loss: 0.5607\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5896 - val_loss: 0.5636\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5674 - val_loss: 0.5828\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5744 - val_loss: 0.5662\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5716 - val_loss: 0.5699\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5620 - val_loss: 0.5526\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5631 - val_loss: 0.5975\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5642 - val_loss: 0.5669\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5477 - val_loss: 0.5631\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5504 - val_loss: 0.5725\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5667 - val_loss: 0.5519\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5703 - val_loss: 0.5782\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5761 - val_loss: 0.6440\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5989 - val_loss: 0.5616\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5608 - val_loss: 0.5759\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5614 - val_loss: 0.5486\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5370 - val_loss: 0.5782\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5457 - val_loss: 0.5804\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 0.8462 - val_loss: 0.7132\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7564 - val_loss: 0.6384\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7136 - val_loss: 0.6767\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7154 - val_loss: 0.6410\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6928 - val_loss: 0.6422\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6716 - val_loss: 0.6444\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6668 - val_loss: 0.6607\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6763 - val_loss: 0.6428\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6520 - val_loss: 0.6215\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6479 - val_loss: 0.6333\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6365 - val_loss: 0.6248\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6412 - val_loss: 0.6312\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6044 - val_loss: 0.6149\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6214 - val_loss: 0.6303\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6198 - val_loss: 0.6569\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.6678\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6336 - val_loss: 0.6100\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6088\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6090 - val_loss: 0.6217\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.6170\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5869 - val_loss: 0.6059\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6213 - val_loss: 0.6169\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6251 - val_loss: 0.6251\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6322 - val_loss: 0.6195\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5906 - val_loss: 0.6072\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5763 - val_loss: 0.6122\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5840 - val_loss: 0.5809\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5749 - val_loss: 0.5976\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5787 - val_loss: 0.5986\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5729 - val_loss: 0.6033\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5830 - val_loss: 0.6190\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5947 - val_loss: 0.5893\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5981 - val_loss: 0.5867\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5651 - val_loss: 0.5988\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5996 - val_loss: 0.6228\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.6138\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5753 - val_loss: 0.5882\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5720 - val_loss: 0.5966\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5811 - val_loss: 0.5832\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5754 - val_loss: 0.6003\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5637 - val_loss: 0.5958\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5754 - val_loss: 0.5917\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5725 - val_loss: 0.5812\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5503 - val_loss: 0.5825\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5482 - val_loss: 0.5684\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5427 - val_loss: 0.5730\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5493 - val_loss: 0.5974\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5548 - val_loss: 0.5942\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5565 - val_loss: 0.5977\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5418 - val_loss: 0.5740\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5373 - val_loss: 0.6007\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5361 - val_loss: 0.5787\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5244 - val_loss: 0.5714\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5304 - val_loss: 0.6025\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5545 - val_loss: 0.6159\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5364 - val_loss: 0.5912\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5299 - val_loss: 0.5860\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5122 - val_loss: 0.5594\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5160 - val_loss: 0.5732\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5118 - val_loss: 0.5627\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5100 - val_loss: 0.5960\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5377 - val_loss: 0.5796\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5259 - val_loss: 0.5962\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5423 - val_loss: 0.5794\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5337 - val_loss: 0.5581\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5178 - val_loss: 0.5611\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.5010 - val_loss: 0.5519\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5025 - val_loss: 0.5723\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5164 - val_loss: 0.5996\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5382 - val_loss: 0.6001\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5381 - val_loss: 0.5695\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5367 - val_loss: 0.5800\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5528 - val_loss: 0.5722\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5049 - val_loss: 0.5544\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4976 - val_loss: 0.5725\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4954 - val_loss: 0.5548\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5023 - val_loss: 0.5585\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5051 - val_loss: 0.5900\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4941 - val_loss: 0.5598\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4871 - val_loss: 0.5818\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5026 - val_loss: 0.5674\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5046 - val_loss: 0.5684\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5110 - val_loss: 0.5679\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4997 - val_loss: 0.5519\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4914 - val_loss: 0.5777\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4796 - val_loss: 0.5563\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4839 - val_loss: 0.5748\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4780 - val_loss: 0.5576\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4763 - val_loss: 0.5448\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4811 - val_loss: 0.5402\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4747 - val_loss: 0.5447\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4648 - val_loss: 0.5511\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4929 - val_loss: 0.5642\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4879 - val_loss: 0.5549\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4871 - val_loss: 0.5539\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4941 - val_loss: 0.5927\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5453 - val_loss: 0.6152\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5101 - val_loss: 0.5676\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4896 - val_loss: 0.5783\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4868 - val_loss: 0.5423\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4625 - val_loss: 0.5604\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4628 - val_loss: 0.5465\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4780 - val_loss: 0.5606\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4887 - val_loss: 0.5851\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4775 - val_loss: 0.5582\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4850 - val_loss: 0.5656\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4889 - val_loss: 0.5511\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4730 - val_loss: 0.5546\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4628 - val_loss: 0.5475\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4615 - val_loss: 0.5724\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 6s 10ms/step - loss: 0.8816 - val_loss: 0.7630\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7893 - val_loss: 0.7149\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7355 - val_loss: 0.7251\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7346 - val_loss: 0.7211\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7083 - val_loss: 0.6764\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6658 - val_loss: 0.6851\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6813 - val_loss: 0.6721\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6742 - val_loss: 0.6901\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6508\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6595 - val_loss: 0.6825\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6620\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6622 - val_loss: 0.6651\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6561 - val_loss: 0.6838\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6864 - val_loss: 0.7108\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6819 - val_loss: 0.6655\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6411 - val_loss: 0.6459\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6403 - val_loss: 0.6453\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6427 - val_loss: 0.6449\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6143 - val_loss: 0.6560\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6336 - val_loss: 0.6444\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6140 - val_loss: 0.6369\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6434\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6170 - val_loss: 0.6576\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.6636\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.6493\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6019 - val_loss: 0.6211\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6007 - val_loss: 0.6340\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6043 - val_loss: 0.6482\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6173 - val_loss: 0.6368\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5999 - val_loss: 0.6470\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6087 - val_loss: 0.6398\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6172 - val_loss: 0.6370\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6103 - val_loss: 0.6388\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6310 - val_loss: 0.6691\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6243 - val_loss: 0.6552\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6324 - val_loss: 0.6353\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6045 - val_loss: 0.6191\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5964 - val_loss: 0.6254\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6076 - val_loss: 0.6285\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5924 - val_loss: 0.6250\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.6184\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5994 - val_loss: 0.6288\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5708 - val_loss: 0.6233\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5574 - val_loss: 0.6131\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5841 - val_loss: 0.6283\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5828 - val_loss: 0.6072\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5567 - val_loss: 0.6159\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5831 - val_loss: 0.6176\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5869 - val_loss: 0.6508\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5863 - val_loss: 0.6412\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5771 - val_loss: 0.6070\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5559 - val_loss: 0.6476\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5737 - val_loss: 0.6321\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5723 - val_loss: 0.6403\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.6450\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5626 - val_loss: 0.6218\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5566 - val_loss: 0.6263\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5630 - val_loss: 0.6163\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5605 - val_loss: 0.6098\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5467 - val_loss: 0.6245\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5816 - val_loss: 0.6323\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5823 - val_loss: 0.6150\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5583 - val_loss: 0.5979\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5463 - val_loss: 0.6181\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5526 - val_loss: 0.6187\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5433 - val_loss: 0.6028\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5587 - val_loss: 0.6312\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5714 - val_loss: 0.7142\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6127 - val_loss: 0.6570\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.6215\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5699 - val_loss: 0.6249\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5683 - val_loss: 0.6392\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5749 - val_loss: 0.6110\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5651 - val_loss: 0.6540\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6183 - val_loss: 0.6141\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5689 - val_loss: 0.6065\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5594 - val_loss: 0.6229\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5472 - val_loss: 0.6092\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5327 - val_loss: 0.6038\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5387 - val_loss: 0.6099\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5310 - val_loss: 0.6161\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5309 - val_loss: 0.6183\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5135 - val_loss: 0.5912\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5131 - val_loss: 0.5947\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5209 - val_loss: 0.6047\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5096 - val_loss: 0.5906\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5372 - val_loss: 0.6088\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5324 - val_loss: 0.6070\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5122 - val_loss: 0.5937\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5343 - val_loss: 0.6121\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5165 - val_loss: 0.5919\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5082 - val_loss: 0.6079\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5101 - val_loss: 0.6145\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5095 - val_loss: 0.5814\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4997 - val_loss: 0.5910\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4919 - val_loss: 0.5928\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5142 - val_loss: 0.5987\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5244 - val_loss: 0.5782\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5176 - val_loss: 0.5886\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5097 - val_loss: 0.5820\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4999 - val_loss: 0.5968\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5014 - val_loss: 0.5951\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5122 - val_loss: 0.5950\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5171 - val_loss: 0.6058\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5138 - val_loss: 0.6092\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5099 - val_loss: 0.5852\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4839 - val_loss: 0.5882\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4916 - val_loss: 0.5857\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4897 - val_loss: 0.5807\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4870 - val_loss: 0.5898\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4943 - val_loss: 0.5942\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5028 - val_loss: 0.5817\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5061 - val_loss: 0.5875\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4887 - val_loss: 0.5959\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4775 - val_loss: 0.5957\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4950 - val_loss: 0.6150\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5001 - val_loss: 0.5939\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4996 - val_loss: 0.5915\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 5ms/step - loss: 0.9045 - val_loss: 0.7201\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8043 - val_loss: 0.7031\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7875 - val_loss: 0.6970\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7611 - val_loss: 0.6840\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7517 - val_loss: 0.6822\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7476 - val_loss: 0.6757\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7520 - val_loss: 0.6836\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7487 - val_loss: 0.6743\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7380 - val_loss: 0.6586\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7368 - val_loss: 0.6591\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7346 - val_loss: 0.6646\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7362 - val_loss: 0.6581\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7327 - val_loss: 0.6614\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7324 - val_loss: 0.6567\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7277 - val_loss: 0.6525\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7310 - val_loss: 0.6580\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7360 - val_loss: 0.6579\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7301 - val_loss: 0.6522\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7256 - val_loss: 0.6500\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7264 - val_loss: 0.6472\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7245 - val_loss: 0.6485\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7257 - val_loss: 0.6503\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7282 - val_loss: 0.6483\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7230 - val_loss: 0.6460\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7213 - val_loss: 0.6459\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7229 - val_loss: 0.6477\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7214 - val_loss: 0.6457\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7205 - val_loss: 0.6453\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.6432\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7237 - val_loss: 0.6487\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7263 - val_loss: 0.6474\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7213 - val_loss: 0.6483\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.6463\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7196 - val_loss: 0.6448\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7211 - val_loss: 0.6457\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7204 - val_loss: 0.6495\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7220 - val_loss: 0.6483\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7246 - val_loss: 0.6457\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 0.6436\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7185 - val_loss: 0.6419\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7180 - val_loss: 0.6399\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7176 - val_loss: 0.6412\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7193 - val_loss: 0.6459\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7206 - val_loss: 0.6426\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7191 - val_loss: 0.6408\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7178 - val_loss: 0.6422\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7179 - val_loss: 0.6432\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7180 - val_loss: 0.6460\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7209 - val_loss: 0.6491\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.6492\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7218 - val_loss: 0.6450\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7200 - val_loss: 0.6435\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7194 - val_loss: 0.6441\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7180 - val_loss: 0.6470\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7196 - val_loss: 0.6441\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7196 - val_loss: 0.6425\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7181 - val_loss: 0.6411\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7167 - val_loss: 0.6412\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7160 - val_loss: 0.6412\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7171 - val_loss: 0.6429\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7181 - val_loss: 0.6457\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 11ms/step - loss: 0.8951 - val_loss: 0.7670\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7886 - val_loss: 0.7173\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7738 - val_loss: 0.7231\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7620 - val_loss: 0.7222\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7607 - val_loss: 0.7302\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7524 - val_loss: 0.7092\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7474 - val_loss: 0.7096\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7422 - val_loss: 0.6979\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7449 - val_loss: 0.6929\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7383 - val_loss: 0.6938\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7413 - val_loss: 0.6930\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7369 - val_loss: 0.6853\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7327 - val_loss: 0.6815\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7348 - val_loss: 0.6790\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7334 - val_loss: 0.6835\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.6816\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7288 - val_loss: 0.6791\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7270 - val_loss: 0.6744\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7303 - val_loss: 0.6781\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7259 - val_loss: 0.6794\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7270 - val_loss: 0.6767\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7262 - val_loss: 0.6763\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7252 - val_loss: 0.6735\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7244 - val_loss: 0.6768\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.6726\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.6769\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7239 - val_loss: 0.6769\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7259 - val_loss: 0.6761\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7250 - val_loss: 0.6754\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7255 - val_loss: 0.6738\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7247 - val_loss: 0.6742\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7232 - val_loss: 0.6748\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7227 - val_loss: 0.6735\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7228 - val_loss: 0.6766\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7242 - val_loss: 0.6747\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7222 - val_loss: 0.6729\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 0.6742\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7227 - val_loss: 0.6716\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7233 - val_loss: 0.6720\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7228 - val_loss: 0.6721\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7229 - val_loss: 0.6723\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7215 - val_loss: 0.6722\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7213 - val_loss: 0.6725\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7215 - val_loss: 0.6752\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7227 - val_loss: 0.6736\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7218 - val_loss: 0.6733\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.6714\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7213 - val_loss: 0.6719\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.6730\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7213 - val_loss: 0.6735\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7214 - val_loss: 0.6720\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.6710\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.6752\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7232 - val_loss: 0.6740\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7216 - val_loss: 0.6737\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7220 - val_loss: 0.6744\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7206 - val_loss: 0.6735\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7207 - val_loss: 0.6722\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7199 - val_loss: 0.6728\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7197 - val_loss: 0.6726\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7194 - val_loss: 0.6731\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7204 - val_loss: 0.6747\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7211 - val_loss: 0.6736\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.6715\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7196 - val_loss: 0.6707\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7194 - val_loss: 0.6712\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7203 - val_loss: 0.6702\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.6740\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.6726\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7201 - val_loss: 0.6738\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7199 - val_loss: 0.6720\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7201 - val_loss: 0.6719\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7193 - val_loss: 0.6725\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7200 - val_loss: 0.6735\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7192 - val_loss: 0.6724\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7199 - val_loss: 0.6725\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7193 - val_loss: 0.6731\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.6725\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7196 - val_loss: 0.6723\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7185 - val_loss: 0.6722\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7189 - val_loss: 0.6730\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7183 - val_loss: 0.6717\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7189 - val_loss: 0.6707\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7189 - val_loss: 0.6730\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7190 - val_loss: 0.6719\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6713\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7192 - val_loss: 0.6713\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.8826 - val_loss: 0.8055\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7502\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7693 - val_loss: 0.7498\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7558 - val_loss: 0.7460\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7511 - val_loss: 0.7395\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7445 - val_loss: 0.7350\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7449 - val_loss: 0.7430\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7450 - val_loss: 0.7294\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7347 - val_loss: 0.7274\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7386 - val_loss: 0.7290\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7336 - val_loss: 0.7316\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7326 - val_loss: 0.7288\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7326 - val_loss: 0.7275\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7330 - val_loss: 0.7282\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7424 - val_loss: 0.7300\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.7191\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7313 - val_loss: 0.7243\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7280 - val_loss: 0.7217\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7285 - val_loss: 0.7241\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7290 - val_loss: 0.7242\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7275 - val_loss: 0.7247\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7262 - val_loss: 0.7250\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7261 - val_loss: 0.7244\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7295 - val_loss: 0.7263\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7278 - val_loss: 0.7250\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7283 - val_loss: 0.7290\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7292 - val_loss: 0.7237\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7270 - val_loss: 0.7224\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7241 - val_loss: 0.7221\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7237 - val_loss: 0.7223\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7243 - val_loss: 0.7245\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7239 - val_loss: 0.7220\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7237 - val_loss: 0.7270\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7269 - val_loss: 0.7243\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7249 - val_loss: 0.7213\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7230 - val_loss: 0.7211\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 0.8599 - val_loss: 0.6835\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7566 - val_loss: 0.6786\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7301 - val_loss: 0.6651\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6921 - val_loss: 0.6581\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7024 - val_loss: 0.6651\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6918 - val_loss: 0.6413\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6572 - val_loss: 0.6226\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.6241\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6307\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6612 - val_loss: 0.5957\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6506 - val_loss: 0.5972\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6240 - val_loss: 0.6067\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6032\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6249 - val_loss: 0.6049\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6348 - val_loss: 0.6056\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6288 - val_loss: 0.6069\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6117 - val_loss: 0.5908\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.5921\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6048 - val_loss: 0.5731\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5982 - val_loss: 0.5873\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5943 - val_loss: 0.5933\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.5950\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6118 - val_loss: 0.5994\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.5977\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6008 - val_loss: 0.5931\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5935 - val_loss: 0.5805\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6046 - val_loss: 0.5913\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5940 - val_loss: 0.6058\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5936 - val_loss: 0.6355\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5923 - val_loss: 0.5933\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.5814\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6064 - val_loss: 0.5673\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5807 - val_loss: 0.5720\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5743 - val_loss: 0.5647\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5761 - val_loss: 0.5686\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5952 - val_loss: 0.5775\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5870 - val_loss: 0.5676\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5622 - val_loss: 0.5819\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5740 - val_loss: 0.5772\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5693 - val_loss: 0.5792\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5646 - val_loss: 0.5597\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5769 - val_loss: 0.5730\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5726 - val_loss: 0.5837\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5610 - val_loss: 0.5733\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5549 - val_loss: 0.5909\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5826 - val_loss: 0.5748\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5670 - val_loss: 0.5835\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5561 - val_loss: 0.5868\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5519 - val_loss: 0.5554\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5405 - val_loss: 0.5491\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5408 - val_loss: 0.5749\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5457 - val_loss: 0.5843\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5322 - val_loss: 0.5598\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5252 - val_loss: 0.6201\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5352 - val_loss: 0.5525\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5326 - val_loss: 0.5518\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5261 - val_loss: 0.5633\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5628 - val_loss: 0.5604\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5849 - val_loss: 0.6462\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5756 - val_loss: 0.5704\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5652 - val_loss: 0.5861\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5645 - val_loss: 0.5771\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5465 - val_loss: 0.5606\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5361 - val_loss: 0.5691\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5334 - val_loss: 0.5676\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5624 - val_loss: 0.5805\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5407 - val_loss: 0.5480\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5380 - val_loss: 0.5551\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5240 - val_loss: 0.6110\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5230 - val_loss: 0.5427\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5199 - val_loss: 0.5894\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5472 - val_loss: 0.5832\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5245 - val_loss: 0.5657\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5333 - val_loss: 0.5967\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5386 - val_loss: 0.5708\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5143 - val_loss: 0.5589\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5239 - val_loss: 0.5750\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5182 - val_loss: 0.5526\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5234 - val_loss: 0.5594\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5078 - val_loss: 0.5778\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5085 - val_loss: 0.5632\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5043 - val_loss: 0.5518\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5220 - val_loss: 0.5699\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5409 - val_loss: 0.5902\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5213 - val_loss: 0.5621\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5112 - val_loss: 0.6969\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5628 - val_loss: 0.6348\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5484 - val_loss: 0.5690\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5134 - val_loss: 0.6146\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5150 - val_loss: 0.5675\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 0.9018 - val_loss: 0.7673\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7893 - val_loss: 0.7459\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7871 - val_loss: 0.6916\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7185 - val_loss: 0.6559\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7384 - val_loss: 0.6852\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7003 - val_loss: 0.6660\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.6529\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.6821\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.6316\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6645 - val_loss: 0.6398\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6662 - val_loss: 0.6433\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.6709\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6997 - val_loss: 0.6539\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6794 - val_loss: 0.6352\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6837 - val_loss: 0.6856\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6794 - val_loss: 0.6354\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6436 - val_loss: 0.6255\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6394 - val_loss: 0.6309\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6542 - val_loss: 0.6176\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.6262\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6411 - val_loss: 0.6325\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6347 - val_loss: 0.6413\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6493\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6552 - val_loss: 0.6599\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.6409\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6441 - val_loss: 0.6456\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6410 - val_loss: 0.6313\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6397 - val_loss: 0.6403\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.6747\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6643\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6697 - val_loss: 0.7007\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6752 - val_loss: 0.6584\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6654 - val_loss: 0.6431\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6310\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6336 - val_loss: 0.6132\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6278\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6525\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6467 - val_loss: 0.6426\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6411 - val_loss: 0.6322\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6401 - val_loss: 0.6227\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6266 - val_loss: 0.6251\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6266 - val_loss: 0.6171\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6173 - val_loss: 0.6169\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6048 - val_loss: 0.6067\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6068 - val_loss: 0.6309\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6065 - val_loss: 0.6173\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6088 - val_loss: 0.6260\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6131 - val_loss: 0.6462\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6054 - val_loss: 0.6657\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6300 - val_loss: 0.6385\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.6139\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6100 - val_loss: 0.6153\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5927 - val_loss: 0.5997\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5829 - val_loss: 0.6157\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5861 - val_loss: 0.6098\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5952 - val_loss: 0.6041\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5887 - val_loss: 0.6815\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6244 - val_loss: 0.6239\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6013 - val_loss: 0.6308\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5984 - val_loss: 0.5916\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6066 - val_loss: 0.6088\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.5935\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6098\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5955 - val_loss: 0.6245\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5922 - val_loss: 0.6192\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6295\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6005 - val_loss: 0.6125\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.6515\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6186 - val_loss: 0.6865\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.5926\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5741 - val_loss: 0.6075\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5692 - val_loss: 0.5896\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5684 - val_loss: 0.5844\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5660 - val_loss: 0.6145\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5898 - val_loss: 0.6288\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5892 - val_loss: 0.6014\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5679 - val_loss: 0.6177\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5976 - val_loss: 0.6151\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5785 - val_loss: 0.6043\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5939 - val_loss: 0.5982\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5741 - val_loss: 0.5881\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5778 - val_loss: 0.5789\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5664 - val_loss: 0.5897\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5571 - val_loss: 0.5810\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5534 - val_loss: 0.5979\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5550 - val_loss: 0.5960\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5524 - val_loss: 0.6011\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5711 - val_loss: 0.5904\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5747 - val_loss: 0.6258\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5680 - val_loss: 0.5759\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5574 - val_loss: 0.6125\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5551 - val_loss: 0.5854\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5565 - val_loss: 0.5978\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5545 - val_loss: 0.5914\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5619 - val_loss: 0.6159\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5708 - val_loss: 0.5976\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5679 - val_loss: 0.6091\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5657 - val_loss: 0.5935\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5702 - val_loss: 0.6017\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5554 - val_loss: 0.5709\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5596 - val_loss: 0.5851\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5768 - val_loss: 0.6407\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5699 - val_loss: 0.5954\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5519 - val_loss: 0.5975\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5530 - val_loss: 0.5639\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5373 - val_loss: 0.5753\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5453 - val_loss: 0.5811\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5409 - val_loss: 0.5833\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5419 - val_loss: 0.5916\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5423 - val_loss: 0.5912\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5450 - val_loss: 0.5707\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5475 - val_loss: 0.5648\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5451 - val_loss: 0.5786\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5438 - val_loss: 0.5955\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5381 - val_loss: 0.5713\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5237 - val_loss: 0.5660\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5326 - val_loss: 0.5601\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5262 - val_loss: 0.5643\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5274 - val_loss: 0.5622\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5321 - val_loss: 0.5628\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5346 - val_loss: 0.5744\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5307 - val_loss: 0.5699\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5343 - val_loss: 0.5768\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5350 - val_loss: 0.5733\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5355 - val_loss: 0.5709\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5400 - val_loss: 0.5806\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5481 - val_loss: 0.5860\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5485 - val_loss: 0.5937\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5454 - val_loss: 0.5775\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5334 - val_loss: 0.5791\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5304 - val_loss: 0.5595\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5632 - val_loss: 0.6522\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5873 - val_loss: 0.5818\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5778 - val_loss: 0.5645\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5491 - val_loss: 0.5975\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5608 - val_loss: 0.5629\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5369 - val_loss: 0.5697\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5191 - val_loss: 0.5812\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5130 - val_loss: 0.5502\n",
      "Epoch 140/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5053 - val_loss: 0.5501\n",
      "Epoch 141/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5122 - val_loss: 0.5828\n",
      "Epoch 142/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5171 - val_loss: 0.5526\n",
      "Epoch 143/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5137 - val_loss: 0.5766\n",
      "Epoch 144/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5252 - val_loss: 0.5659\n",
      "Epoch 145/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5240 - val_loss: 0.5538\n",
      "Epoch 146/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5120 - val_loss: 0.5338\n",
      "Epoch 147/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4997 - val_loss: 0.5494\n",
      "Epoch 148/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5062 - val_loss: 0.5699\n",
      "Epoch 149/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5050 - val_loss: 0.5562\n",
      "Epoch 150/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5122 - val_loss: 0.5701\n",
      "Epoch 151/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5299 - val_loss: 0.6217\n",
      "Epoch 152/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5464 - val_loss: 0.5607\n",
      "Epoch 153/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5492 - val_loss: 0.6090\n",
      "Epoch 154/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5303 - val_loss: 0.5870\n",
      "Epoch 155/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5267 - val_loss: 0.5877\n",
      "Epoch 156/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5306 - val_loss: 0.5936\n",
      "Epoch 157/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5179 - val_loss: 0.5473\n",
      "Epoch 158/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5110 - val_loss: 0.5509\n",
      "Epoch 159/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4988 - val_loss: 0.5533\n",
      "Epoch 160/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5168 - val_loss: 0.5379\n",
      "Epoch 161/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5097 - val_loss: 0.5517\n",
      "Epoch 162/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5092 - val_loss: 0.5532\n",
      "Epoch 163/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4935 - val_loss: 0.5475\n",
      "Epoch 164/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4923 - val_loss: 0.5312\n",
      "Epoch 165/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5010 - val_loss: 0.5468\n",
      "Epoch 166/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5093 - val_loss: 0.5702\n",
      "Epoch 167/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5023 - val_loss: 0.5577\n",
      "Epoch 168/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5156 - val_loss: 0.5721\n",
      "Epoch 169/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5366 - val_loss: 0.5585\n",
      "Epoch 170/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5203 - val_loss: 0.5449\n",
      "Epoch 171/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5157 - val_loss: 0.5669\n",
      "Epoch 172/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5063 - val_loss: 0.5528\n",
      "Epoch 173/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5053 - val_loss: 0.5637\n",
      "Epoch 174/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4932 - val_loss: 0.5622\n",
      "Epoch 175/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4972 - val_loss: 0.5828\n",
      "Epoch 176/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5387 - val_loss: 0.6146\n",
      "Epoch 177/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5435 - val_loss: 0.5980\n",
      "Epoch 178/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5196 - val_loss: 0.5660\n",
      "Epoch 179/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5036 - val_loss: 0.5418\n",
      "Epoch 180/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4966 - val_loss: 0.5574\n",
      "Epoch 181/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4839 - val_loss: 0.5471\n",
      "Epoch 182/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4854 - val_loss: 0.5523\n",
      "Epoch 183/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4933 - val_loss: 0.5813\n",
      "Epoch 184/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5002 - val_loss: 0.5443\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.8612 - val_loss: 0.7636\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7514 - val_loss: 0.7343\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7388 - val_loss: 0.7171\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7193 - val_loss: 0.6959\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6869 - val_loss: 0.6915\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6653 - val_loss: 0.6707\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6713 - val_loss: 0.6777\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6945 - val_loss: 0.7059\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6861 - val_loss: 0.6913\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7115 - val_loss: 0.6570\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6627 - val_loss: 0.6892\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6679\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6412 - val_loss: 0.6652\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6305 - val_loss: 0.6394\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6498\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6261 - val_loss: 0.6440\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6572\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6646 - val_loss: 0.6899\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6570\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6433 - val_loss: 0.6614\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6671\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6356 - val_loss: 0.6583\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.6421\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6417 - val_loss: 0.6583\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6584 - val_loss: 0.6473\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6209 - val_loss: 0.6483\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6058 - val_loss: 0.6453\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6474 - val_loss: 0.6461\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.6686\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6269 - val_loss: 0.6491\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6213 - val_loss: 0.6666\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6237 - val_loss: 0.6533\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6201 - val_loss: 0.6291\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6020 - val_loss: 0.6354\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5912 - val_loss: 0.6278\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5913 - val_loss: 0.6259\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6154 - val_loss: 0.6571\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6398 - val_loss: 0.6534\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.6366\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.6378\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6090 - val_loss: 0.6362\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5971 - val_loss: 0.6559\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6162 - val_loss: 0.6234\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5776 - val_loss: 0.6335\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5738 - val_loss: 0.6243\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6416\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6034 - val_loss: 0.6301\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6249\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5923 - val_loss: 0.6278\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6687\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.6202\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5800 - val_loss: 0.6017\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5719 - val_loss: 0.6150\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5626 - val_loss: 0.6071\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5543 - val_loss: 0.5961\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.6134\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5705 - val_loss: 0.6216\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5872 - val_loss: 0.6089\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5651 - val_loss: 0.6030\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5470 - val_loss: 0.6084\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5681 - val_loss: 0.6057\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5574 - val_loss: 0.6114\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6309\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6034 - val_loss: 0.6200\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5740 - val_loss: 0.6213\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5590 - val_loss: 0.5928\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5545 - val_loss: 0.6084\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5459 - val_loss: 0.6023\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5459 - val_loss: 0.5951\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5445 - val_loss: 0.6218\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5503 - val_loss: 0.5971\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5386 - val_loss: 0.5844\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5409 - val_loss: 0.5948\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5535 - val_loss: 0.6106\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5565 - val_loss: 0.5851\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5393 - val_loss: 0.6003\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5401 - val_loss: 0.6458\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5417 - val_loss: 0.5872\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5476 - val_loss: 0.5946\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5448 - val_loss: 0.5929\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5330 - val_loss: 0.5923\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5483 - val_loss: 0.5802\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5367 - val_loss: 0.5867\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5431 - val_loss: 0.5878\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5294 - val_loss: 0.5796\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5243 - val_loss: 0.5665\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5243 - val_loss: 0.5729\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5181 - val_loss: 0.5882\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5174 - val_loss: 0.5795\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5194 - val_loss: 0.5754\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5207 - val_loss: 0.5891\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5315 - val_loss: 0.5845\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5181 - val_loss: 0.5816\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5458 - val_loss: 0.5766\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5324 - val_loss: 0.5777\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5209 - val_loss: 0.5731\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5183 - val_loss: 0.5742\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5139 - val_loss: 0.5807\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.4999 - val_loss: 0.5814\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5141 - val_loss: 0.5990\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5150 - val_loss: 0.5653\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4920 - val_loss: 0.5734\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5055 - val_loss: 0.5840\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5157 - val_loss: 0.6421\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5256 - val_loss: 0.5971\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5672 - val_loss: 0.6201\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5581 - val_loss: 0.6196\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5374 - val_loss: 0.5755\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5096 - val_loss: 0.5807\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5105 - val_loss: 0.5897\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5183 - val_loss: 0.5761\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5029 - val_loss: 0.5794\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4955 - val_loss: 0.5733\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5058 - val_loss: 0.5655\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5074 - val_loss: 0.5702\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5223 - val_loss: 0.5899\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5167 - val_loss: 0.6121\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4952 - val_loss: 0.5664\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4890 - val_loss: 0.5740\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4861 - val_loss: 0.5738\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4875 - val_loss: 0.5714\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 11ms/step - loss: 1.0163 - val_loss: 0.7969\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8895 - val_loss: 0.7743\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8541 - val_loss: 0.7629\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8328 - val_loss: 0.7670\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8286 - val_loss: 0.7472\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8251 - val_loss: 0.7556\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.8128 - val_loss: 0.7384\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8153 - val_loss: 0.7502\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8103 - val_loss: 0.7323\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8037 - val_loss: 0.7555\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7971 - val_loss: 0.7441\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7935 - val_loss: 0.7515\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7845 - val_loss: 0.7217\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7836 - val_loss: 0.7538\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7775 - val_loss: 0.7272\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7851 - val_loss: 0.7201\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7747 - val_loss: 0.7104\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7697 - val_loss: 0.7272\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7506 - val_loss: 0.6879\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7586 - val_loss: 0.7085\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7458 - val_loss: 0.6741\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7361 - val_loss: 0.7346\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7351 - val_loss: 0.6681\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7171 - val_loss: 0.6783\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7239 - val_loss: 0.6899\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7520 - val_loss: 0.7154\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7351 - val_loss: 0.6846\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7651 - val_loss: 0.7170\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7546 - val_loss: 0.6919\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7253 - val_loss: 0.6714\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7187 - val_loss: 0.6617\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7136 - val_loss: 0.6706\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7058 - val_loss: 0.6598\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7174 - val_loss: 0.6945\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.7411 - val_loss: 0.6725\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7192 - val_loss: 0.6664\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7256 - val_loss: 0.7156\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7390 - val_loss: 0.6953\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7945 - val_loss: 0.7462\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8075 - val_loss: 0.6761\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7672 - val_loss: 0.6834\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7612 - val_loss: 0.7298\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7646 - val_loss: 0.7278\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8154 - val_loss: 0.7221\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8298 - val_loss: 0.7312\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8820 - val_loss: 0.7518\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8303 - val_loss: 0.7182\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8002 - val_loss: 0.7014\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7924 - val_loss: 0.6945\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7778 - val_loss: 0.6754\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7794 - val_loss: 0.6946\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7959 - val_loss: 0.6999\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7774 - val_loss: 0.6809\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 8ms/step - loss: 1.0922 - val_loss: 0.9846\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0333 - val_loss: 0.9595\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0125 - val_loss: 0.9553\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.9558\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0061 - val_loss: 0.9556\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0057 - val_loss: 0.9562\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0055 - val_loss: 0.9558\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0055 - val_loss: 0.9564\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9564\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0054 - val_loss: 0.9565\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 1.0054 - val_loss: 0.9566\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.0053 - val_loss: 0.9569\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 1.0054 - val_loss: 0.9568\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9570\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9572\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9574\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9572\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 1.0053 - val_loss: 0.9575\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9576\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9577\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9576\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 1.0053 - val_loss: 0.9577\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9577\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 9ms/step - loss: 1.0570 - val_loss: 0.8447\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8921 - val_loss: 0.8208\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8485 - val_loss: 0.7766\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9078 - val_loss: 0.7460\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7687 - val_loss: 0.7262\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7239 - val_loss: 0.7052\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7280 - val_loss: 0.7208\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.7339 - val_loss: 0.7071\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6704\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6654 - val_loss: 0.7075\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6546 - val_loss: 0.6714\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6685 - val_loss: 0.6666\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6545 - val_loss: 0.6827\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6382 - val_loss: 0.6600\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6807\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6415 - val_loss: 0.6503\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6327 - val_loss: 0.6428\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6250 - val_loss: 0.6441\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6324 - val_loss: 0.6417\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6362 - val_loss: 0.6496\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6259 - val_loss: 0.6430\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6125 - val_loss: 0.6513\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.6472\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6031 - val_loss: 0.6462\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6141 - val_loss: 0.6581\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6448\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5975 - val_loss: 0.6325\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5961 - val_loss: 0.6450\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5925 - val_loss: 0.6444\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5899 - val_loss: 0.6316\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5896 - val_loss: 0.6409\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6012 - val_loss: 0.6352\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5851 - val_loss: 0.6434\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5824 - val_loss: 0.6289\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5994 - val_loss: 0.6375\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5757 - val_loss: 0.6445\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 0.6382\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5797 - val_loss: 0.6493\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5899 - val_loss: 0.6529\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6172 - val_loss: 0.6507\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.6292\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5753 - val_loss: 0.6202\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5599 - val_loss: 0.6368\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5595 - val_loss: 0.6378\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5590 - val_loss: 0.6171\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5594 - val_loss: 0.6270\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5968 - val_loss: 0.6621\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5778 - val_loss: 0.6667\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5742 - val_loss: 0.6270\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5477 - val_loss: 0.6333\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5487 - val_loss: 0.6268\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6000 - val_loss: 0.6606\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5973 - val_loss: 0.6578\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.6444\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.6199\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5619 - val_loss: 0.6666\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5626 - val_loss: 0.6305\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5465 - val_loss: 0.6214\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5307 - val_loss: 0.6192\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5321 - val_loss: 0.6226\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5436 - val_loss: 0.6669\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5443 - val_loss: 0.6325\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5259 - val_loss: 0.6254\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5672 - val_loss: 0.6249\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5437 - val_loss: 0.6201\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 14ms/step - loss: 0.8241 - val_loss: 0.6713\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7145 - val_loss: 0.6024\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.6120\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.5979\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6412 - val_loss: 0.6164\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6368 - val_loss: 0.5852\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 0.5948\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6280 - val_loss: 0.5818\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6189 - val_loss: 0.5689\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.5754\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.5917\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.5620\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5904 - val_loss: 0.5619\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5896 - val_loss: 0.5537\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5838 - val_loss: 0.5692\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5812 - val_loss: 0.5632\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5802 - val_loss: 0.5700\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5729 - val_loss: 0.5616\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5694 - val_loss: 0.5673\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5607 - val_loss: 0.5525\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5588 - val_loss: 0.5657\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5609 - val_loss: 0.5637\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5514 - val_loss: 0.5596\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5633 - val_loss: 0.5676\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5494 - val_loss: 0.5735\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5525 - val_loss: 0.5427\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5422 - val_loss: 0.5568\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 0.5593\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5354 - val_loss: 0.5745\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5323 - val_loss: 0.5440\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5218 - val_loss: 0.5415\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5250 - val_loss: 0.5582\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5270 - val_loss: 0.5578\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5172 - val_loss: 0.5599\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5136 - val_loss: 0.5412\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5136 - val_loss: 0.5606\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5091 - val_loss: 0.5566\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5074 - val_loss: 0.5468\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5081 - val_loss: 0.5455\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5135 - val_loss: 0.5488\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5072 - val_loss: 0.5390\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5033 - val_loss: 0.5610\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5076 - val_loss: 0.5563\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4962 - val_loss: 0.5483\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5046 - val_loss: 0.5401\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4898 - val_loss: 0.5466\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4839 - val_loss: 0.5494\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4837 - val_loss: 0.5424\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4796 - val_loss: 0.5517\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4778 - val_loss: 0.5444\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4846 - val_loss: 0.5585\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4897 - val_loss: 0.5678\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4918 - val_loss: 0.5528\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4892 - val_loss: 0.5465\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4775 - val_loss: 0.5473\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4802 - val_loss: 0.5458\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4711 - val_loss: 0.5368\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4630 - val_loss: 0.5445\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4652 - val_loss: 0.5388\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4606 - val_loss: 0.5478\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4601 - val_loss: 0.5392\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4610 - val_loss: 0.5454\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4625 - val_loss: 0.5419\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4611 - val_loss: 0.5325\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4573 - val_loss: 0.5354\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4507 - val_loss: 0.5315\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4470 - val_loss: 0.5305\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4538 - val_loss: 0.5315\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4467 - val_loss: 0.5318\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4485 - val_loss: 0.5387\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4476 - val_loss: 0.5344\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4429 - val_loss: 0.5293\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4462 - val_loss: 0.5348\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4447 - val_loss: 0.5297\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4440 - val_loss: 0.5341\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4388 - val_loss: 0.5256\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4430 - val_loss: 0.5309\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4461 - val_loss: 0.5457\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4419 - val_loss: 0.5405\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4347 - val_loss: 0.5310\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4400 - val_loss: 0.5237\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4350 - val_loss: 0.5221\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4324 - val_loss: 0.5257\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4305 - val_loss: 0.5243\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4313 - val_loss: 0.5319\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4323 - val_loss: 0.5321\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4292 - val_loss: 0.5295\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4403 - val_loss: 0.5262\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4390 - val_loss: 0.5292\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4304 - val_loss: 0.5390\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4317 - val_loss: 0.5298\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4309 - val_loss: 0.5285\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4257 - val_loss: 0.5207\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4249 - val_loss: 0.5320\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4273 - val_loss: 0.5198\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4217 - val_loss: 0.5310\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4215 - val_loss: 0.5396\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4256 - val_loss: 0.5201\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4278 - val_loss: 0.5161\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4212 - val_loss: 0.5308\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4186 - val_loss: 0.5196\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4186 - val_loss: 0.5281\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4169 - val_loss: 0.5307\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4159 - val_loss: 0.5287\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4147 - val_loss: 0.5261\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4153 - val_loss: 0.5249\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4167 - val_loss: 0.5251\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4128 - val_loss: 0.5246\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4110 - val_loss: 0.5204\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4147 - val_loss: 0.5279\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4149 - val_loss: 0.5271\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4127 - val_loss: 0.5365\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4158 - val_loss: 0.5275\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4088 - val_loss: 0.5254\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.5282\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4076 - val_loss: 0.5259\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4097 - val_loss: 0.5385\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4035 - val_loss: 0.5328\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4028 - val_loss: 0.5301\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.8446 - val_loss: 0.6748\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7413 - val_loss: 0.6560\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 0.6456\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6668 - val_loss: 0.6232\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6401 - val_loss: 0.6237\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6307 - val_loss: 0.6144\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6247 - val_loss: 0.6185\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6256 - val_loss: 0.6376\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6225 - val_loss: 0.6103\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6116 - val_loss: 0.5940\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6113\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.6066\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5885 - val_loss: 0.6002\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5804 - val_loss: 0.5943\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5753 - val_loss: 0.6007\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5713 - val_loss: 0.5936\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5668 - val_loss: 0.5932\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5608 - val_loss: 0.6048\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5651 - val_loss: 0.5884\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5593 - val_loss: 0.5942\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5589 - val_loss: 0.5802\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5519 - val_loss: 0.5759\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5458 - val_loss: 0.5740\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5449 - val_loss: 0.5762\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5431 - val_loss: 0.5821\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5453 - val_loss: 0.5674\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5388 - val_loss: 0.5742\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5369 - val_loss: 0.5793\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5338 - val_loss: 0.6026\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5414 - val_loss: 0.5702\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5390 - val_loss: 0.5609\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5361 - val_loss: 0.5737\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5388 - val_loss: 0.5555\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5269 - val_loss: 0.5672\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5222 - val_loss: 0.5547\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5169 - val_loss: 0.5655\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5076 - val_loss: 0.5525\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5044 - val_loss: 0.5691\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5067 - val_loss: 0.5743\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5076 - val_loss: 0.5568\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5010 - val_loss: 0.5527\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4964 - val_loss: 0.5614\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4958 - val_loss: 0.5601\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4980 - val_loss: 0.5609\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4907 - val_loss: 0.5498\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4910 - val_loss: 0.5529\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4929 - val_loss: 0.5600\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4868 - val_loss: 0.5534\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4945 - val_loss: 0.5498\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4919 - val_loss: 0.5581\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4810 - val_loss: 0.5399\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4800 - val_loss: 0.5440\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4742 - val_loss: 0.5387\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4719 - val_loss: 0.5295\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4720 - val_loss: 0.5443\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4701 - val_loss: 0.5339\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4651 - val_loss: 0.5419\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4724 - val_loss: 0.5395\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4680 - val_loss: 0.5422\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4707 - val_loss: 0.5317\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4713 - val_loss: 0.5296\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4656 - val_loss: 0.5339\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4595 - val_loss: 0.5304\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4571 - val_loss: 0.5308\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4553 - val_loss: 0.5237\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4591 - val_loss: 0.5439\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4606 - val_loss: 0.5422\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4530 - val_loss: 0.5256\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4473 - val_loss: 0.5394\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4501 - val_loss: 0.5276\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4484 - val_loss: 0.5381\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4526 - val_loss: 0.5295\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4500 - val_loss: 0.5348\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4493 - val_loss: 0.5135\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4476 - val_loss: 0.5190\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4426 - val_loss: 0.5406\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4404 - val_loss: 0.5169\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4353 - val_loss: 0.5217\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4372 - val_loss: 0.5322\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4407 - val_loss: 0.5201\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4359 - val_loss: 0.5181\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4342 - val_loss: 0.5215\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4360 - val_loss: 0.5249\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4331 - val_loss: 0.5347\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4316 - val_loss: 0.5256\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4338 - val_loss: 0.5213\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4316 - val_loss: 0.5274\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4327 - val_loss: 0.5375\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4325 - val_loss: 0.5140\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4359 - val_loss: 0.5196\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4346 - val_loss: 0.5269\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4307 - val_loss: 0.5175\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4264 - val_loss: 0.5298\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4254 - val_loss: 0.5151\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.8123 - val_loss: 0.7277\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7357 - val_loss: 0.6948\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6847 - val_loss: 0.6671\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6609 - val_loss: 0.6546\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6430 - val_loss: 0.6655\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6533 - val_loss: 0.6518\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6248 - val_loss: 0.6500\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6421\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6567\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6053 - val_loss: 0.6422\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6433\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5932 - val_loss: 0.6345\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5945 - val_loss: 0.6310\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5906 - val_loss: 0.6316\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5816 - val_loss: 0.6373\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6349\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 0.6267\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5692 - val_loss: 0.6353\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5694 - val_loss: 0.6243\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5689 - val_loss: 0.6318\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5719 - val_loss: 0.6215\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5791 - val_loss: 0.6279\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5656 - val_loss: 0.6238\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5503 - val_loss: 0.6228\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5566 - val_loss: 0.6192\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5609 - val_loss: 0.6286\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5557 - val_loss: 0.6221\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5585 - val_loss: 0.6240\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5568 - val_loss: 0.6274\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5564 - val_loss: 0.6200\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5507 - val_loss: 0.6157\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5379 - val_loss: 0.6241\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5364 - val_loss: 0.6188\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5312 - val_loss: 0.6203\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5534 - val_loss: 0.6204\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5455 - val_loss: 0.6197\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5336 - val_loss: 0.6229\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5300 - val_loss: 0.6148\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5274 - val_loss: 0.6211\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5295 - val_loss: 0.6172\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5243 - val_loss: 0.6197\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5181 - val_loss: 0.6141\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5101 - val_loss: 0.6173\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5119 - val_loss: 0.6124\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5094 - val_loss: 0.6108\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5072 - val_loss: 0.6077\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5015 - val_loss: 0.6044\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4970 - val_loss: 0.6114\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4923 - val_loss: 0.6098\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4952 - val_loss: 0.6049\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4993 - val_loss: 0.6077\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4962 - val_loss: 0.6119\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4987 - val_loss: 0.6083\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4818 - val_loss: 0.6042\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5006 - val_loss: 0.6137\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4939 - val_loss: 0.6088\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4779 - val_loss: 0.6103\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4716 - val_loss: 0.6083\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4683 - val_loss: 0.6082\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4717 - val_loss: 0.6138\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4873 - val_loss: 0.6019\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4861 - val_loss: 0.5992\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4768 - val_loss: 0.6037\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4682 - val_loss: 0.6107\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4629 - val_loss: 0.6045\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4618 - val_loss: 0.5984\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4587 - val_loss: 0.6056\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4568 - val_loss: 0.6028\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4586 - val_loss: 0.6011\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4559 - val_loss: 0.6071\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4542 - val_loss: 0.5952\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4515 - val_loss: 0.5910\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4504 - val_loss: 0.5964\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4603 - val_loss: 0.6060\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4629 - val_loss: 0.5971\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4483 - val_loss: 0.6103\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4471 - val_loss: 0.5891\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4529 - val_loss: 0.6019\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4459 - val_loss: 0.5908\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4420 - val_loss: 0.5924\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4471 - val_loss: 0.5913\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4395 - val_loss: 0.6046\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4354 - val_loss: 0.5991\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4334 - val_loss: 0.5923\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4294 - val_loss: 0.5821\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4321 - val_loss: 0.5898\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4379 - val_loss: 0.5874\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4342 - val_loss: 0.5797\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4279 - val_loss: 0.5861\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4239 - val_loss: 0.5858\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4250 - val_loss: 0.5838\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4283 - val_loss: 0.5868\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4303 - val_loss: 0.5789\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 0.5771\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4227 - val_loss: 0.5809\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4245 - val_loss: 0.5834\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4259 - val_loss: 0.5793\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4232 - val_loss: 0.5770\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4320 - val_loss: 0.5784\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4226 - val_loss: 0.5823\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4273 - val_loss: 0.5774\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4185 - val_loss: 0.5771\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4166 - val_loss: 0.5784\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4159 - val_loss: 0.5850\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4179 - val_loss: 0.5860\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4213 - val_loss: 0.5801\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4175 - val_loss: 0.5680\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4166 - val_loss: 0.5854\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4130 - val_loss: 0.5844\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4139 - val_loss: 0.5735\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4106 - val_loss: 0.5749\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4118 - val_loss: 0.5702\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.5727\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4091 - val_loss: 0.5720\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4107 - val_loss: 0.5816\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4118 - val_loss: 0.5664\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4087 - val_loss: 0.5739\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4100 - val_loss: 0.5703\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4112 - val_loss: 0.5852\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4120 - val_loss: 0.5821\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4162 - val_loss: 0.5782\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4182 - val_loss: 0.5737\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4173 - val_loss: 0.5759\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4083 - val_loss: 0.5897\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4074 - val_loss: 0.5713\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4014 - val_loss: 0.5610\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4044 - val_loss: 0.5789\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4018 - val_loss: 0.5699\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3981 - val_loss: 0.5808\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3999 - val_loss: 0.5725\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3973 - val_loss: 0.5679\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3983 - val_loss: 0.5761\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3966 - val_loss: 0.5820\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3930 - val_loss: 0.5655\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3974 - val_loss: 0.5666\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3980 - val_loss: 0.5670\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 0.5769\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3937 - val_loss: 0.5662\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3983 - val_loss: 0.5743\n",
      "Epoch 140/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3991 - val_loss: 0.5643\n",
      "Epoch 141/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3940 - val_loss: 0.5692\n",
      "Epoch 142/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3955 - val_loss: 0.5761\n",
      "Epoch 143/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3958 - val_loss: 0.5618\n",
      "Epoch 144/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3896 - val_loss: 0.5664\n",
      "Epoch 145/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3911 - val_loss: 0.5713\n",
      "Epoch 146/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3966 - val_loss: 0.5586\n",
      "Epoch 147/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3925 - val_loss: 0.5675\n",
      "Epoch 148/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3929 - val_loss: 0.5718\n",
      "Epoch 149/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3906 - val_loss: 0.5688\n",
      "Epoch 150/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3896 - val_loss: 0.5653\n",
      "Epoch 151/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3988 - val_loss: 0.5667\n",
      "Epoch 152/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3892 - val_loss: 0.5653\n",
      "Epoch 153/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3876 - val_loss: 0.5658\n",
      "Epoch 154/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3891 - val_loss: 0.5618\n",
      "Epoch 155/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3822 - val_loss: 0.5508\n",
      "Epoch 156/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3809 - val_loss: 0.5607\n",
      "Epoch 157/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3843 - val_loss: 0.5661\n",
      "Epoch 158/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3882 - val_loss: 0.5558\n",
      "Epoch 159/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3916 - val_loss: 0.5704\n",
      "Epoch 160/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3874 - val_loss: 0.5612\n",
      "Epoch 161/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3864 - val_loss: 0.5572\n",
      "Epoch 162/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3829 - val_loss: 0.5659\n",
      "Epoch 163/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3806 - val_loss: 0.5560\n",
      "Epoch 164/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3813 - val_loss: 0.5515\n",
      "Epoch 165/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3780 - val_loss: 0.5568\n",
      "Epoch 166/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3783 - val_loss: 0.5544\n",
      "Epoch 167/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3775 - val_loss: 0.5514\n",
      "Epoch 168/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3784 - val_loss: 0.5467\n",
      "Epoch 169/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3765 - val_loss: 0.5565\n",
      "Epoch 170/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3811 - val_loss: 0.5502\n",
      "Epoch 171/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3771 - val_loss: 0.5552\n",
      "Epoch 172/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.3844 - val_loss: 0.5527\n",
      "Epoch 173/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3878 - val_loss: 0.5616\n",
      "Epoch 174/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3811 - val_loss: 0.5670\n",
      "Epoch 175/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3858 - val_loss: 0.5635\n",
      "Epoch 176/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3763 - val_loss: 0.5517\n",
      "Epoch 177/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3726 - val_loss: 0.5632\n",
      "Epoch 178/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3719 - val_loss: 0.5511\n",
      "Epoch 179/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3703 - val_loss: 0.5507\n",
      "Epoch 180/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3686 - val_loss: 0.5610\n",
      "Epoch 181/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3720 - val_loss: 0.5640\n",
      "Epoch 182/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3746 - val_loss: 0.5560\n",
      "Epoch 183/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3744 - val_loss: 0.5627\n",
      "Epoch 184/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3737 - val_loss: 0.5508\n",
      "Epoch 185/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3727 - val_loss: 0.5584\n",
      "Epoch 186/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3737 - val_loss: 0.5516\n",
      "Epoch 187/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3699 - val_loss: 0.5616\n",
      "Epoch 188/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3714 - val_loss: 0.5558\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9466 - val_loss: 0.7655\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8139 - val_loss: 0.7339\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7775 - val_loss: 0.7051\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7529 - val_loss: 0.6810\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7302 - val_loss: 0.6658\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7093 - val_loss: 0.6482\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6936 - val_loss: 0.6256\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6750 - val_loss: 0.6186\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6650 - val_loss: 0.6096\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6575 - val_loss: 0.6106\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6536 - val_loss: 0.6036\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6473 - val_loss: 0.5986\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6412 - val_loss: 0.5967\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6373 - val_loss: 0.5967\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6325 - val_loss: 0.5939\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6326 - val_loss: 0.5931\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6295 - val_loss: 0.5906\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 0.5881\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6291 - val_loss: 0.5908\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6261 - val_loss: 0.5901\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 0.5869\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6209 - val_loss: 0.5895\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6183 - val_loss: 0.5834\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.5871\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.5836\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6132 - val_loss: 0.5831\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 0.5826\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 0.5828\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 0.5820\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 0.5822\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6030 - val_loss: 0.5825\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6045 - val_loss: 0.5808\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6030 - val_loss: 0.5826\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.5797\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.5818\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5979 - val_loss: 0.5804\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5970 - val_loss: 0.5814\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 0.5838\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5945 - val_loss: 0.5824\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5933 - val_loss: 0.5814\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5931 - val_loss: 0.5860\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5925 - val_loss: 0.5857\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5931 - val_loss: 0.5835\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5905 - val_loss: 0.5853\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5916 - val_loss: 0.5904\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5907 - val_loss: 0.5877\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5897 - val_loss: 0.5833\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 0.5841\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5904 - val_loss: 0.5871\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5903 - val_loss: 0.5888\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5893 - val_loss: 0.5898\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5881 - val_loss: 0.5860\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5879 - val_loss: 0.5888\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5893 - val_loss: 0.5832\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9407 - val_loss: 0.7717\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8084 - val_loss: 0.7242\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7787 - val_loss: 0.7070\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7568 - val_loss: 0.6882\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7299 - val_loss: 0.6694\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7112 - val_loss: 0.6653\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6976 - val_loss: 0.6561\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6846 - val_loss: 0.6545\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6727 - val_loss: 0.6470\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6637 - val_loss: 0.6413\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6570 - val_loss: 0.6363\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6338\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.6275\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6393 - val_loss: 0.6220\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6342 - val_loss: 0.6142\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6286 - val_loss: 0.6089\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6244 - val_loss: 0.6117\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 0.6084\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6195 - val_loss: 0.6058\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 0.6043\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6164 - val_loss: 0.6059\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6109 - val_loss: 0.6033\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6104 - val_loss: 0.6021\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6008\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6076 - val_loss: 0.5999\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6003\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 0.5986\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6047 - val_loss: 0.6001\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.5971\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6014\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.5970\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6102\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 0.6004\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.6023\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 0.5972\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 0.5983\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5970 - val_loss: 0.6009\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5963 - val_loss: 0.6018\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5982 - val_loss: 0.6016\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5951 - val_loss: 0.6008\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.5998\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5942 - val_loss: 0.6032\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 0.6019\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 0.5987\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5940 - val_loss: 0.6004\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 0.6032\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5958 - val_loss: 0.6047\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5930 - val_loss: 0.6015\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5932 - val_loss: 0.5998\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5924 - val_loss: 0.5987\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5914 - val_loss: 0.6008\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 9ms/step - loss: 0.9314 - val_loss: 0.7940\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8074 - val_loss: 0.7519\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7690 - val_loss: 0.7460\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7448 - val_loss: 0.7467\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7251 - val_loss: 0.7300\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7099 - val_loss: 0.7259\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6978 - val_loss: 0.7247\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6882 - val_loss: 0.7197\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6828 - val_loss: 0.7200\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6771 - val_loss: 0.7166\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6797 - val_loss: 0.7131\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6684 - val_loss: 0.7168\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.7089\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6585 - val_loss: 0.7035\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.7012\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6507 - val_loss: 0.7010\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6472 - val_loss: 0.6984\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6434 - val_loss: 0.6954\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6405 - val_loss: 0.6916\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6368 - val_loss: 0.6916\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6347 - val_loss: 0.6896\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6313 - val_loss: 0.6887\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6825\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6282 - val_loss: 0.6814\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.6814\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6244 - val_loss: 0.6743\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6224 - val_loss: 0.6742\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6207 - val_loss: 0.6756\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6215 - val_loss: 0.6728\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.6733\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6720\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6721\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.6681\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6120 - val_loss: 0.6704\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6127 - val_loss: 0.6712\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6121 - val_loss: 0.6707\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6110 - val_loss: 0.6701\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6181 - val_loss: 0.6667\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6672\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6113 - val_loss: 0.6649\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6067 - val_loss: 0.6623\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.6656\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6043 - val_loss: 0.6617\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6013 - val_loss: 0.6626\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6012 - val_loss: 0.6592\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6020 - val_loss: 0.6643\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.6578\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6006 - val_loss: 0.6563\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5983 - val_loss: 0.6557\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5985 - val_loss: 0.6608\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5969 - val_loss: 0.6561\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5982 - val_loss: 0.6560\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5962 - val_loss: 0.6648\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5960 - val_loss: 0.6545\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5950 - val_loss: 0.6538\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5961 - val_loss: 0.6550\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 0.6632\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.6554\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5954 - val_loss: 0.6532\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5951 - val_loss: 0.6490\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5927 - val_loss: 0.6520\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5912 - val_loss: 0.6482\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5908 - val_loss: 0.6522\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5927 - val_loss: 0.6467\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5923 - val_loss: 0.6501\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5917 - val_loss: 0.6439\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5909 - val_loss: 0.6453\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5891 - val_loss: 0.6466\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5879 - val_loss: 0.6467\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5874 - val_loss: 0.6460\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5875 - val_loss: 0.6434\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5874 - val_loss: 0.6430\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5878 - val_loss: 0.6464\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5875 - val_loss: 0.6450\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5880 - val_loss: 0.6447\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5869 - val_loss: 0.6425\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5889 - val_loss: 0.6492\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5969 - val_loss: 0.6465\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5946 - val_loss: 0.6478\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 0.6462\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.6484\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6439\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5859 - val_loss: 0.6485\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6432\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6422\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6423\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5843 - val_loss: 0.6425\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5843 - val_loss: 0.6438\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5850 - val_loss: 0.6423\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6437\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5860 - val_loss: 0.6456\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.6462\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 0.6426\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 0.6444\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5861 - val_loss: 0.6428\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6440\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6439\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 0.6426\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.6459\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6414\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 0.6433\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5836 - val_loss: 0.6416\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5832 - val_loss: 0.6433\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 0.6431\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5824 - val_loss: 0.6427\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5826 - val_loss: 0.6426\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 0.6429\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 0.6424\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5836 - val_loss: 0.6449\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5833 - val_loss: 0.6427\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6435\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 0.6420\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5834 - val_loss: 0.6438\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5831 - val_loss: 0.6420\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6463\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 0.6450\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.6440\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5832 - val_loss: 0.6436\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5816 - val_loss: 0.6401\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5822 - val_loss: 0.6426\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 0.6428\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5832 - val_loss: 0.6421\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5832 - val_loss: 0.6426\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 0.6440\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5829 - val_loss: 0.6431\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5830 - val_loss: 0.6419\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5830 - val_loss: 0.6446\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5840 - val_loss: 0.6425\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5830 - val_loss: 0.6424\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6435\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5835 - val_loss: 0.6441\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5829 - val_loss: 0.6445\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5833 - val_loss: 0.6419\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.6432\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5829 - val_loss: 0.6413\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5807 - val_loss: 0.6431\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5813 - val_loss: 0.6411\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 0.6435\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5800 - val_loss: 0.6425\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9485 - val_loss: 0.7710\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7863 - val_loss: 0.6718\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7290 - val_loss: 0.6422\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7000 - val_loss: 0.6319\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6776 - val_loss: 0.6005\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6553 - val_loss: 0.5950\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6445 - val_loss: 0.6017\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6323 - val_loss: 0.5952\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6302 - val_loss: 0.5797\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 0.5846\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 0.5825\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6087 - val_loss: 0.5662\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.5713\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.5680\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5947 - val_loss: 0.5715\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5869 - val_loss: 0.5702\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.5697\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5784 - val_loss: 0.5579\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5780 - val_loss: 0.5693\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5683 - val_loss: 0.5616\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5665 - val_loss: 0.5597\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5619 - val_loss: 0.5610\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5584 - val_loss: 0.5494\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5537 - val_loss: 0.5664\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5565 - val_loss: 0.5536\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5496 - val_loss: 0.5637\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5459 - val_loss: 0.5495\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5439 - val_loss: 0.5612\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5396 - val_loss: 0.5370\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5376 - val_loss: 0.5416\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5299 - val_loss: 0.5499\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5310 - val_loss: 0.5481\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5276 - val_loss: 0.5438\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 0.5540\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5227 - val_loss: 0.5489\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5204 - val_loss: 0.5441\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5150 - val_loss: 0.5370\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5115 - val_loss: 0.5288\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5113 - val_loss: 0.5418\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5082 - val_loss: 0.5342\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5070 - val_loss: 0.5323\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5032 - val_loss: 0.5382\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5020 - val_loss: 0.5385\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5046 - val_loss: 0.5415\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.4978 - val_loss: 0.5304\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4948 - val_loss: 0.5358\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4955 - val_loss: 0.5323\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4922 - val_loss: 0.5304\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4940 - val_loss: 0.5278\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4892 - val_loss: 0.5375\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4824 - val_loss: 0.5308\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4811 - val_loss: 0.5209\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4791 - val_loss: 0.5321\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4803 - val_loss: 0.5245\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4788 - val_loss: 0.5289\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4793 - val_loss: 0.5293\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4748 - val_loss: 0.5267\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4732 - val_loss: 0.5250\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4702 - val_loss: 0.5310\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4700 - val_loss: 0.5160\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4683 - val_loss: 0.5256\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4669 - val_loss: 0.5332\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4671 - val_loss: 0.5261\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4649 - val_loss: 0.5210\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4657 - val_loss: 0.5199\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4634 - val_loss: 0.5240\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4656 - val_loss: 0.5160\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4644 - val_loss: 0.5243\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4658 - val_loss: 0.5244\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4587 - val_loss: 0.5259\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4550 - val_loss: 0.5353\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4573 - val_loss: 0.5227\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4550 - val_loss: 0.5206\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4564 - val_loss: 0.5259\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4542 - val_loss: 0.5299\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4548 - val_loss: 0.5238\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4513 - val_loss: 0.5273\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4556 - val_loss: 0.5224\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4509 - val_loss: 0.5179\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4493 - val_loss: 0.5171\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 9ms/step - loss: 0.8952 - val_loss: 0.7573\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7744 - val_loss: 0.7005\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7342 - val_loss: 0.6714\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7058 - val_loss: 0.6503\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6873 - val_loss: 0.6343\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6695 - val_loss: 0.6402\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6586 - val_loss: 0.6184\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6194\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6389 - val_loss: 0.6115\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6334 - val_loss: 0.6117\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6273 - val_loss: 0.6130\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6067\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6040\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6065 - val_loss: 0.5953\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6014 - val_loss: 0.5995\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5981 - val_loss: 0.5953\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5947 - val_loss: 0.5980\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5906 - val_loss: 0.5971\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5878 - val_loss: 0.5967\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.5941\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5779 - val_loss: 0.5824\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5743 - val_loss: 0.5924\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5706 - val_loss: 0.5822\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5688 - val_loss: 0.5727\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5682 - val_loss: 0.5724\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5601 - val_loss: 0.5762\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5600 - val_loss: 0.5689\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5582 - val_loss: 0.5695\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5565 - val_loss: 0.5729\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5555 - val_loss: 0.5579\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5525 - val_loss: 0.5799\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5488 - val_loss: 0.5630\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5408 - val_loss: 0.5619\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5364 - val_loss: 0.5595\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5307 - val_loss: 0.5545\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5284 - val_loss: 0.5562\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5240 - val_loss: 0.5664\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5238 - val_loss: 0.5534\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5210 - val_loss: 0.5491\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.5548\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5155 - val_loss: 0.5419\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5125 - val_loss: 0.5475\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5093 - val_loss: 0.5439\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5034 - val_loss: 0.5409\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5038 - val_loss: 0.5483\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4987 - val_loss: 0.5560\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4957 - val_loss: 0.5580\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4944 - val_loss: 0.5404\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4926 - val_loss: 0.5473\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4881 - val_loss: 0.5541\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4899 - val_loss: 0.5457\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4884 - val_loss: 0.5430\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4835 - val_loss: 0.5451\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4917 - val_loss: 0.5499\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4870 - val_loss: 0.5435\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4878 - val_loss: 0.5420\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4795 - val_loss: 0.5413\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4750 - val_loss: 0.5379\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4740 - val_loss: 0.5334\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4731 - val_loss: 0.5368\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4735 - val_loss: 0.5354\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4705 - val_loss: 0.5383\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4699 - val_loss: 0.5397\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4690 - val_loss: 0.5450\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4676 - val_loss: 0.5405\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4632 - val_loss: 0.5316\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4657 - val_loss: 0.5422\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4639 - val_loss: 0.5456\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4612 - val_loss: 0.5450\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4658 - val_loss: 0.5380\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4679 - val_loss: 0.5341\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4606 - val_loss: 0.5282\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4582 - val_loss: 0.5454\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4593 - val_loss: 0.5336\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4573 - val_loss: 0.5318\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4525 - val_loss: 0.5332\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4529 - val_loss: 0.5371\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4527 - val_loss: 0.5353\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4508 - val_loss: 0.5359\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4500 - val_loss: 0.5396\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4482 - val_loss: 0.5372\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4471 - val_loss: 0.5409\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4488 - val_loss: 0.5304\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4488 - val_loss: 0.5324\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4479 - val_loss: 0.5394\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4479 - val_loss: 0.5456\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4447 - val_loss: 0.5389\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4448 - val_loss: 0.5356\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4443 - val_loss: 0.5347\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4421 - val_loss: 0.5343\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4398 - val_loss: 0.5356\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4389 - val_loss: 0.5421\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 10ms/step - loss: 0.9047 - val_loss: 0.7508\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7523 - val_loss: 0.7172\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.7009 - val_loss: 0.6925\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6638 - val_loss: 0.6753\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6459 - val_loss: 0.6758\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6356 - val_loss: 0.6735\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6278 - val_loss: 0.6666\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.6673\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.6634\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6598\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6097 - val_loss: 0.6567\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6015 - val_loss: 0.6539\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5966 - val_loss: 0.6606\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5950 - val_loss: 0.6546\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5900 - val_loss: 0.6519\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5850 - val_loss: 0.6449\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5787 - val_loss: 0.6421\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5735 - val_loss: 0.6348\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5689 - val_loss: 0.6359\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5705 - val_loss: 0.6336\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5648 - val_loss: 0.6328\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5615 - val_loss: 0.6195\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5516 - val_loss: 0.6240\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5458 - val_loss: 0.6199\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5421 - val_loss: 0.6171\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5425 - val_loss: 0.6212\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5331 - val_loss: 0.6113\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5303 - val_loss: 0.6095\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5255 - val_loss: 0.6067\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5202 - val_loss: 0.6088\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5145 - val_loss: 0.6037\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5131 - val_loss: 0.6110\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5127 - val_loss: 0.5987\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5151 - val_loss: 0.6072\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5136 - val_loss: 0.6067\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5041 - val_loss: 0.6013\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4979 - val_loss: 0.6052\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4949 - val_loss: 0.5990\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4926 - val_loss: 0.5938\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4877 - val_loss: 0.5972\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4882 - val_loss: 0.5940\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4853 - val_loss: 0.5975\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4879 - val_loss: 0.5918\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4845 - val_loss: 0.6027\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4817 - val_loss: 0.5957\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4809 - val_loss: 0.5935\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4784 - val_loss: 0.5929\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4771 - val_loss: 0.5833\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4722 - val_loss: 0.6020\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4735 - val_loss: 0.5943\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4669 - val_loss: 0.6034\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4715 - val_loss: 0.5913\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4758 - val_loss: 0.5938\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4700 - val_loss: 0.5909\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4639 - val_loss: 0.5956\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4604 - val_loss: 0.5924\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4583 - val_loss: 0.5884\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4580 - val_loss: 0.5907\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4584 - val_loss: 0.5943\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4559 - val_loss: 0.5924\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4544 - val_loss: 0.5909\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4549 - val_loss: 0.5903\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4516 - val_loss: 0.5902\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4534 - val_loss: 0.5884\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4503 - val_loss: 0.5888\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4477 - val_loss: 0.5901\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4447 - val_loss: 0.5887\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4431 - val_loss: 0.5823\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4405 - val_loss: 0.5884\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4394 - val_loss: 0.5877\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4413 - val_loss: 0.6044\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4473 - val_loss: 0.6023\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4443 - val_loss: 0.5923\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.4420 - val_loss: 0.5878\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4402 - val_loss: 0.5874\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4351 - val_loss: 0.5879\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4364 - val_loss: 0.5930\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4345 - val_loss: 0.5892\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4326 - val_loss: 0.5921\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4338 - val_loss: 0.5836\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4346 - val_loss: 0.5890\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4296 - val_loss: 0.5916\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4285 - val_loss: 0.5996\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4256 - val_loss: 0.5791\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4244 - val_loss: 0.5914\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4233 - val_loss: 0.5794\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4244 - val_loss: 0.5896\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4249 - val_loss: 0.5876\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4262 - val_loss: 0.5981\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4249 - val_loss: 0.5878\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4232 - val_loss: 0.5985\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4319 - val_loss: 0.5886\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4290 - val_loss: 0.5846\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4239 - val_loss: 0.5859\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4231 - val_loss: 0.5934\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4182 - val_loss: 0.5856\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4229 - val_loss: 0.5901\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4267 - val_loss: 0.5899\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4317 - val_loss: 0.5998\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4270 - val_loss: 0.5810\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4148 - val_loss: 0.5958\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4122 - val_loss: 0.5851\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4122 - val_loss: 0.5815\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4100 - val_loss: 0.5858\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 12ms/step - loss: 0.8817 - val_loss: 0.6957\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7743 - val_loss: 0.6770\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7575 - val_loss: 0.6567\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7492 - val_loss: 0.6853\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7656 - val_loss: 0.6718\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7547 - val_loss: 0.6554\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7437 - val_loss: 0.6563\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7341 - val_loss: 0.6455\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7335 - val_loss: 0.6491\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7341 - val_loss: 0.6482\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7308 - val_loss: 0.6427\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7296 - val_loss: 0.6428\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7270 - val_loss: 0.6622\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7305 - val_loss: 0.6498\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7275 - val_loss: 0.6421\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7281 - val_loss: 0.6456\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7301 - val_loss: 0.6512\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7318 - val_loss: 0.6475\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7251 - val_loss: 0.6449\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7276 - val_loss: 0.6409\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7322 - val_loss: 0.6667\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7358 - val_loss: 0.6470\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7274 - val_loss: 0.6433\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7226 - val_loss: 0.6395\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7213 - val_loss: 0.6417\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7233 - val_loss: 0.6496\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.7262 - val_loss: 0.6428\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7220 - val_loss: 0.6390\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7198 - val_loss: 0.6453\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7213 - val_loss: 0.6442\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7216 - val_loss: 0.6421\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.7426 - val_loss: 0.6501\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7612 - val_loss: 0.6476\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7380 - val_loss: 0.6446\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7313 - val_loss: 0.6425\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7307 - val_loss: 0.6811\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7339 - val_loss: 0.6407\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7219 - val_loss: 0.6391\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7196 - val_loss: 0.6390\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7198 - val_loss: 0.6420\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7186 - val_loss: 0.6390\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7190 - val_loss: 0.6462\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7272 - val_loss: 0.6441\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7201 - val_loss: 0.6422\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7199 - val_loss: 0.6434\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7192 - val_loss: 0.6419\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7191 - val_loss: 0.6406\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7178 - val_loss: 0.6428\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.7216 - val_loss: 0.6420\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7197 - val_loss: 0.6420\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7187 - val_loss: 0.6412\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7204 - val_loss: 0.6420\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7177 - val_loss: 0.6412\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7180 - val_loss: 0.6418\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7345 - val_loss: 0.6518\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7257 - val_loss: 0.6463\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7232 - val_loss: 0.6425\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7192 - val_loss: 0.6412\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7191 - val_loss: 0.6479\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2234s 4ms/step - loss: 0.8947 - val_loss: 0.7657\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8028 - val_loss: 0.7332\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7837 - val_loss: 0.7103\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7608 - val_loss: 0.7048\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7517 - val_loss: 0.6961\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7464 - val_loss: 0.6841\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7383 - val_loss: 0.6852\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7428 - val_loss: 0.6892\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7362 - val_loss: 0.6814\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7307 - val_loss: 0.6746\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.7331 - val_loss: 0.6853\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7410 - val_loss: 0.6842\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7341 - val_loss: 0.6853\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7320 - val_loss: 0.6777\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7260 - val_loss: 0.6778\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7301 - val_loss: 0.7069\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7434 - val_loss: 0.6773\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7293 - val_loss: 0.6836\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7289 - val_loss: 0.6781\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7369 - val_loss: 0.6830\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7321 - val_loss: 0.6879\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7294 - val_loss: 0.6791\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7285 - val_loss: 0.6801\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7252 - val_loss: 0.6768\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7268 - val_loss: 0.6772\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7284 - val_loss: 0.6774\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7286 - val_loss: 0.6767\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7335 - val_loss: 0.6819\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7347 - val_loss: 0.6755\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7265 - val_loss: 0.6760\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 3s 8ms/step - loss: 0.9080 - val_loss: 0.7626\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7972 - val_loss: 0.7570\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7884 - val_loss: 0.7508\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7669 - val_loss: 0.7308\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7593 - val_loss: 0.7357\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7518 - val_loss: 0.7554\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7615 - val_loss: 0.7373\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7420 - val_loss: 0.7208\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7344 - val_loss: 0.7345\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7414 - val_loss: 0.7301\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7425 - val_loss: 0.7353\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7339 - val_loss: 0.7278\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7316 - val_loss: 0.7325\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7322 - val_loss: 0.7287\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7321 - val_loss: 0.7257\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7309 - val_loss: 0.7279\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7275 - val_loss: 0.7234\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7262 - val_loss: 0.7254\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7254 - val_loss: 0.7276\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7264 - val_loss: 0.7268\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7319 - val_loss: 0.7332\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7375 - val_loss: 0.7300\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7472 - val_loss: 0.7307\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7418 - val_loss: 0.7477\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7493 - val_loss: 0.7304\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7305 - val_loss: 0.7316\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7277 - val_loss: 0.7329\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7285 - val_loss: 0.7326\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 10ms/step - loss: 0.8769 - val_loss: 0.6800\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7696 - val_loss: 0.6625\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7429 - val_loss: 0.6428\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7190 - val_loss: 0.6370\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6336\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6693 - val_loss: 0.6592\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6655 - val_loss: 0.6165\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6423 - val_loss: 0.6067\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6551 - val_loss: 0.6244\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6464 - val_loss: 0.5957\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6213 - val_loss: 0.5915\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6379 - val_loss: 0.6244\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6716 - val_loss: 0.6133\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6470 - val_loss: 0.6131\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6699 - val_loss: 0.5766\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6291 - val_loss: 0.5882\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6339 - val_loss: 0.6775\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.5947\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.5664\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5876 - val_loss: 0.5624\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5763 - val_loss: 0.5684\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5799 - val_loss: 0.5727\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5702 - val_loss: 0.5539\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.5784\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5947 - val_loss: 0.5533\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5816 - val_loss: 0.5826\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5555 - val_loss: 0.5944\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5654 - val_loss: 0.5745\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5757 - val_loss: 0.5753\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5776 - val_loss: 0.5871\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5710 - val_loss: 0.5638\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5714 - val_loss: 0.5753\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5683 - val_loss: 0.5668\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5677 - val_loss: 0.5461\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5496 - val_loss: 0.5616\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5436 - val_loss: 0.5470\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5434 - val_loss: 0.5516\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5505 - val_loss: 0.5501\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5413 - val_loss: 0.5585\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5430 - val_loss: 0.5618\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5361 - val_loss: 0.5662\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5261 - val_loss: 0.5575\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5184 - val_loss: 0.5664\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5251 - val_loss: 0.5473\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5583 - val_loss: 0.5613\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5444 - val_loss: 0.5780\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5334 - val_loss: 0.5442\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5760 - val_loss: 0.5624\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5333 - val_loss: 0.5448\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5345 - val_loss: 0.5407\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5125 - val_loss: 0.5407\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5179 - val_loss: 0.5583\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5301 - val_loss: 0.5529\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5178 - val_loss: 0.5589\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5171 - val_loss: 0.5185\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4995 - val_loss: 0.5457\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4929 - val_loss: 0.5434\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4869 - val_loss: 0.5401\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4934 - val_loss: 0.5263\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4828 - val_loss: 0.5358\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4826 - val_loss: 0.5304\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4828 - val_loss: 0.5416\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4907 - val_loss: 0.5420\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4881 - val_loss: 0.5258\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.5411\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5178 - val_loss: 0.5283\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5014 - val_loss: 0.5919\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.5029 - val_loss: 0.5350\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5045 - val_loss: 0.5274\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5014 - val_loss: 0.5534\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5019 - val_loss: 0.5130\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5179 - val_loss: 0.5455\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5085 - val_loss: 0.5570\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5150 - val_loss: 0.5737\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5379 - val_loss: 0.5370\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5374 - val_loss: 0.5476\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5043 - val_loss: 0.5273\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4851 - val_loss: 0.5300\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4876 - val_loss: 0.5407\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4966 - val_loss: 0.5221\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4807 - val_loss: 0.5352\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4742 - val_loss: 0.5200\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4716 - val_loss: 0.5141\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4710 - val_loss: 0.5132\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4640 - val_loss: 0.5197\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4686 - val_loss: 0.5264\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4753 - val_loss: 0.5308\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4964 - val_loss: 0.5442\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4797 - val_loss: 0.5263\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4671 - val_loss: 0.5203\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4665 - val_loss: 0.5190\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 10ms/step - loss: 0.9234 - val_loss: 0.7716\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8214 - val_loss: 0.7189\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7737 - val_loss: 0.7184\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7623 - val_loss: 0.6932\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7288 - val_loss: 0.6587\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7127 - val_loss: 0.6900\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7207 - val_loss: 0.7191\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7327 - val_loss: 0.6715\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6912 - val_loss: 0.6607\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6737 - val_loss: 0.6306\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6633 - val_loss: 0.6347\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6494 - val_loss: 0.6376\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6475 - val_loss: 0.6637\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6732 - val_loss: 0.6645\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6591 - val_loss: 0.6318\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6386 - val_loss: 0.6413\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6443 - val_loss: 0.6582\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6337 - val_loss: 0.6542\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6387 - val_loss: 0.6463\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6207\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6046 - val_loss: 0.6260\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5916 - val_loss: 0.6355\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.6240 - val_loss: 0.6312\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6355 - val_loss: 0.6664\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6287\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5909 - val_loss: 0.6181\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.6098\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.6173\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5943 - val_loss: 0.6181\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6047 - val_loss: 0.6206\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6071 - val_loss: 0.6145\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5920 - val_loss: 0.6214\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5843 - val_loss: 0.6197\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6033 - val_loss: 0.6064\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5806 - val_loss: 0.6127\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5661 - val_loss: 0.6172\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5601 - val_loss: 0.6271\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5826 - val_loss: 0.6123\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5590 - val_loss: 0.6093\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5587 - val_loss: 0.5980\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5678 - val_loss: 0.6034\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5889 - val_loss: 0.6147\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5720 - val_loss: 0.5929\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5539 - val_loss: 0.6076\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5428 - val_loss: 0.5936\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5664 - val_loss: 0.6004\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5483 - val_loss: 0.6258\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5387 - val_loss: 0.5930\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5580 - val_loss: 0.6260\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5627 - val_loss: 0.5812\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5750 - val_loss: 0.6195\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5848 - val_loss: 0.6291\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5837 - val_loss: 0.6165\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5834 - val_loss: 0.6072\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5876 - val_loss: 0.5952\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5661 - val_loss: 0.5974\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5518 - val_loss: 0.6199\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5589 - val_loss: 0.5927\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5447 - val_loss: 0.5977\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5367 - val_loss: 0.5767\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5216 - val_loss: 0.5914\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5300 - val_loss: 0.5757\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5279 - val_loss: 0.5822\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5202 - val_loss: 0.5744\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5158 - val_loss: 0.5670\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5101 - val_loss: 0.5826\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5186 - val_loss: 0.5950\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5219 - val_loss: 0.6091\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5357 - val_loss: 0.5789\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.5835\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5216 - val_loss: 0.5689\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5279 - val_loss: 0.6384\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5354 - val_loss: 0.5653\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5149 - val_loss: 0.5684\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5010 - val_loss: 0.5550\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5081 - val_loss: 0.5832\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5052 - val_loss: 0.5681\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5086 - val_loss: 0.5723\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4910 - val_loss: 0.5775\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5071 - val_loss: 0.5560\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4988 - val_loss: 0.5707\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5141 - val_loss: 0.6191\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5028 - val_loss: 0.5694\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5297 - val_loss: 0.5819\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5145 - val_loss: 0.5926\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5253 - val_loss: 0.5825\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5254 - val_loss: 0.5570\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4895 - val_loss: 0.5534\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5110 - val_loss: 0.5745\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4993 - val_loss: 0.5803\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4834 - val_loss: 0.5498\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4805 - val_loss: 0.5457\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4735 - val_loss: 0.5417\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4832 - val_loss: 0.5646\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4852 - val_loss: 0.5570\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4694 - val_loss: 0.5501\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4644 - val_loss: 0.5545\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4824 - val_loss: 0.5597\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5061 - val_loss: 0.5721\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4829 - val_loss: 0.5918\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4902 - val_loss: 0.5630\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4738 - val_loss: 0.6085\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4875 - val_loss: 0.5725\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4823 - val_loss: 0.5693\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4894 - val_loss: 0.5988\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5036 - val_loss: 0.5584\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4856 - val_loss: 0.5544\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4694 - val_loss: 0.5448\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4696 - val_loss: 0.5569\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4633 - val_loss: 0.5640\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4530 - val_loss: 0.5402\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4490 - val_loss: 0.5498\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4482 - val_loss: 0.5689\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4536 - val_loss: 0.5477\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4427 - val_loss: 0.5500\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4507 - val_loss: 0.5434\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4480 - val_loss: 0.5695\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4486 - val_loss: 0.5586\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4537 - val_loss: 0.5487\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4459 - val_loss: 0.5574\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4452 - val_loss: 0.5502\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4353 - val_loss: 0.5752\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4445 - val_loss: 0.5568\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4628 - val_loss: 0.5892\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5059 - val_loss: 0.5950\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4848 - val_loss: 0.5663\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4602 - val_loss: 0.5487\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4470 - val_loss: 0.5437\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4762 - val_loss: 0.5532\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4597 - val_loss: 0.5764\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4716 - val_loss: 0.5501\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 11ms/step - loss: 0.9300 - val_loss: 0.7949\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8467 - val_loss: 0.7789\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7768 - val_loss: 0.7423\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 0.7251\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7220 - val_loss: 0.7054\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7053 - val_loss: 0.6915\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7001 - val_loss: 0.7339\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.6992\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6905 - val_loss: 0.6765\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6907 - val_loss: 0.7000\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6654 - val_loss: 0.6580\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6409 - val_loss: 0.6696\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.6719\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6346 - val_loss: 0.6569\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6225 - val_loss: 0.6326\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6316 - val_loss: 0.6429\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6137 - val_loss: 0.6434\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6248 - val_loss: 0.6358\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6904\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6357 - val_loss: 0.6422\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6495\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.6024 - val_loss: 0.6426\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6160 - val_loss: 0.6419\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6390\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5975 - val_loss: 0.6340\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5925 - val_loss: 0.6457\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5916 - val_loss: 0.6315\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5835 - val_loss: 0.6325\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5817 - val_loss: 0.6250\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6053 - val_loss: 0.6421\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6014 - val_loss: 0.6510\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6191 - val_loss: 0.6671\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6361 - val_loss: 0.6481\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6167 - val_loss: 0.6306\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5757 - val_loss: 0.6142\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5800 - val_loss: 0.6312\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.6194\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5790 - val_loss: 0.6221\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5900 - val_loss: 0.6385\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5815 - val_loss: 0.6187\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5917 - val_loss: 0.6200\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5793 - val_loss: 0.6133\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5674 - val_loss: 0.6516\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5726 - val_loss: 0.5995\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5505 - val_loss: 0.6068\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5493 - val_loss: 0.6005\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5400 - val_loss: 0.5982\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5432 - val_loss: 0.6004\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5697 - val_loss: 0.6267\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6134 - val_loss: 0.6681\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5629 - val_loss: 0.6006\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5545 - val_loss: 0.6053\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5571 - val_loss: 0.5885\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5736 - val_loss: 0.6148\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5545 - val_loss: 0.5923\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5439 - val_loss: 0.5961\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5452 - val_loss: 0.5959\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5400 - val_loss: 0.5954\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5290 - val_loss: 0.5846\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5332 - val_loss: 0.5806\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5247 - val_loss: 0.5810\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5348 - val_loss: 0.5892\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5386 - val_loss: 0.5996\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5302 - val_loss: 0.6035\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5240 - val_loss: 0.5967\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5160 - val_loss: 0.5889\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5167 - val_loss: 0.5936\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5161 - val_loss: 0.5811\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5094 - val_loss: 0.5810\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5055 - val_loss: 0.5784\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5261 - val_loss: 0.5939\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5254 - val_loss: 0.5941\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5530 - val_loss: 0.5986\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5487 - val_loss: 0.6045\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5477 - val_loss: 0.5992\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5466 - val_loss: 0.5797\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5436 - val_loss: 0.6047\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5144 - val_loss: 0.5810\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5142 - val_loss: 0.5800\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5072 - val_loss: 0.5771\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5110 - val_loss: 0.6010\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4995 - val_loss: 0.5722\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5004 - val_loss: 0.5810\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5115 - val_loss: 0.5778\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5014 - val_loss: 0.5837\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4891 - val_loss: 0.5733\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4873 - val_loss: 0.5880\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4780 - val_loss: 0.5593\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4870 - val_loss: 0.5806\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5029 - val_loss: 0.6047\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5213 - val_loss: 0.5854\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5467 - val_loss: 0.5748\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5137 - val_loss: 0.5902\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5521 - val_loss: 0.6030\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5202 - val_loss: 0.5928\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5098 - val_loss: 0.5748\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5114 - val_loss: 0.5672\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4969 - val_loss: 0.5701\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4995 - val_loss: 0.5747\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4872 - val_loss: 0.5840\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4886 - val_loss: 0.5634\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4846 - val_loss: 0.5758\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4985 - val_loss: 0.5964\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5216 - val_loss: 0.6159\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5239 - val_loss: 0.6823\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5355 - val_loss: 0.6034\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.5040 - val_loss: 0.5951\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4870 - val_loss: 0.5820\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.9244 - val_loss: 0.7852\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8252 - val_loss: 0.7064\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7729 - val_loss: 0.7229\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7592 - val_loss: 0.6732\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7294 - val_loss: 0.6325\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7153 - val_loss: 0.6805\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7264 - val_loss: 0.6358\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6751 - val_loss: 0.6377\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.5964\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6369 - val_loss: 0.6114\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6465 - val_loss: 0.6118\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6549 - val_loss: 0.6011\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6478 - val_loss: 0.6373\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6133 - val_loss: 0.5778\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.5723\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5784 - val_loss: 0.5640\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5796 - val_loss: 0.5823\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5656 - val_loss: 0.5633\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5674 - val_loss: 0.5814\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5941 - val_loss: 0.6037\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5892 - val_loss: 0.5671\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5732 - val_loss: 0.5861\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5502 - val_loss: 0.5457\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5402 - val_loss: 0.5688\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5488 - val_loss: 0.5706\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5888 - val_loss: 0.5514\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5740 - val_loss: 0.5609\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5549 - val_loss: 0.5490\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5471 - val_loss: 0.5696\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5530 - val_loss: 0.5565\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5420 - val_loss: 0.5768\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5213 - val_loss: 0.5627\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5302 - val_loss: 0.5822\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5383 - val_loss: 0.5616\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5303 - val_loss: 0.5491\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5125 - val_loss: 0.5330\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5004 - val_loss: 0.5427\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4986 - val_loss: 0.5156\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4950 - val_loss: 0.5231\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5054 - val_loss: 0.5378\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5083 - val_loss: 0.5386\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5076 - val_loss: 0.5683\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5108 - val_loss: 0.5417\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4930 - val_loss: 0.5349\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4857 - val_loss: 0.6533\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5916 - val_loss: 0.5503\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5138 - val_loss: 0.5513\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5006 - val_loss: 0.5204\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4801 - val_loss: 0.5204\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4607 - val_loss: 0.5200\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4576 - val_loss: 0.5285\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4696 - val_loss: 0.5336\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4650 - val_loss: 0.5293\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4745 - val_loss: 0.5454\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4820 - val_loss: 0.5240\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5823 - val_loss: 0.6089\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5503 - val_loss: 0.5632\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5147 - val_loss: 0.5475\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.9430 - val_loss: 0.7870\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7888 - val_loss: 0.7053\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7354 - val_loss: 0.6977\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7206 - val_loss: 0.6712\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7134 - val_loss: 0.6642\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7172 - val_loss: 0.6787\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6998 - val_loss: 0.6669\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6755 - val_loss: 0.6390\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6606 - val_loss: 0.6275\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6438 - val_loss: 0.6365\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6214 - val_loss: 0.6087\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6090 - val_loss: 0.6315\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.6264\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6073 - val_loss: 0.6261\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5895 - val_loss: 0.5989\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.5993\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5819 - val_loss: 0.5925\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6386 - val_loss: 0.6527\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5852 - val_loss: 0.5940\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5651 - val_loss: 0.6234\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5651 - val_loss: 0.5905\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5545 - val_loss: 0.5766\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5485 - val_loss: 0.5873\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5623 - val_loss: 0.5925\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5526 - val_loss: 0.5869\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5483 - val_loss: 0.5857\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5382 - val_loss: 0.5947\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5407 - val_loss: 0.5778\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5167 - val_loss: 0.5840\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5324 - val_loss: 0.5671\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5128 - val_loss: 0.5741\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5339 - val_loss: 0.5701\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5499 - val_loss: 0.5795\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5320 - val_loss: 0.5818\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5211 - val_loss: 0.5685\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4947 - val_loss: 0.5633\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4898 - val_loss: 0.5699\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4957 - val_loss: 0.5601\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5188 - val_loss: 0.5654\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4999 - val_loss: 0.5557\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5412 - val_loss: 0.5539\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4970 - val_loss: 0.5456\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4927 - val_loss: 0.5833\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4849 - val_loss: 0.5690\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4864 - val_loss: 0.5498\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4751 - val_loss: 0.5515\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4829 - val_loss: 0.5478\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4681 - val_loss: 0.5493\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4616 - val_loss: 0.5407\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4547 - val_loss: 0.5425\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4588 - val_loss: 0.5528\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4651 - val_loss: 0.5450\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4913 - val_loss: 0.5654\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5331 - val_loss: 0.5574\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4930 - val_loss: 0.5538\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4654 - val_loss: 0.5547\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4505 - val_loss: 0.5467\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4522 - val_loss: 0.5511\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4491 - val_loss: 0.5544\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4553 - val_loss: 0.5424\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4818 - val_loss: 0.5526\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4685 - val_loss: 0.5824\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4706 - val_loss: 0.5583\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5062 - val_loss: 0.6000\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4751 - val_loss: 0.5550\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4641 - val_loss: 0.5509\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4358 - val_loss: 0.5429\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4292 - val_loss: 0.5298\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4218 - val_loss: 0.5418\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4218 - val_loss: 0.5381\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4171 - val_loss: 0.5329\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4167 - val_loss: 0.5473\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4197 - val_loss: 0.5454\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4307 - val_loss: 0.5598\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4200 - val_loss: 0.5451\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4184 - val_loss: 0.5435\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4198 - val_loss: 0.5592\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4182 - val_loss: 0.5517\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4239 - val_loss: 0.5705\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4202 - val_loss: 0.5517\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4194 - val_loss: 0.5673\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4185 - val_loss: 0.5620\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4081 - val_loss: 0.5515\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4048 - val_loss: 0.5490\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4011 - val_loss: 0.5459\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4034 - val_loss: 0.5537\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4253 - val_loss: 0.5806\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4542 - val_loss: 0.5842\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 8ms/step - loss: 0.9388 - val_loss: 0.7916\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8192 - val_loss: 0.7499\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7501 - val_loss: 0.6887\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7179 - val_loss: 0.6915\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6818 - val_loss: 0.6683\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6804 - val_loss: 0.6925\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6432 - val_loss: 0.6476\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6448 - val_loss: 0.6635\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6396 - val_loss: 0.6303\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6046 - val_loss: 0.6226\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6055 - val_loss: 0.6240\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5936 - val_loss: 0.6467\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6160\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5780 - val_loss: 0.6292\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5724 - val_loss: 0.6217\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5772 - val_loss: 0.6259\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5561 - val_loss: 0.6050\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5580 - val_loss: 0.6083\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5581 - val_loss: 0.6122\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5513 - val_loss: 0.6151\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5639 - val_loss: 0.6186\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5715 - val_loss: 0.6004\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5439 - val_loss: 0.6242\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5566 - val_loss: 0.6061\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5212 - val_loss: 0.5967\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5374 - val_loss: 0.6060\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5309 - val_loss: 0.6065\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5248 - val_loss: 0.6177\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5137 - val_loss: 0.5878\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5259 - val_loss: 0.6045\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5140 - val_loss: 0.6188\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5082 - val_loss: 0.5948\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5095 - val_loss: 0.6016\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5020 - val_loss: 0.6070\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5154 - val_loss: 0.6049\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5047 - val_loss: 0.6110\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5368 - val_loss: 0.6573\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5817 - val_loss: 0.6261\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5300 - val_loss: 0.5950\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4882 - val_loss: 0.5983\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4789 - val_loss: 0.5903\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4753 - val_loss: 0.5891\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4784 - val_loss: 0.5931\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5056 - val_loss: 0.6043\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4848 - val_loss: 0.5907\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4858 - val_loss: 0.5928\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4789 - val_loss: 0.5947\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4861 - val_loss: 0.6074\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4965 - val_loss: 0.5942\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 11ms/step - loss: 0.8404 - val_loss: 0.6714\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7557 - val_loss: 0.6578\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7149 - val_loss: 0.6189\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6912 - val_loss: 0.6166\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6787 - val_loss: 0.6301\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6863 - val_loss: 0.6348\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6737 - val_loss: 0.6317\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.6074\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6935 - val_loss: 0.6532\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6846 - val_loss: 0.6215\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6524 - val_loss: 0.6000\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6395 - val_loss: 0.6065\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6646 - val_loss: 0.6584\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.6199\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6752 - val_loss: 0.6195\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.5894\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.5939\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6341 - val_loss: 0.5993\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6626 - val_loss: 0.6244\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6428 - val_loss: 0.5913\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6488 - val_loss: 0.6436\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.6011\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6128\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6259 - val_loss: 0.6082\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 0.5977\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.5859\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6086 - val_loss: 0.5840\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5944 - val_loss: 0.5771\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5901 - val_loss: 0.5890\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6096 - val_loss: 0.6129\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6107 - val_loss: 0.5933\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5917 - val_loss: 0.5772\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.5885\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.5864\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.5809\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5991 - val_loss: 0.5902\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5835 - val_loss: 0.5692\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5816 - val_loss: 0.6149\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6031 - val_loss: 0.5950\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5825 - val_loss: 0.5849\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6026 - val_loss: 0.6169\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.5936\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6217 - val_loss: 0.6060\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6016 - val_loss: 0.5760\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6050 - val_loss: 0.5841\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5860 - val_loss: 0.5933\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.5930\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5704 - val_loss: 0.6006\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5702 - val_loss: 0.5838\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5573 - val_loss: 0.5965\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5813 - val_loss: 0.5751\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5610 - val_loss: 0.5672\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5627 - val_loss: 0.5781\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5714 - val_loss: 0.5839\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5564 - val_loss: 0.5977\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5672 - val_loss: 0.5585\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5511 - val_loss: 0.5485\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5615 - val_loss: 0.5902\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5733 - val_loss: 0.5439\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5449 - val_loss: 0.5526\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5360 - val_loss: 0.5519\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5424 - val_loss: 0.5649\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5473 - val_loss: 0.5593\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5339 - val_loss: 0.5549\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5338 - val_loss: 0.5684\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5450 - val_loss: 0.5605\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5381 - val_loss: 0.5411\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5372 - val_loss: 0.5554\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5533 - val_loss: 0.5793\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5330 - val_loss: 0.5679\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5283 - val_loss: 0.5531\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5371 - val_loss: 0.5494\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5122 - val_loss: 0.5543\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5108 - val_loss: 0.5475\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5198 - val_loss: 0.5598\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5393 - val_loss: 0.6047\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5459 - val_loss: 0.5638\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5419 - val_loss: 0.5897\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5413 - val_loss: 0.5868\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5589 - val_loss: 0.5800\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5454 - val_loss: 0.5813\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5410 - val_loss: 0.5905\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5602 - val_loss: 0.5888\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5559 - val_loss: 0.5623\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5365 - val_loss: 0.5726\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5339 - val_loss: 0.5770\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5392 - val_loss: 0.5500\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.8727 - val_loss: 0.7457\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7982 - val_loss: 0.7095\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7469 - val_loss: 0.6869\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7540 - val_loss: 0.6985\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7312 - val_loss: 0.7349\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7258 - val_loss: 0.7017\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7201 - val_loss: 0.6834\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6958 - val_loss: 0.6580\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.6520\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7085 - val_loss: 0.6808\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6773 - val_loss: 0.6454\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6758 - val_loss: 0.6691\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6885 - val_loss: 0.6706\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6819 - val_loss: 0.6526\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6721 - val_loss: 0.6593\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6602 - val_loss: 0.6944\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.6315\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6321\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6406 - val_loss: 0.6262\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.6228\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6561 - val_loss: 0.6781\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6723 - val_loss: 0.6438\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6747 - val_loss: 0.7050\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.6838\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7057 - val_loss: 0.7089\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6871 - val_loss: 0.6600\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6600 - val_loss: 0.6392\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6567 - val_loss: 0.6375\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6521 - val_loss: 0.6551\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6960 - val_loss: 0.6607\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.6234\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6182\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6249 - val_loss: 0.6134\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6146 - val_loss: 0.6223\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6060\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6243\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6430\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5987 - val_loss: 0.6046\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5986 - val_loss: 0.5971\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6163 - val_loss: 0.6354\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6198 - val_loss: 0.6178\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.6421\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.6447\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6163 - val_loss: 0.6187\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5976 - val_loss: 0.6463\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5963 - val_loss: 0.6142\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5866 - val_loss: 0.6005\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6122 - val_loss: 0.6354\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.6686\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5953 - val_loss: 0.6162\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5972 - val_loss: 0.6120\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5943 - val_loss: 0.6341\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5866 - val_loss: 0.6081\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5810 - val_loss: 0.6019\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5742 - val_loss: 0.6059\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5724 - val_loss: 0.6130\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5946 - val_loss: 0.6228\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.6240\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5694 - val_loss: 0.6128\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 0.8549 - val_loss: 0.7583\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7686 - val_loss: 0.7430\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7214 - val_loss: 0.7173\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7298 - val_loss: 0.7028\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6824 - val_loss: 0.7010\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.6715\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6723 - val_loss: 0.6715\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6717 - val_loss: 0.6767\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6729 - val_loss: 0.6597\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6613 - val_loss: 0.6785\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6652 - val_loss: 0.7021\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7043 - val_loss: 0.6801\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6844 - val_loss: 0.6806\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6729 - val_loss: 0.6832\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6431 - val_loss: 0.6682\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6663 - val_loss: 0.6576\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6322 - val_loss: 0.6712\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6661\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.6403 - val_loss: 0.6547\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6580 - val_loss: 0.6553\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6294 - val_loss: 0.6385\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6253 - val_loss: 0.6527\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6340\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.6353\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6355\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6361 - val_loss: 0.6456\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6175 - val_loss: 0.6365\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.6193\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6080 - val_loss: 0.6396\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6056 - val_loss: 0.6334\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6740\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6361 - val_loss: 0.6726\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6310\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6235 - val_loss: 0.6484\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6215 - val_loss: 0.6414\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6026 - val_loss: 0.6481\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.6452\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6163 - val_loss: 0.6478\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.6235\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5908 - val_loss: 0.6483\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.6300\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5932 - val_loss: 0.6186\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.6676\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6259\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5787 - val_loss: 0.6297\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5924 - val_loss: 0.6288\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5663 - val_loss: 0.6253\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5726 - val_loss: 0.6172\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6226 - val_loss: 0.6623\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6283\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5779 - val_loss: 0.6133\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5717 - val_loss: 0.6470\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5929 - val_loss: 0.6309\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6301\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5762 - val_loss: 0.6450\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5789 - val_loss: 0.6288\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5745 - val_loss: 0.6232\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5669 - val_loss: 0.6085\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5500 - val_loss: 0.6215\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5546 - val_loss: 0.6107\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5549 - val_loss: 0.6063\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5687 - val_loss: 0.6172\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6458 - val_loss: 0.6274\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.6333\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5551 - val_loss: 0.6352\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5588 - val_loss: 0.6492\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5709 - val_loss: 0.6346\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5659 - val_loss: 0.6468\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6070 - val_loss: 0.6355\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6222 - val_loss: 0.6386\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5757 - val_loss: 0.6330\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5745 - val_loss: 0.6143\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5527 - val_loss: 0.6186\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5571 - val_loss: 0.6184\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5369 - val_loss: 0.6158\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5399 - val_loss: 0.6160\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5585 - val_loss: 0.6340\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5470 - val_loss: 0.6353\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 66s 745ms/step - loss: 0.5460 - val_loss: 0.6155\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5478 - val_loss: 0.6073\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5282 - val_loss: 0.6098\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 12ms/step - loss: 0.8856 - val_loss: 0.7118\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7829 - val_loss: 0.6731\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7623 - val_loss: 0.6692\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7567 - val_loss: 0.6536\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7439 - val_loss: 0.6566\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7393 - val_loss: 0.6515\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7388 - val_loss: 0.6482\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7349 - val_loss: 0.6491\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7344 - val_loss: 0.6525\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.6485\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7328 - val_loss: 0.6483\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7311 - val_loss: 0.6442\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7303 - val_loss: 0.6414\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7276 - val_loss: 0.6443\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7287 - val_loss: 0.6465\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7287 - val_loss: 0.6437\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7270 - val_loss: 0.6449\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7243 - val_loss: 0.6402\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7255 - val_loss: 0.6489\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.6460\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7243 - val_loss: 0.6452\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7239 - val_loss: 0.6424\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7221 - val_loss: 0.6405\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7207 - val_loss: 0.6388\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 0.6448\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7296 - val_loss: 0.6462\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.6423\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7213 - val_loss: 0.6395\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7195 - val_loss: 0.6376\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7195 - val_loss: 0.6391\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7205 - val_loss: 0.6399\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7228 - val_loss: 0.6430\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.6398\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7184 - val_loss: 0.6401\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7187 - val_loss: 0.6410\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7195 - val_loss: 0.6409\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7200 - val_loss: 0.6413\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7192 - val_loss: 0.6433\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.6403\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.6433\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7184 - val_loss: 0.6417\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7216 - val_loss: 0.6503\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7252 - val_loss: 0.6423\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7200 - val_loss: 0.6403\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7185 - val_loss: 0.6402\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7172 - val_loss: 0.6390\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7170 - val_loss: 0.6397\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7175 - val_loss: 0.6419\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7182 - val_loss: 0.6413\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.8907 - val_loss: 0.7544\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7855 - val_loss: 0.7023\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7674 - val_loss: 0.7025\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7744 - val_loss: 0.6983\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.6914\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7465 - val_loss: 0.6874\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7446 - val_loss: 0.6895\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7422 - val_loss: 0.6908\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7407 - val_loss: 0.6891\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7382 - val_loss: 0.6788\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7347 - val_loss: 0.6763\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7342 - val_loss: 0.6820\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7360 - val_loss: 0.6821\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7338 - val_loss: 0.6816\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7314 - val_loss: 0.6791\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7296 - val_loss: 0.6804\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7344 - val_loss: 0.6806\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7315 - val_loss: 0.6781\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7281 - val_loss: 0.6819\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7289 - val_loss: 0.6764\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7271 - val_loss: 0.6778\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7267 - val_loss: 0.6762\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7252 - val_loss: 0.6806\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.6744\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7268 - val_loss: 0.6805\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7277 - val_loss: 0.6781\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7269 - val_loss: 0.6777\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7275 - val_loss: 0.6780\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7253 - val_loss: 0.6794\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7252 - val_loss: 0.6767\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7244 - val_loss: 0.6775\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7233 - val_loss: 0.6746\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7237 - val_loss: 0.6755\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7229 - val_loss: 0.6757\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 0.6748\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7234 - val_loss: 0.6741\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7234 - val_loss: 0.6750\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7223 - val_loss: 0.6734\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 0.6754\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7221 - val_loss: 0.6758\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7223 - val_loss: 0.6750\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7227 - val_loss: 0.6746\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.6777\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7225 - val_loss: 0.6749\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7223 - val_loss: 0.6762\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7234 - val_loss: 0.6794\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.6738\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7236 - val_loss: 0.6754\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 0.6747\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7220 - val_loss: 0.6748\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.6745\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7217 - val_loss: 0.6740\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7211 - val_loss: 0.6744\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7207 - val_loss: 0.6737\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7203 - val_loss: 0.6730\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7201 - val_loss: 0.6723\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7212 - val_loss: 0.6737\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.6721\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.6746\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7216 - val_loss: 0.6740\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.6796\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7232 - val_loss: 0.6745\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 0.6752\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 0.6740\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7197 - val_loss: 0.6761\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7210 - val_loss: 0.6738\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.6729\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7204 - val_loss: 0.6741\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.6727\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7196 - val_loss: 0.6733\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7198 - val_loss: 0.6708\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7203 - val_loss: 0.6728\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7195 - val_loss: 0.6710\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7188 - val_loss: 0.6716\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6720\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7204 - val_loss: 0.6732\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7197 - val_loss: 0.6748\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7205 - val_loss: 0.6759\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7202 - val_loss: 0.6746\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.6731\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7188 - val_loss: 0.6729\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6727\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7208 - val_loss: 0.6728\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7187 - val_loss: 0.6725\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7188 - val_loss: 0.6719\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6714\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7190 - val_loss: 0.6728\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6718\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7202 - val_loss: 0.6735\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6713\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7181 - val_loss: 0.6709\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.8852 - val_loss: 0.7774\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7817 - val_loss: 0.7587\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7653 - val_loss: 0.7513\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7565 - val_loss: 0.7421\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7585 - val_loss: 0.7687\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7640 - val_loss: 0.7567\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 0.7438\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7450 - val_loss: 0.7421\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7438 - val_loss: 0.7420\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7429 - val_loss: 0.7429\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7455 - val_loss: 0.7436\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7411 - val_loss: 0.7413\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7372 - val_loss: 0.7372\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7331 - val_loss: 0.7291\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7322 - val_loss: 0.7316\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7324 - val_loss: 0.7340\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7298 - val_loss: 0.7348\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7325 - val_loss: 0.7319\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7350 - val_loss: 0.7353\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7355 - val_loss: 0.7307\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7343 - val_loss: 0.7312\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7268 - val_loss: 0.7245\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7262 - val_loss: 0.7293\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7251 - val_loss: 0.7264\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7243 - val_loss: 0.7256\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7233 - val_loss: 0.7260\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7244 - val_loss: 0.7267\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7240 - val_loss: 0.7278\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7251 - val_loss: 0.7255\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7249 - val_loss: 0.7264\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7265 - val_loss: 0.7270\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7237 - val_loss: 0.7248\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7225 - val_loss: 0.7255\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7253 - val_loss: 0.7247\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7241 - val_loss: 0.7289\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7248 - val_loss: 0.7301\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.7234\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7230 - val_loss: 0.7249\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7225 - val_loss: 0.7228\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7221 - val_loss: 0.7220\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7215 - val_loss: 0.7213\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7211 - val_loss: 0.7239\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.7244\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7214 - val_loss: 0.7251\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7224 - val_loss: 0.7225\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7251 - val_loss: 0.7265\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7275 - val_loss: 0.7272\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7238 - val_loss: 0.7223\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7255 - val_loss: 0.7259\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 0.7231\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7213 - val_loss: 0.7213\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7205 - val_loss: 0.7224\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 0.7249\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 0.7246\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.7244\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.7218\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.7219\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7204 - val_loss: 0.7217\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.7213\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7203 - val_loss: 0.7218\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.7244\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.7238\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7207 - val_loss: 0.7228\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.7232\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7207 - val_loss: 0.7228\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.7222\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7208 - val_loss: 0.7227\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7204 - val_loss: 0.7216\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.7229\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 0.7236\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7208 - val_loss: 0.7234\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7200 - val_loss: 0.7238\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7221 - val_loss: 0.7245\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7204 - val_loss: 0.7219\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7197 - val_loss: 0.7224\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7210 - val_loss: 0.7258\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 0.7220\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7206 - val_loss: 0.7227\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 0.7237\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 5s 10ms/step - loss: 0.8554 - val_loss: 0.6790\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7320 - val_loss: 0.6474\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7097 - val_loss: 0.6918\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7029 - val_loss: 0.6286\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6731 - val_loss: 0.6273\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6788 - val_loss: 0.6613\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6923 - val_loss: 0.6365\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6943 - val_loss: 0.6521\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6018\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6388 - val_loss: 0.5900\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.5973\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6652 - val_loss: 0.6198\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6371 - val_loss: 0.6063\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6195 - val_loss: 0.6425\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6434 - val_loss: 0.6457\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6145\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6156 - val_loss: 0.5988\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.5883\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6193 - val_loss: 0.5732\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6421 - val_loss: 0.6118\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6469 - val_loss: 0.5993\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6058 - val_loss: 0.5888\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6170 - val_loss: 0.5891\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6219 - val_loss: 0.6125\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6596 - val_loss: 0.6056\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6138 - val_loss: 0.5911\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.5660\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5793 - val_loss: 0.5795\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5792 - val_loss: 0.5804\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5762 - val_loss: 0.5975\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5916 - val_loss: 0.5772\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5868 - val_loss: 0.5722\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.5887\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5781 - val_loss: 0.5738\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5678 - val_loss: 0.5750\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5786 - val_loss: 0.5982\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5796 - val_loss: 0.5904\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5706 - val_loss: 0.5805\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5799 - val_loss: 0.5825\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5591 - val_loss: 0.5575\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5533 - val_loss: 0.5558\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5497 - val_loss: 0.5422\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.6744\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.6699\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5984 - val_loss: 0.5832\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.5508\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5687 - val_loss: 0.5690\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5692 - val_loss: 0.5687\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5751 - val_loss: 0.5801\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5514 - val_loss: 0.5730\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5510 - val_loss: 0.5578\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5494 - val_loss: 0.5632\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5598 - val_loss: 0.5519\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5327 - val_loss: 0.5847\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5638 - val_loss: 0.5906\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5748 - val_loss: 0.5663\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5480 - val_loss: 0.5795\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5606 - val_loss: 0.5523\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5422 - val_loss: 0.5941\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5749 - val_loss: 0.6015\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.5744\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5838 - val_loss: 0.5674\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.8536 - val_loss: 0.7369\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7770 - val_loss: 0.6888\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7218 - val_loss: 0.6675\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6910 - val_loss: 0.6553\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6630\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6623 - val_loss: 0.6656\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6867 - val_loss: 0.6838\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6763 - val_loss: 0.6368\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6417\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6552 - val_loss: 0.6840\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6699 - val_loss: 0.6345\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6503 - val_loss: 0.6294\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6338 - val_loss: 0.6379\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6182 - val_loss: 0.6122\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6469 - val_loss: 0.6570\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6161\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.6158\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6392 - val_loss: 0.6069\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6369\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6112 - val_loss: 0.6208\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6027 - val_loss: 0.6074\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6044 - val_loss: 0.6154\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5989 - val_loss: 0.6185\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5811 - val_loss: 0.5973\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5988 - val_loss: 0.6289\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6494 - val_loss: 0.6192\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.6308\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6191 - val_loss: 0.6486\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5867 - val_loss: 0.5949\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.6355\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6037 - val_loss: 0.6046\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.6230\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.6102\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5784 - val_loss: 0.5882\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5856 - val_loss: 0.5898\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5564 - val_loss: 0.5863\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6052 - val_loss: 0.6130\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5889 - val_loss: 0.6193\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5944 - val_loss: 0.6261\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5757 - val_loss: 0.5973\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.5697\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5589 - val_loss: 0.5811\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5400 - val_loss: 0.5897\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5480 - val_loss: 0.5644\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5394 - val_loss: 0.5687\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5435 - val_loss: 0.5728\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5420 - val_loss: 0.5583\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5278 - val_loss: 0.5682\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5313 - val_loss: 0.5781\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5301 - val_loss: 0.5925\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5597 - val_loss: 0.6090\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5894 - val_loss: 0.6316\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5601 - val_loss: 0.5804\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5542 - val_loss: 0.5881\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5275 - val_loss: 0.5508\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5295 - val_loss: 0.5792\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5503 - val_loss: 0.5623\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5498 - val_loss: 0.5660\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5369 - val_loss: 0.5704\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5233 - val_loss: 0.5658\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5262 - val_loss: 0.5630\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5253 - val_loss: 0.5611\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5114 - val_loss: 0.5581\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5104 - val_loss: 0.5772\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4992 - val_loss: 0.5458\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5059 - val_loss: 0.5758\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5458 - val_loss: 0.5560\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5230 - val_loss: 0.5845\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5380 - val_loss: 0.5626\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5118 - val_loss: 0.5385\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.5095 - val_loss: 0.5654\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5214 - val_loss: 0.6311\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5230 - val_loss: 0.5537\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5096 - val_loss: 0.5449\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5089 - val_loss: 0.5588\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5010 - val_loss: 0.5352\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5066 - val_loss: 0.5597\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5481 - val_loss: 0.5531\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5313 - val_loss: 0.5632\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5649 - val_loss: 0.5814\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5502 - val_loss: 0.5869\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5373 - val_loss: 0.5421\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5095 - val_loss: 0.5374\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5076 - val_loss: 0.5471\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4944 - val_loss: 0.5537\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5177 - val_loss: 0.5598\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5079 - val_loss: 0.5431\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4953 - val_loss: 0.5498\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4873 - val_loss: 0.5314\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4905 - val_loss: 0.5491\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4752 - val_loss: 0.5298\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4807 - val_loss: 0.5251\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4922 - val_loss: 0.5504\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4778 - val_loss: 0.5320\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4824 - val_loss: 0.5299\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.4742 - val_loss: 0.5348\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4802 - val_loss: 0.5759\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5038 - val_loss: 0.5503\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5042 - val_loss: 0.5385\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4913 - val_loss: 0.5356\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5319 - val_loss: 0.6017\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5526 - val_loss: 0.5792\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5285 - val_loss: 0.5789\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5075 - val_loss: 0.5688\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5132 - val_loss: 0.5513\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5016 - val_loss: 0.5403\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.4970 - val_loss: 0.5385\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4953 - val_loss: 0.5649\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5455 - val_loss: 0.5528\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5242 - val_loss: 0.5412\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5064 - val_loss: 0.5312\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5049 - val_loss: 0.5296\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 9ms/step - loss: 0.8579 - val_loss: 0.7422\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7566 - val_loss: 0.7196\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7503 - val_loss: 0.7084\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7202 - val_loss: 0.6880\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7210 - val_loss: 0.7285\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7011 - val_loss: 0.6853\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6814 - val_loss: 0.6971\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7176 - val_loss: 0.6637\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 0.6928\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6762 - val_loss: 0.6775\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6554 - val_loss: 0.6742\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6336 - val_loss: 0.6397\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6262 - val_loss: 0.6665\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6346 - val_loss: 0.6494\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6570\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6103 - val_loss: 0.6347\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.6378\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6046 - val_loss: 0.6313\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6065 - val_loss: 0.6439\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6442 - val_loss: 0.6588\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6217 - val_loss: 0.6489\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.6361\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6024 - val_loss: 0.6298\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6177 - val_loss: 0.6355\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6272 - val_loss: 0.6362\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6389 - val_loss: 0.6376\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6075 - val_loss: 0.6533\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6038 - val_loss: 0.6158\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5909 - val_loss: 0.6278\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5913 - val_loss: 0.6068\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.6328\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5951 - val_loss: 0.6338\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5955 - val_loss: 0.6421\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6216 - val_loss: 0.6409\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6125 - val_loss: 0.6370\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.6336\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6018 - val_loss: 0.6256\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5976 - val_loss: 0.6169\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.6175\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5817 - val_loss: 0.6252\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.6163\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.6076\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5897 - val_loss: 0.6248\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6159 - val_loss: 0.6281\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.6237\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5884 - val_loss: 0.6050\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5660 - val_loss: 0.6035\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5663 - val_loss: 0.6214\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.5992\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5771 - val_loss: 0.6033\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5746 - val_loss: 0.5936\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5867 - val_loss: 0.6006\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5860 - val_loss: 0.5992\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5897 - val_loss: 0.6158\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5885 - val_loss: 0.6123\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5736 - val_loss: 0.6123\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5744 - val_loss: 0.6064\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5729 - val_loss: 0.6170\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.6168\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5705 - val_loss: 0.6113\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5530 - val_loss: 0.6156\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5722 - val_loss: 0.6161\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5505 - val_loss: 0.5944\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5478 - val_loss: 0.6120\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5590 - val_loss: 0.6014\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5564 - val_loss: 0.6082\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5381 - val_loss: 0.5867\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5498 - val_loss: 0.6190\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5737 - val_loss: 0.6074\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5810 - val_loss: 0.6154\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5531 - val_loss: 0.5989\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5464 - val_loss: 0.6058\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5364 - val_loss: 0.5899\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5406 - val_loss: 0.5951\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5466 - val_loss: 0.6124\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5720 - val_loss: 0.5881\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5513 - val_loss: 0.6190\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5718 - val_loss: 0.6211\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5631 - val_loss: 0.6425\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5612 - val_loss: 0.6217\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5483 - val_loss: 0.6085\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5411 - val_loss: 0.6025\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5452 - val_loss: 0.6041\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5591 - val_loss: 0.5919\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5471 - val_loss: 0.6460\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5465 - val_loss: 0.6046\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5514 - val_loss: 0.6001\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 1.0151 - val_loss: 0.8067\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8915 - val_loss: 0.7797\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8596 - val_loss: 0.7727\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8475 - val_loss: 0.7504\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8251 - val_loss: 0.7441\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8333 - val_loss: 0.7382\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8221 - val_loss: 0.7257\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8176 - val_loss: 0.7402\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8147 - val_loss: 0.7163\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8112 - val_loss: 0.7365\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8014 - val_loss: 0.7232\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7973 - val_loss: 0.7164\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7936 - val_loss: 0.7122\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7885 - val_loss: 0.7209\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7788 - val_loss: 0.7054\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7746 - val_loss: 0.7212\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7781 - val_loss: 0.6991\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7815 - val_loss: 0.7000\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7715 - val_loss: 0.6969\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7697 - val_loss: 0.7167\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7671 - val_loss: 0.6993\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7821 - val_loss: 0.6869\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7680 - val_loss: 0.6937\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7584 - val_loss: 0.6912\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7714 - val_loss: 0.6911\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7671 - val_loss: 0.7020\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7591 - val_loss: 0.6831\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7486 - val_loss: 0.6868\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.6952\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7445 - val_loss: 0.6791\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7632 - val_loss: 0.6815\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.6894\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7345 - val_loss: 0.6920\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7415 - val_loss: 0.6816\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7341 - val_loss: 0.6885\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7442 - val_loss: 0.6729\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7294 - val_loss: 0.6912\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7418 - val_loss: 0.6858\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7304 - val_loss: 0.6856\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7211 - val_loss: 0.6823\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7316 - val_loss: 0.6781\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.6918\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7301 - val_loss: 0.6744\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7247 - val_loss: 0.7436\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7213 - val_loss: 0.6780\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7196 - val_loss: 0.6836\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7211 - val_loss: 0.6985\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7214 - val_loss: 0.7069\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7187 - val_loss: 0.6931\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7173 - val_loss: 0.6902\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7237 - val_loss: 0.6761\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7152 - val_loss: 0.6894\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7166 - val_loss: 0.6900\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7368 - val_loss: 0.6837\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7335 - val_loss: 0.6943\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7134 - val_loss: 0.6782\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 1.1055 - val_loss: 0.9966\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0306 - val_loss: 0.9645\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0104 - val_loss: 0.9556\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0059 - val_loss: 0.9546\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9552\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0054 - val_loss: 0.9557\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0054 - val_loss: 0.9561\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9564\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 1.0053 - val_loss: 0.9567\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9569\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9570\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9570\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9573\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9574\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9575\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.0053 - val_loss: 0.9575\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9575\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0052 - val_loss: 0.9576\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9577\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9578\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.0053 - val_loss: 0.9577\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9577\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 1.0053 - val_loss: 0.9578\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0053 - val_loss: 0.9581\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 4s 10ms/step - loss: 1.0757 - val_loss: 0.8651\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8753 - val_loss: 0.7890\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8100 - val_loss: 0.7655\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7816 - val_loss: 0.7957\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7668 - val_loss: 0.7304\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7205 - val_loss: 0.7299\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.7225 - val_loss: 0.7149\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.6991\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 0.6768\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.6772\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7315 - val_loss: 0.6922\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6951 - val_loss: 0.7007\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6849 - val_loss: 0.6787\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.6762\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.6817\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6783 - val_loss: 0.7045\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6681 - val_loss: 0.6826\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6482 - val_loss: 0.6661\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6468 - val_loss: 0.6733\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.7271\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6454 - val_loss: 0.6543\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.6254 - val_loss: 0.6543\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6235 - val_loss: 0.6652\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6308 - val_loss: 0.6426\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6400 - val_loss: 0.6509\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.6560\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6163 - val_loss: 0.6426\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6111 - val_loss: 0.6427\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6103 - val_loss: 0.6441\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6016 - val_loss: 0.6338\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.6313\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 0.6452\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5894 - val_loss: 0.6341\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6341 - val_loss: 0.6432\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6169 - val_loss: 0.6267\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5943 - val_loss: 0.6329\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.7469\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6297 - val_loss: 0.6434\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6005 - val_loss: 0.6242\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5944 - val_loss: 0.6456\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5954 - val_loss: 0.6729\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6215\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6023 - val_loss: 0.6521\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.6470\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5800 - val_loss: 0.7099\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.6299\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5921 - val_loss: 0.6502\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5924 - val_loss: 0.6594\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5888 - val_loss: 0.6448\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5967 - val_loss: 0.6424\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5873 - val_loss: 0.6327\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.6193\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5921 - val_loss: 0.6367\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5890 - val_loss: 0.6187\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.6219\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6050 - val_loss: 0.6313\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6184 - val_loss: 0.6378\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5776 - val_loss: 0.6368\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5943 - val_loss: 0.6347\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5649 - val_loss: 0.6341\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5590 - val_loss: 0.6348\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5635 - val_loss: 0.6168\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5639 - val_loss: 0.6476\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5899 - val_loss: 0.6125\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5689 - val_loss: 0.6281\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5591 - val_loss: 0.6128\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5858 - val_loss: 0.6299\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5641 - val_loss: 0.6157\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5521 - val_loss: 0.6413\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5504 - val_loss: 0.6154\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5380 - val_loss: 0.6262\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5404 - val_loss: 0.6316\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5487 - val_loss: 0.6185\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.6517\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5625 - val_loss: 0.6243\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5460 - val_loss: 0.6211\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5366 - val_loss: 0.6716\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5457 - val_loss: 0.6205\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5517 - val_loss: 0.6146\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5610 - val_loss: 0.6900\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6052 - val_loss: 0.6381\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5769 - val_loss: 0.6194\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5842 - val_loss: 0.6724\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5740 - val_loss: 0.6483\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.8227 - val_loss: 0.6489\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7196 - val_loss: 0.6234\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6649 - val_loss: 0.5944\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6489 - val_loss: 0.5985\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6326 - val_loss: 0.5962\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6189 - val_loss: 0.5810\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6113 - val_loss: 0.5767\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.5817\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.5750\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5994 - val_loss: 0.5732\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 0.5654\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5842 - val_loss: 0.5777\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5781 - val_loss: 0.5733\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 0.5898\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5843 - val_loss: 0.5658\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5776 - val_loss: 0.5720\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5628 - val_loss: 0.5606\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5586 - val_loss: 0.5581\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5553 - val_loss: 0.5526\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5528 - val_loss: 0.5689\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5523 - val_loss: 0.5517\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5467 - val_loss: 0.5461\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5467 - val_loss: 0.5555\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5494 - val_loss: 0.5846\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5487 - val_loss: 0.5366\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5349 - val_loss: 0.5518\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5376 - val_loss: 0.5509\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5289 - val_loss: 0.5512\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5440 - val_loss: 0.5616\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5378 - val_loss: 0.5553\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5309 - val_loss: 0.5437\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5227 - val_loss: 0.5422\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5181 - val_loss: 0.5433\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5230 - val_loss: 0.5395\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5093 - val_loss: 0.5421\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5083 - val_loss: 0.5394\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5047 - val_loss: 0.5419\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5053 - val_loss: 0.5566\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5060 - val_loss: 0.5331\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5117 - val_loss: 0.5450\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4992 - val_loss: 0.5465\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4964 - val_loss: 0.5352\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4905 - val_loss: 0.5335\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4949 - val_loss: 0.5558\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4994 - val_loss: 0.5322\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4914 - val_loss: 0.5361\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4865 - val_loss: 0.5411\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4847 - val_loss: 0.5305\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4819 - val_loss: 0.5369\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4752 - val_loss: 0.5233\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4776 - val_loss: 0.5451\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4778 - val_loss: 0.5569\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4866 - val_loss: 0.5443\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4768 - val_loss: 0.5331\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4722 - val_loss: 0.5414\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4765 - val_loss: 0.5480\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4723 - val_loss: 0.5216\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4696 - val_loss: 0.5211\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4664 - val_loss: 0.5407\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4666 - val_loss: 0.5360\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4637 - val_loss: 0.5250\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4629 - val_loss: 0.5297\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4602 - val_loss: 0.5418\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4610 - val_loss: 0.5309\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4533 - val_loss: 0.5519\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4575 - val_loss: 0.5257\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4544 - val_loss: 0.5252\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4572 - val_loss: 0.5268\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4518 - val_loss: 0.5329\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4535 - val_loss: 0.5377\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4618 - val_loss: 0.5396\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4546 - val_loss: 0.5363\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4541 - val_loss: 0.5289\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4518 - val_loss: 0.5293\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4458 - val_loss: 0.5238\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4409 - val_loss: 0.5213\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4400 - val_loss: 0.5273\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4389 - val_loss: 0.5279\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.8267 - val_loss: 0.6900\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7232 - val_loss: 0.6651\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6825 - val_loss: 0.6372\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6637 - val_loss: 0.6266\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6495 - val_loss: 0.6336\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6352 - val_loss: 0.6092\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6342 - val_loss: 0.6221\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 0.6178 - val_loss: 0.6216\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6078 - val_loss: 0.6170\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6054\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5991 - val_loss: 0.5980\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.5981\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5963 - val_loss: 0.6128\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5936 - val_loss: 0.5937\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5899 - val_loss: 0.5893\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5882 - val_loss: 0.6076\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5786 - val_loss: 0.5979\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5785 - val_loss: 0.5788\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5700 - val_loss: 0.6031\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5676 - val_loss: 0.5857\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5613 - val_loss: 0.5826\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5606 - val_loss: 0.5788\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5570 - val_loss: 0.5686\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5523 - val_loss: 0.5766\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5611 - val_loss: 0.6065\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5550 - val_loss: 0.5802\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5405 - val_loss: 0.5812\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5346 - val_loss: 0.5743\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5334 - val_loss: 0.5808\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5319 - val_loss: 0.5760\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5353 - val_loss: 0.5694\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5413 - val_loss: 0.5797\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5272 - val_loss: 0.5710\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5281 - val_loss: 0.5685\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5185 - val_loss: 0.5680\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5092 - val_loss: 0.5631\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5100 - val_loss: 0.5660\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5061 - val_loss: 0.5651\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5188 - val_loss: 0.5729\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5092 - val_loss: 0.5515\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4954 - val_loss: 0.5472\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4919 - val_loss: 0.5544\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4906 - val_loss: 0.5409\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4879 - val_loss: 0.5428\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4906 - val_loss: 0.5638\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4995 - val_loss: 0.5697\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5013 - val_loss: 0.5606\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4979 - val_loss: 0.5673\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4875 - val_loss: 0.5580\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4795 - val_loss: 0.5472\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4786 - val_loss: 0.5359\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4699 - val_loss: 0.5507\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4736 - val_loss: 0.5482\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4733 - val_loss: 0.5504\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4746 - val_loss: 0.5442\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4636 - val_loss: 0.5494\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4675 - val_loss: 0.5394\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4671 - val_loss: 0.5343\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4593 - val_loss: 0.5329\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4585 - val_loss: 0.5335\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4594 - val_loss: 0.5349\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4588 - val_loss: 0.5395\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4557 - val_loss: 0.5352\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4513 - val_loss: 0.5310\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4514 - val_loss: 0.5236\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4569 - val_loss: 0.5255\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4523 - val_loss: 0.5407\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4488 - val_loss: 0.5511\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4518 - val_loss: 0.5224\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4489 - val_loss: 0.5455\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4443 - val_loss: 0.5447\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4382 - val_loss: 0.5299\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4388 - val_loss: 0.5246\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4442 - val_loss: 0.5181\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4485 - val_loss: 0.5229\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4529 - val_loss: 0.5260\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4369 - val_loss: 0.5170\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4338 - val_loss: 0.5238\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4378 - val_loss: 0.5244\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4385 - val_loss: 0.5229\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4326 - val_loss: 0.5298\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4305 - val_loss: 0.5195\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4288 - val_loss: 0.5302\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4260 - val_loss: 0.5324\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4311 - val_loss: 0.5218\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4300 - val_loss: 0.5242\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4303 - val_loss: 0.5307\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4242 - val_loss: 0.5273\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4235 - val_loss: 0.5219\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4234 - val_loss: 0.5224\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4215 - val_loss: 0.5258\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4187 - val_loss: 0.5250\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4198 - val_loss: 0.5219\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4226 - val_loss: 0.5388\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4246 - val_loss: 0.5291\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4217 - val_loss: 0.5214\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4205 - val_loss: 0.5339\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.8202 - val_loss: 0.7649\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7195 - val_loss: 0.6904\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6801 - val_loss: 0.6706\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6793 - val_loss: 0.6817\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6548 - val_loss: 0.6747\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6376 - val_loss: 0.6704\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6256 - val_loss: 0.6770\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6267 - val_loss: 0.6539\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6224 - val_loss: 0.6628\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6179 - val_loss: 0.6514\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5936 - val_loss: 0.6431\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5852 - val_loss: 0.6409\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5809 - val_loss: 0.6292\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5785 - val_loss: 0.6424\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5765 - val_loss: 0.6321\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5713 - val_loss: 0.6264\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5646 - val_loss: 0.6427\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5644 - val_loss: 0.6331\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5637 - val_loss: 0.6342\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5557 - val_loss: 0.6228\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5514 - val_loss: 0.6192\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5545 - val_loss: 0.6205\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5538 - val_loss: 0.6337\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5436 - val_loss: 0.6227\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5429 - val_loss: 0.6192\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5476 - val_loss: 0.6363\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5399 - val_loss: 0.6224\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5415 - val_loss: 0.6199\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5362 - val_loss: 0.6235\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 0.6349\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5528 - val_loss: 0.6246\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5364 - val_loss: 0.6076\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5278 - val_loss: 0.6215\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5373 - val_loss: 0.6112\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5149 - val_loss: 0.6171\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5149 - val_loss: 0.6117\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5137 - val_loss: 0.6136\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5159 - val_loss: 0.6081\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5101 - val_loss: 0.6147\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5024 - val_loss: 0.6061\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5056 - val_loss: 0.6076\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5083 - val_loss: 0.6036\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4933 - val_loss: 0.6082\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4998 - val_loss: 0.6084\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4903 - val_loss: 0.6058\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4874 - val_loss: 0.5910\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4867 - val_loss: 0.6053\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4852 - val_loss: 0.6101\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4876 - val_loss: 0.5957\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4864 - val_loss: 0.6062\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4872 - val_loss: 0.5976\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4853 - val_loss: 0.5968\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4880 - val_loss: 0.5948\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4791 - val_loss: 0.6014\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4759 - val_loss: 0.5997\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4749 - val_loss: 0.5944\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4741 - val_loss: 0.6071\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4743 - val_loss: 0.5948\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4706 - val_loss: 0.5949\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4692 - val_loss: 0.5901\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4629 - val_loss: 0.5970\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4618 - val_loss: 0.5880\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4652 - val_loss: 0.5962\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4687 - val_loss: 0.5802\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4753 - val_loss: 0.6104\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4666 - val_loss: 0.5883\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4560 - val_loss: 0.5911\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4517 - val_loss: 0.5884\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4592 - val_loss: 0.6128\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4585 - val_loss: 0.6006\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4520 - val_loss: 0.5874\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4494 - val_loss: 0.6033\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4477 - val_loss: 0.5846\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4459 - val_loss: 0.5984\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4424 - val_loss: 0.5959\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4424 - val_loss: 0.5933\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4455 - val_loss: 0.5920\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4479 - val_loss: 0.5977\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4433 - val_loss: 0.5974\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4404 - val_loss: 0.6040\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4421 - val_loss: 0.6017\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4342 - val_loss: 0.6012\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4427 - val_loss: 0.6026\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4418 - val_loss: 0.6083\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 5ms/step - loss: 0.9384 - val_loss: 0.7636\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.8346 - val_loss: 0.7409\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7995 - val_loss: 0.6950\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7511 - val_loss: 0.6678\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7259 - val_loss: 0.6543\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7091 - val_loss: 0.6412\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6985 - val_loss: 0.6382\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6864 - val_loss: 0.6241\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6781 - val_loss: 0.6390\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6715 - val_loss: 0.6127\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6598 - val_loss: 0.6067\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6539 - val_loss: 0.6031\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6442 - val_loss: 0.6004\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6367 - val_loss: 0.5925\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6309 - val_loss: 0.5897\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6252 - val_loss: 0.5952\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 0.5886\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5880\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6120 - val_loss: 0.5848\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 0.5927\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 0.5828\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 0.5803\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.5766\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.5804\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5987 - val_loss: 0.5736\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 0.5725\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5947 - val_loss: 0.5775\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5963 - val_loss: 0.5720\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 0.5713\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5918 - val_loss: 0.5725\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5941 - val_loss: 0.5710\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5908 - val_loss: 0.5703\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5904 - val_loss: 0.5713\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5900 - val_loss: 0.5717\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5877 - val_loss: 0.5715\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5872 - val_loss: 0.5704\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 0.5737\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 0.5675\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.5687\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.5688\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5858 - val_loss: 0.5678\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.5682\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5840 - val_loss: 0.5668\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5843 - val_loss: 0.5667\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5831 - val_loss: 0.5669\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.5662\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 0.5694\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 0.5703\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5827 - val_loss: 0.5669\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 0.5657\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5831 - val_loss: 0.5647\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5805 - val_loss: 0.5655\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5815 - val_loss: 0.5684\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5819 - val_loss: 0.5697\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.5782\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5878 - val_loss: 0.5661\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5821 - val_loss: 0.5729\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 0.5689\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5791 - val_loss: 0.5678\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.5676\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.5662\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5787 - val_loss: 0.5673\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 0.5625\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5785 - val_loss: 0.5639\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 0.5645\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 0.5636\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 0.5652\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5777 - val_loss: 0.5654\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5773 - val_loss: 0.5661\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 0.5732\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5794 - val_loss: 0.5654\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 0.5684\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5776 - val_loss: 0.5645\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5768 - val_loss: 0.5680\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5773 - val_loss: 0.5665\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 0.5660\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 0.5660\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.5655\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5785 - val_loss: 0.5637\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5776 - val_loss: 0.5654\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5776 - val_loss: 0.5693\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5775 - val_loss: 0.5674\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5771 - val_loss: 0.5639\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9343 - val_loss: 0.7662\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7923 - val_loss: 0.7192\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7625 - val_loss: 0.7016\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7488 - val_loss: 0.7021\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7390 - val_loss: 0.7039\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7288 - val_loss: 0.6816\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7169 - val_loss: 0.6695\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.7123 - val_loss: 0.6671\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7050 - val_loss: 0.6546\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6973 - val_loss: 0.6474\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6908 - val_loss: 0.6466\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6812 - val_loss: 0.6408\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 0.6350\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6750 - val_loss: 0.6325\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6706 - val_loss: 0.6292\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6692 - val_loss: 0.6286\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6635 - val_loss: 0.6320\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6618 - val_loss: 0.6248\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6617 - val_loss: 0.6303\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6587 - val_loss: 0.6289\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6559 - val_loss: 0.6285\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6557 - val_loss: 0.6257\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6511 - val_loss: 0.6237\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6495 - val_loss: 0.6261\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6473 - val_loss: 0.6254\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6466 - val_loss: 0.6271\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6478 - val_loss: 0.6240\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6460 - val_loss: 0.6225\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6435 - val_loss: 0.6251\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6440 - val_loss: 0.6271\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6419 - val_loss: 0.6244\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6413 - val_loss: 0.6224\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6407 - val_loss: 0.6228\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6399 - val_loss: 0.6257\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6407 - val_loss: 0.6239\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6385 - val_loss: 0.6225\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6384 - val_loss: 0.6227\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6346 - val_loss: 0.6226\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6330 - val_loss: 0.6207\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6315 - val_loss: 0.6171\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6293 - val_loss: 0.6156\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6262 - val_loss: 0.6126\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 0.6093\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6215 - val_loss: 0.6079\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.6052\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 0.6069\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.6074\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.6045\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.6048\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6146 - val_loss: 0.6046\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6125 - val_loss: 0.6016\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6021\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 0.6039\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 0.6028\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 0.6042\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 0.6068\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.6014\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6077 - val_loss: 0.6008\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6079 - val_loss: 0.6035\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 0.5993\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6037\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.5992\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6055\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6008\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.5988\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6032\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6040 - val_loss: 0.6023\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.6015\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6035 - val_loss: 0.6001\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.5997\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 0.6043\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 0.5995\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.6012\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 0.6008\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6024\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.6027\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 0.6037\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5983 - val_loss: 0.5997\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 0.6021\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5992 - val_loss: 0.6005\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 0.5996\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6026\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6014\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 0.5997\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.5995\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "90/90 [==============================] - 2s 6ms/step - loss: 0.9417 - val_loss: 0.7992\n",
      "Epoch 2/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.8156 - val_loss: 0.7654\n",
      "Epoch 3/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7717 - val_loss: 0.7655\n",
      "Epoch 4/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7584 - val_loss: 0.7508\n",
      "Epoch 5/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7474 - val_loss: 0.7479\n",
      "Epoch 6/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7358 - val_loss: 0.7377\n",
      "Epoch 7/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7244 - val_loss: 0.7334\n",
      "Epoch 8/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7109 - val_loss: 0.7263\n",
      "Epoch 9/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.7008 - val_loss: 0.7214\n",
      "Epoch 10/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6929 - val_loss: 0.7196\n",
      "Epoch 11/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6885 - val_loss: 0.7101\n",
      "Epoch 12/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6804 - val_loss: 0.7052\n",
      "Epoch 13/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6755 - val_loss: 0.6986\n",
      "Epoch 14/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6685 - val_loss: 0.6979\n",
      "Epoch 15/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6650 - val_loss: 0.6941\n",
      "Epoch 16/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6596 - val_loss: 0.6883\n",
      "Epoch 17/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6903\n",
      "Epoch 18/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6489 - val_loss: 0.6907\n",
      "Epoch 19/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6454 - val_loss: 0.6886\n",
      "Epoch 20/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6408 - val_loss: 0.6835\n",
      "Epoch 21/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6382 - val_loss: 0.6791\n",
      "Epoch 22/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6381 - val_loss: 0.6817\n",
      "Epoch 23/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6355 - val_loss: 0.6818\n",
      "Epoch 24/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6369 - val_loss: 0.6799\n",
      "Epoch 25/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6353 - val_loss: 0.6763\n",
      "Epoch 26/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6322 - val_loss: 0.6766\n",
      "Epoch 27/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6323 - val_loss: 0.6793\n",
      "Epoch 28/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6305 - val_loss: 0.6796\n",
      "Epoch 29/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6303 - val_loss: 0.6769\n",
      "Epoch 30/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6270 - val_loss: 0.6738\n",
      "Epoch 31/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 0.6747\n",
      "Epoch 32/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6266 - val_loss: 0.6713\n",
      "Epoch 33/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.6735\n",
      "Epoch 34/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6223 - val_loss: 0.6699\n",
      "Epoch 35/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 0.6718\n",
      "Epoch 36/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 0.6716\n",
      "Epoch 37/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.6689\n",
      "Epoch 38/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6667\n",
      "Epoch 39/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6162 - val_loss: 0.6673\n",
      "Epoch 40/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.6675\n",
      "Epoch 41/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6661\n",
      "Epoch 42/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6664\n",
      "Epoch 43/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6638\n",
      "Epoch 44/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 0.6660\n",
      "Epoch 45/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 0.6658\n",
      "Epoch 46/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6148 - val_loss: 0.6661\n",
      "Epoch 47/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6141 - val_loss: 0.6676\n",
      "Epoch 48/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.6630\n",
      "Epoch 49/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 0.6656\n",
      "Epoch 50/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 0.6618\n",
      "Epoch 51/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 0.6613\n",
      "Epoch 52/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6071 - val_loss: 0.6629\n",
      "Epoch 53/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 0.6613\n",
      "Epoch 54/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 0.6628\n",
      "Epoch 55/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.6607\n",
      "Epoch 56/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6065 - val_loss: 0.6614\n",
      "Epoch 57/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6077 - val_loss: 0.6584\n",
      "Epoch 58/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6070 - val_loss: 0.6609\n",
      "Epoch 59/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6049 - val_loss: 0.6583\n",
      "Epoch 60/250\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6583\n",
      "Epoch 61/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6585\n",
      "Epoch 62/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.6595\n",
      "Epoch 63/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.6588\n",
      "Epoch 64/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6047 - val_loss: 0.6642\n",
      "Epoch 65/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 0.6578\n",
      "Epoch 66/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6556\n",
      "Epoch 67/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6561\n",
      "Epoch 68/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6035 - val_loss: 0.6545\n",
      "Epoch 69/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6567\n",
      "Epoch 70/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6035 - val_loss: 0.6534\n",
      "Epoch 71/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6561\n",
      "Epoch 72/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6548\n",
      "Epoch 73/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6528\n",
      "Epoch 74/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6535\n",
      "Epoch 75/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5994 - val_loss: 0.6522\n",
      "Epoch 76/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6003 - val_loss: 0.6511\n",
      "Epoch 77/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6538\n",
      "Epoch 78/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6529\n",
      "Epoch 79/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 0.6521\n",
      "Epoch 80/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5993 - val_loss: 0.6513\n",
      "Epoch 81/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5983 - val_loss: 0.6523\n",
      "Epoch 82/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5979 - val_loss: 0.6525\n",
      "Epoch 83/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.6516\n",
      "Epoch 84/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5966 - val_loss: 0.6486\n",
      "Epoch 85/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5973 - val_loss: 0.6530\n",
      "Epoch 86/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5970 - val_loss: 0.6502\n",
      "Epoch 87/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5963 - val_loss: 0.6499\n",
      "Epoch 88/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 0.6513\n",
      "Epoch 89/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 0.6490\n",
      "Epoch 90/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5945 - val_loss: 0.6496\n",
      "Epoch 91/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5951 - val_loss: 0.6483\n",
      "Epoch 92/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5956 - val_loss: 0.6494\n",
      "Epoch 93/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5933 - val_loss: 0.6447\n",
      "Epoch 94/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5920 - val_loss: 0.6473\n",
      "Epoch 95/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5935 - val_loss: 0.6497\n",
      "Epoch 96/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 0.6489\n",
      "Epoch 97/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5928 - val_loss: 0.6453\n",
      "Epoch 98/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5913 - val_loss: 0.6459\n",
      "Epoch 99/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5907 - val_loss: 0.6470\n",
      "Epoch 100/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5899 - val_loss: 0.6467\n",
      "Epoch 101/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5921 - val_loss: 0.6438\n",
      "Epoch 102/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5940 - val_loss: 0.6518\n",
      "Epoch 103/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5924 - val_loss: 0.6446\n",
      "Epoch 104/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5886 - val_loss: 0.6419\n",
      "Epoch 105/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 0.6442\n",
      "Epoch 106/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5874 - val_loss: 0.6445\n",
      "Epoch 107/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6414\n",
      "Epoch 108/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6428\n",
      "Epoch 109/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6437\n",
      "Epoch 110/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 0.6413\n",
      "Epoch 111/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6435\n",
      "Epoch 112/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6425\n",
      "Epoch 113/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6418\n",
      "Epoch 114/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5830 - val_loss: 0.6405\n",
      "Epoch 115/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 0.6445\n",
      "Epoch 116/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 0.6424\n",
      "Epoch 117/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5834 - val_loss: 0.6426\n",
      "Epoch 118/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5852 - val_loss: 0.6430\n",
      "Epoch 119/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5840 - val_loss: 0.6429\n",
      "Epoch 120/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6394\n",
      "Epoch 121/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5835 - val_loss: 0.6418\n",
      "Epoch 122/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5840 - val_loss: 0.6391\n",
      "Epoch 123/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.6410\n",
      "Epoch 124/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5833 - val_loss: 0.6435\n",
      "Epoch 125/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5830 - val_loss: 0.6412\n",
      "Epoch 126/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.6439\n",
      "Epoch 127/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5826 - val_loss: 0.6435\n",
      "Epoch 128/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5835 - val_loss: 0.6417\n",
      "Epoch 129/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5830 - val_loss: 0.6426\n",
      "Epoch 130/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5822 - val_loss: 0.6394\n",
      "Epoch 131/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 0.6422\n",
      "Epoch 132/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5820 - val_loss: 0.6388\n",
      "Epoch 133/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5824 - val_loss: 0.6402\n",
      "Epoch 134/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5841 - val_loss: 0.6451\n",
      "Epoch 135/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6460\n",
      "Epoch 136/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.6422\n",
      "Epoch 137/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5824 - val_loss: 0.6410\n",
      "Epoch 138/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 0.6417\n",
      "Epoch 139/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5809 - val_loss: 0.6433\n",
      "Epoch 140/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5821 - val_loss: 0.6429\n",
      "Epoch 141/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5813 - val_loss: 0.6423\n",
      "Epoch 142/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5811 - val_loss: 0.6459\n",
      "Epoch 143/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5822 - val_loss: 0.6399\n",
      "Epoch 144/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5811 - val_loss: 0.6403\n",
      "Epoch 145/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5821 - val_loss: 0.6395\n",
      "Epoch 146/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5815 - val_loss: 0.6400\n",
      "Epoch 147/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5805 - val_loss: 0.6420\n",
      "Epoch 148/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 0.6425\n",
      "Epoch 149/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5806 - val_loss: 0.6404\n",
      "Epoch 150/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 0.6387\n",
      "Epoch 151/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5799 - val_loss: 0.6397\n",
      "Epoch 152/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5798 - val_loss: 0.6414\n",
      "Epoch 153/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5811 - val_loss: 0.6421\n",
      "Epoch 154/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5879 - val_loss: 0.6445\n",
      "Epoch 155/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6420\n",
      "Epoch 156/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5806 - val_loss: 0.6393\n",
      "Epoch 157/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5797 - val_loss: 0.6413\n",
      "Epoch 158/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5801 - val_loss: 0.6400\n",
      "Epoch 159/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 0.6394\n",
      "Epoch 160/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5787 - val_loss: 0.6375\n",
      "Epoch 161/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 0.6393\n",
      "Epoch 162/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5792 - val_loss: 0.6392\n",
      "Epoch 163/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 0.6408\n",
      "Epoch 164/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5798 - val_loss: 0.6399\n",
      "Epoch 165/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 0.6402\n",
      "Epoch 166/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 0.6434\n",
      "Epoch 167/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5796 - val_loss: 0.6405\n",
      "Epoch 168/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5789 - val_loss: 0.6405\n",
      "Epoch 169/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 0.6418\n",
      "Epoch 170/250\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5784 - val_loss: 0.6406\n",
      "Epoch 171/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 0.6409\n",
      "Epoch 172/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 0.6435\n",
      "Epoch 173/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5798 - val_loss: 0.6463\n",
      "Epoch 174/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.6409\n",
      "Epoch 175/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5812 - val_loss: 0.6394\n",
      "Epoch 176/250\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5799 - val_loss: 0.6400\n",
      "Epoch 177/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 0.6411\n",
      "Epoch 178/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5803 - val_loss: 0.6397\n",
      "Epoch 179/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 0.6412\n",
      "Epoch 180/250\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 0.6416\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epoch 1/250\n",
      "135/135 [==============================] - 2s 5ms/step - loss: 0.7985 - val_loss: 0.6313\n",
      "Epoch 2/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7081 - val_loss: 0.5796\n",
      "Epoch 3/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6723 - val_loss: 0.5846\n",
      "Epoch 4/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6626 - val_loss: 0.5752\n",
      "Epoch 5/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6435 - val_loss: 0.5647\n",
      "Epoch 6/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6358 - val_loss: 0.5702\n",
      "Epoch 7/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6312 - val_loss: 0.5773\n",
      "Epoch 8/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6259 - val_loss: 0.5622\n",
      "Epoch 9/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 0.5727\n",
      "Epoch 10/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 0.5614\n",
      "Epoch 11/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6104 - val_loss: 0.5516\n",
      "Epoch 12/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6077 - val_loss: 0.5529\n",
      "Epoch 13/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6047 - val_loss: 0.5631\n",
      "Epoch 14/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6083 - val_loss: 0.5514\n",
      "Epoch 15/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5942 - val_loss: 0.5684\n",
      "Epoch 16/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.5526\n",
      "Epoch 17/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 0.5309\n",
      "Epoch 18/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5834 - val_loss: 0.5405\n",
      "Epoch 19/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.5509\n",
      "Epoch 20/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.5335\n",
      "Epoch 21/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5667 - val_loss: 0.5436\n",
      "Epoch 22/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5669 - val_loss: 0.5283\n",
      "Epoch 23/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5655 - val_loss: 0.5349\n",
      "Epoch 24/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5599 - val_loss: 0.5330\n",
      "Epoch 25/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5699 - val_loss: 0.5356\n",
      "Epoch 26/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5667 - val_loss: 0.5253\n",
      "Epoch 27/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5519 - val_loss: 0.5261\n",
      "Epoch 28/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5536 - val_loss: 0.5327\n",
      "Epoch 29/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5486 - val_loss: 0.5305\n",
      "Epoch 30/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5396 - val_loss: 0.5388\n",
      "Epoch 31/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5355 - val_loss: 0.5203\n",
      "Epoch 32/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5312 - val_loss: 0.5201\n",
      "Epoch 33/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 0.5226\n",
      "Epoch 34/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5324 - val_loss: 0.5295\n",
      "Epoch 35/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5316 - val_loss: 0.5292\n",
      "Epoch 36/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5336 - val_loss: 0.5141\n",
      "Epoch 37/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5273 - val_loss: 0.5224\n",
      "Epoch 38/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5226 - val_loss: 0.5124\n",
      "Epoch 39/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5272 - val_loss: 0.5111\n",
      "Epoch 40/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5264 - val_loss: 0.5070\n",
      "Epoch 41/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5225 - val_loss: 0.5214\n",
      "Epoch 42/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5082 - val_loss: 0.5136\n",
      "Epoch 43/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5001 - val_loss: 0.5059\n",
      "Epoch 44/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4980 - val_loss: 0.4999\n",
      "Epoch 45/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5010 - val_loss: 0.5140\n",
      "Epoch 46/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4972 - val_loss: 0.5102\n",
      "Epoch 47/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4950 - val_loss: 0.5037\n",
      "Epoch 48/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5072 - val_loss: 0.5098\n",
      "Epoch 49/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5020 - val_loss: 0.4990\n",
      "Epoch 50/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4904 - val_loss: 0.5067\n",
      "Epoch 51/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4870 - val_loss: 0.4987\n",
      "Epoch 52/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4822 - val_loss: 0.5076\n",
      "Epoch 53/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4800 - val_loss: 0.4963\n",
      "Epoch 54/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4803 - val_loss: 0.5029\n",
      "Epoch 55/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4825 - val_loss: 0.5055\n",
      "Epoch 56/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4785 - val_loss: 0.5019\n",
      "Epoch 57/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4825 - val_loss: 0.5041\n",
      "Epoch 58/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4949 - val_loss: 0.5207\n",
      "Epoch 59/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4922 - val_loss: 0.5098\n",
      "Epoch 60/250\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.4755 - val_loss: 0.5029\n",
      "Epoch 61/250\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.4767 - val_loss: 0.5047\n",
      "Epoch 62/250\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.4870 - val_loss: 0.4969\n",
      "Epoch 63/250\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.4769 - val_loss: 0.4931\n",
      "Epoch 64/250\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.4697 - val_loss: 0.4995\n",
      "Epoch 65/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4781 - val_loss: 0.5033\n",
      "Epoch 66/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4703 - val_loss: 0.5007\n",
      "Epoch 67/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4652 - val_loss: 0.4974\n",
      "Epoch 68/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4579 - val_loss: 0.4938\n",
      "Epoch 69/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4569 - val_loss: 0.5001\n",
      "Epoch 70/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4541 - val_loss: 0.4973\n",
      "Epoch 71/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4545 - val_loss: 0.4922\n",
      "Epoch 72/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4551 - val_loss: 0.4992\n",
      "Epoch 73/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4575 - val_loss: 0.5048\n",
      "Epoch 74/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4571 - val_loss: 0.5030\n",
      "Epoch 75/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4596 - val_loss: 0.4953\n",
      "Epoch 76/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4645 - val_loss: 0.4974\n",
      "Epoch 77/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4625 - val_loss: 0.4929\n",
      "Epoch 78/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4539 - val_loss: 0.4898\n",
      "Epoch 79/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4542 - val_loss: 0.5067\n",
      "Epoch 80/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4583 - val_loss: 0.4939\n",
      "Epoch 81/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4493 - val_loss: 0.4990\n",
      "Epoch 82/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4495 - val_loss: 0.4972\n",
      "Epoch 83/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4488 - val_loss: 0.5009\n",
      "Epoch 84/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4501 - val_loss: 0.4990\n",
      "Epoch 85/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4465 - val_loss: 0.5022\n",
      "Epoch 86/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4475 - val_loss: 0.4929\n",
      "Epoch 87/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4458 - val_loss: 0.4946\n",
      "Epoch 88/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4439 - val_loss: 0.4999\n",
      "Epoch 89/250\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4447 - val_loss: 0.5036\n",
      "Epoch 90/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4431 - val_loss: 0.4969\n",
      "Epoch 91/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4451 - val_loss: 0.4969\n",
      "Epoch 92/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4523 - val_loss: 0.5017\n",
      "Epoch 93/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4485 - val_loss: 0.5031\n",
      "Epoch 94/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4476 - val_loss: 0.4986\n",
      "Epoch 95/250\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4441 - val_loss: 0.5067\n",
      "Epoch 96/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4427 - val_loss: 0.4998\n",
      "Epoch 97/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4464 - val_loss: 0.4984\n",
      "Epoch 98/250\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4464 - val_loss: 0.5172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_ED...\n",
       "                                                     [3, &#x27;elu&#x27;]],\n",
       "                                                    [[500, None], [200, None],\n",
       "                                                     [80, &#x27;elu&#x27;], [60, &#x27;elu&#x27;],\n",
       "                                                     [40, None],\n",
       "                                                     [8, &#x27;softplus&#x27;],\n",
       "                                                     [3, None]],\n",
       "                                                    [[500, &#x27;softplus&#x27;],\n",
       "                                                     [200, None],\n",
       "                                                     [80, &#x27;softplus&#x27;],\n",
       "                                                     [40, &#x27;elu&#x27;], [20, None],\n",
       "                                                     [8, &#x27;elu&#x27;],\n",
       "                                                     [3, &#x27;softplus&#x27;]],\n",
       "                                                    [[500, &#x27;elu&#x27;], [80, &#x27;elu&#x27;],\n",
       "                                                     [3, None]],\n",
       "                                                    [[80, None], [8, &#x27;elu&#x27;],\n",
       "                                                     [3, &#x27;softplus&#x27;]]],\n",
       "                         &#x27;autoencoder__verbose&#x27;: [1]},\n",
       "             scoring=make_scorer(autoencoder_loss_scorer, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_ED...\n",
       "                                                     [3, &#x27;elu&#x27;]],\n",
       "                                                    [[500, None], [200, None],\n",
       "                                                     [80, &#x27;elu&#x27;], [60, &#x27;elu&#x27;],\n",
       "                                                     [40, None],\n",
       "                                                     [8, &#x27;softplus&#x27;],\n",
       "                                                     [3, None]],\n",
       "                                                    [[500, &#x27;softplus&#x27;],\n",
       "                                                     [200, None],\n",
       "                                                     [80, &#x27;softplus&#x27;],\n",
       "                                                     [40, &#x27;elu&#x27;], [20, None],\n",
       "                                                     [8, &#x27;elu&#x27;],\n",
       "                                                     [3, &#x27;softplus&#x27;]],\n",
       "                                                    [[500, &#x27;elu&#x27;], [80, &#x27;elu&#x27;],\n",
       "                                                     [3, None]],\n",
       "                                                    [[80, None], [8, &#x27;elu&#x27;],\n",
       "                                                     [3, &#x27;softplus&#x27;]]],\n",
       "                         &#x27;autoencoder__verbose&#x27;: [1]},\n",
       "             scoring=make_scorer(autoencoder_loss_scorer, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_EDUCATION_12&#x27;, &#x27;T_EDUCATION_6&#x27;,...\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;add_noise&#x27;, GaussianNoiseTransformer()),\n",
       "                (&#x27;autoencoder&#x27;, AutoencoderTransformer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                 Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_EDUCATION_12&#x27;, &#x27;T_EDUCATION_6&#x27;, &#x27;R_EDUCATION&#x27;,\n",
       "       &#x27;R_EDUCATION_INCOM...\n",
       "       &#x27;R_EXPENDITURE_SAVINGS&#x27;, &#x27;R_EXPENDITURE_DEBT&#x27;, &#x27;CAT_DEBT&#x27;,\n",
       "       &#x27;CAT_CREDIT_CARD&#x27;, &#x27;CAT_MORTGAGE&#x27;, &#x27;CAT_SAVINGS_ACCOUNT&#x27;,\n",
       "       &#x27;CAT_DEPENDENTS&#x27;, &#x27;CREDIT_SCORE&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Unnamed: 0&#x27;, &#x27;INCOME&#x27;, &#x27;SAVINGS&#x27;, &#x27;DEBT&#x27;, &#x27;R_SAVINGS_INCOME&#x27;,\n",
       "       &#x27;R_DEBT_INCOME&#x27;, &#x27;R_DEBT_SAVINGS&#x27;, &#x27;T_CLOTHING_12&#x27;, &#x27;T_CLOTHING_6&#x27;,\n",
       "       &#x27;R_CLOTHING&#x27;, &#x27;R_CLOTHING_INCOME&#x27;, &#x27;R_CLOTHING_SAVINGS&#x27;,\n",
       "       &#x27;R_CLOTHING_DEBT&#x27;, &#x27;T_EDUCATION_12&#x27;, &#x27;T_EDUCATION_6&#x27;, &#x27;R_EDUCATION&#x27;,\n",
       "       &#x27;R_EDUCATION_INCOME&#x27;, &#x27;R_EDUCATION_SAVINGS&#x27;, &#x27;R_EDUCATION_DEBT&#x27;,\n",
       "       &#x27;T_ENTERTAINMENT_12&#x27;, &#x27;T_ENTERTAINMENT_6&#x27;, &#x27;R_ENTERTAINMENT&#x27;,\n",
       "       &#x27;R_ENTERTAINMENT_INCOME&#x27;, &#x27;R_ENTERTAINMENT_SAVINGS&#x27;,\n",
       "       &#x27;R_ENTERTAINMENT_DEBT&#x27;, &#x27;T_FINES_12&#x27;, &#x27;T_FINES_6&#x27;, &#x27;R_FINES&#x27;,\n",
       "       &#x27;R_FINES_INCOME&#x27;, &#x27;R_FINES_SAVINGS&#x27;, &#x27;R_FINES_DEBT&#x27;, &#x27;T_GAMBLING_12&#x27;,\n",
       "       &#x27;T_GAMBLING_6&#x27;, &#x27;R_GAMBLING&#x27;, &#x27;R_GAMBLING_INCOME&#x27;, &#x27;R_GAMBLING_SAVINGS&#x27;,\n",
       "       &#x27;R_GAMBLING_DEBT&#x27;, &#x27;T_GROCERIES_12&#x27;, &#x27;T_GROCERIES_6&#x27;, &#x27;R_GROCERIES&#x27;,\n",
       "       &#x27;R_GROCERIES_INCOME&#x27;, &#x27;R_GROCERIES_SAVINGS&#x27;, &#x27;R_GROCERIES_DEBT&#x27;,\n",
       "       &#x27;T_HEALTH_12&#x27;, &#x27;T_HEALTH_6&#x27;, &#x27;R_HEALTH&#x27;, &#x27;R_HEALTH_INCOME&#x27;,\n",
       "       &#x27;R_HEALTH_SAVINGS&#x27;, &#x27;R_HEALTH_DEBT&#x27;, &#x27;T_HOUSING_12&#x27;, &#x27;T_HOUSING_6&#x27;,\n",
       "       &#x27;R_HOUSING&#x27;, &#x27;R_HOUSING_INCOME&#x27;, &#x27;R_HOUSING_SAVINGS&#x27;, &#x27;R_HOUSING_DEBT&#x27;,\n",
       "       &#x27;T_TAX_12&#x27;, &#x27;T_TAX_6&#x27;, &#x27;R_TAX&#x27;, &#x27;R_TAX_INCOME&#x27;, &#x27;R_TAX_SAVINGS&#x27;,\n",
       "       &#x27;R_TAX_DEBT&#x27;, &#x27;T_TRAVEL_12&#x27;, &#x27;T_TRAVEL_6&#x27;, &#x27;R_TRAVEL&#x27;,\n",
       "       &#x27;R_TRAVEL_INCOME&#x27;, &#x27;R_TRAVEL_SAVINGS&#x27;, &#x27;R_TRAVEL_DEBT&#x27;,\n",
       "       &#x27;T_UTILITIES_12&#x27;, &#x27;T_UTILITIES_6&#x27;, &#x27;R_UTILITIES&#x27;, &#x27;R_UTILITIES_INCOME&#x27;,\n",
       "       &#x27;R_UTILITIES_SAVINGS&#x27;, &#x27;R_UTILITIES_DEBT&#x27;, &#x27;T_EXPENDITURE_12&#x27;,\n",
       "       &#x27;T_EXPENDITURE_6&#x27;, &#x27;R_EXPENDITURE&#x27;, &#x27;R_EXPENDITURE_INCOME&#x27;,\n",
       "       &#x27;R_EXPENDITURE_SAVINGS&#x27;, &#x27;R_EXPENDITURE_DEBT&#x27;, &#x27;CAT_DEBT&#x27;,\n",
       "       &#x27;CAT_CREDIT_CARD&#x27;, &#x27;CAT_MORTGAGE&#x27;, &#x27;CAT_SAVINGS_ACCOUNT&#x27;,\n",
       "       &#x27;CAT_DEPENDENTS&#x27;, &#x27;CREDIT_SCORE&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;CAT_GAMBLING&#x27;, &#x27;CAT_LOCATION&#x27;, &#x27;CAT_MARITAL_STATUS&#x27;, &#x27;CAT_EDUCATION&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNoiseTransformer</label><div class=\"sk-toggleable__content\"><pre>GaussianNoiseTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoencoderTransformer</label><div class=\"sk-toggleable__content\"><pre>AutoencoderTransformer()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         Index(['Unnamed: 0', 'INCOME', 'SAVINGS', 'DEBT', 'R_SAVINGS_INCOME',\n",
       "       'R_DEBT_INCOME', 'R_DEBT_SAVINGS', 'T_CLOTHING_12', 'T_CLOTHING_6',\n",
       "       'R_CLOTHING', 'R_CLOTHING_INCOME', 'R_CLOTHING_SAVINGS',\n",
       "       'R_CLOTHING_DEBT', 'T_ED...\n",
       "                                                     [3, 'elu']],\n",
       "                                                    [[500, None], [200, None],\n",
       "                                                     [80, 'elu'], [60, 'elu'],\n",
       "                                                     [40, None],\n",
       "                                                     [8, 'softplus'],\n",
       "                                                     [3, None]],\n",
       "                                                    [[500, 'softplus'],\n",
       "                                                     [200, None],\n",
       "                                                     [80, 'softplus'],\n",
       "                                                     [40, 'elu'], [20, None],\n",
       "                                                     [8, 'elu'],\n",
       "                                                     [3, 'softplus']],\n",
       "                                                    [[500, 'elu'], [80, 'elu'],\n",
       "                                                     [3, None]],\n",
       "                                                    [[80, None], [8, 'elu'],\n",
       "                                                     [3, 'softplus']]],\n",
       "                         'autoencoder__verbose': [1]},\n",
       "             scoring=make_scorer(autoencoder_loss_scorer, greater_is_better=False))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def autoencoder_loss_scorer(X, prediction):\n",
    "    return mean_squared_error(prediction[1], prediction[0]) # scoring method chosen for the grid_search comparison\n",
    "\n",
    "\n",
    "autoencoder_scorer = make_scorer(autoencoder_loss_scorer, greater_is_better=False)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=autoencoder_scorer)\n",
    "grid_search.fit(X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autoencoder__epochs': 250,\n",
       " 'autoencoder__learning_rate': 0.001,\n",
       " 'autoencoder__structure': [[500, 'elu'], [80, 'elu'], [3, None]],\n",
       " 'autoencoder__verbose': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6388077049963578"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  4.287951  ,   0.42407632,   1.3517463 ],\n",
       "       [ -1.4952854 ,  -3.197262  ,   0.98070496],\n",
       "       [ -3.2481709 ,   5.980605  ,  -1.8597491 ],\n",
       "       ...,\n",
       "       [ 15.188078  ,   2.698692  , -12.512763  ],\n",
       "       [ -2.898413  ,   4.3259397 ,  -2.6536803 ],\n",
       "       [  0.08941425,  -1.4226025 ,  -0.81629246]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings=grid_search.transform(X_train)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad9788667fc03be3be26dd74a7aac5e0",
     "grade": false,
     "grade_id": "cell-3dcb52b60347e6fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Quality of the Compression</b>\n",
    "\n",
    "The following cell comprises the code to visualize the encoded feature matrix, employing the binary target array to color the samples. We also use other plotting methods to analyze the output of the autoencoder.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f427ddd98a0da9920d4a0993c0a2356",
     "grade": false,
     "grade_id": "cell-2ccd0b6c3464f31e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<br>z=%{z}<br>color=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           0,
           1,
           1,
           1,
           0,
           1,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           1,
           0,
           1,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           1,
           1,
           1,
           0,
           1,
           1,
           1,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           1,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           1,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           1,
           1,
           1,
           0,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           1,
           1,
           0
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": [
          4.287951,
          -1.4952854,
          -3.2481709,
          0.87749285,
          0.7549774,
          -2.6163917,
          -1.1600686,
          -2.6952825,
          -0.36918807,
          -7.265085,
          0.5408441,
          1.8831073,
          9.499558,
          -1.9575778,
          -0.40476048,
          0.33270442,
          -2.2652025,
          -17.833694,
          -0.9189444,
          -3.0714738,
          0.69634455,
          -0.6948983,
          -0.53021175,
          -2.7520485,
          4.602511,
          -0.040431067,
          1.4092907,
          3.1483238,
          25.986683,
          -0.5051758,
          -4.8941603,
          21.000446,
          -0.65192306,
          -0.970113,
          -2.3982432,
          0.31457043,
          -0.3558455,
          19.876701,
          0.4331792,
          -0.14528514,
          -2.491812,
          30.9831,
          -5.4524956,
          -9.080223,
          -6.7368407,
          -14.77405,
          -4.3878026,
          -1.5540409,
          -1.9323648,
          6.7574296,
          0.6325548,
          1.1276635,
          4.0461593,
          2.5734737,
          3.8768308,
          1.811037,
          -5.7499547,
          -7.1672597,
          0.9721976,
          -5.738848,
          2.6231964,
          2.2008502,
          0.7633139,
          2.8231783,
          -1.7843903,
          16.65605,
          -0.7836806,
          -12.341051,
          -14.826872,
          -1.2393985,
          -0.5901276,
          -0.34978598,
          5.850782,
          -3.0865142,
          -12.070817,
          -2.833855,
          0.8648567,
          3.6567478,
          2.7895036,
          -2.301537,
          5.8502903,
          -6.99537,
          -0.97639924,
          -2.3329608,
          4.8880305,
          -11.897135,
          10.684074,
          -3.5805094,
          3.8433225,
          -0.62022096,
          -4.56033,
          -0.30511945,
          -0.33269125,
          -8.341213,
          -0.56553686,
          -1.5330069,
          -2.0714233,
          9.984911,
          -5.4185987,
          11.126329,
          1.0345435,
          -9.790928,
          -2.3102913,
          1.2988795,
          -2.8799675,
          -2.781248,
          -7.1016626,
          -5.6590543,
          0.27555168,
          -1.252178,
          -2.8300574,
          4.391653,
          -6.133842,
          -8.327718,
          -0.38218743,
          -0.3884526,
          -11.907013,
          1.4269961,
          0.072448894,
          -2.2447615,
          -4.430948,
          2.1530244,
          0.83725196,
          -1.6390067,
          -3.0046096,
          10.096773,
          -2.1017015,
          -2.1056664,
          -2.983824,
          -5.089475,
          -9.012543,
          10.835842,
          -0.5795164,
          1.7427853,
          -0.70170254,
          1.0953032,
          9.161869,
          1.6673399,
          2.1169531,
          9.637753,
          -7.3146696,
          -0.14643718,
          -5.3582606,
          0.65340334,
          -3.0865672,
          -0.12145053,
          2.3177912,
          0.40353775,
          21.313337,
          1.7863714,
          0.5742815,
          13.5014515,
          -1.4266859,
          0.60808283,
          -8.2721195,
          -4.1317387,
          15.125644,
          -1.6943684,
          -4.4973755,
          0.0355068,
          -1.94179,
          4.466417,
          -0.39492768,
          3.2162523,
          -6.2260885,
          1.0829349,
          -0.63408715,
          0.65573305,
          0.38955653,
          1.6949968,
          29.154024,
          -7.3098946,
          10.272687,
          -13.705675,
          -1.3295584,
          1.2527705,
          0.8194753,
          7.256929,
          10.410362,
          6.4139094,
          10.593718,
          1.6360003,
          -4.6697693,
          -13.559926,
          -1.3359771,
          0.85523546,
          5.2810493,
          3.3293474,
          11.205189,
          -1.1107866,
          -7.7344527,
          -1.9895233,
          -5.9898663,
          -8.495467,
          -1.1439722,
          4.1775885,
          -7.247497,
          -1.8903122,
          -2.061108,
          2.210305,
          10.020908,
          -1.9948925,
          -22.409843,
          -2.7838643,
          -5.299454,
          7.079375,
          -2.4564362,
          -9.3158,
          -5.5079865,
          0.91982603,
          8.710136,
          -0.27688533,
          -0.6014184,
          -1.1331402,
          1.7466111,
          -0.28631568,
          -1.721635,
          -4.0843782,
          5.012854,
          2.5225723,
          0.009911403,
          0.40089792,
          -6.7737556,
          -1.0678449,
          0.26509327,
          -6.162402,
          11.069716,
          6.0142484,
          -0.5166182,
          -3.8878772,
          12.441004,
          1.2487763,
          -19.762867,
          0.79187745,
          1.287362,
          -9.273627,
          -3.218527,
          -2.9944036,
          -6.156942,
          -10.135038,
          12.580105,
          1.8795046,
          -13.926403,
          -2.158083,
          0.92010754,
          2.5582535,
          -8.450991,
          -2.616626,
          8.962745,
          5.3383102,
          -0.7527381,
          -2.6670573,
          -10.465766,
          -0.5014428,
          3.3395526,
          -3.9061134,
          -11.405582,
          -0.33538073,
          -0.51895106,
          2.5939748,
          -21.362972,
          3.8922746,
          -7.6801744,
          -3.430998,
          0.014953211,
          7.3676925,
          4.476423,
          -8.749844,
          1.4848903,
          2.5650008,
          -0.021710917,
          7.9625115,
          1.8006166,
          -10.797541,
          -0.2286561,
          2.8383334,
          -0.66672736,
          -8.309927,
          0.33914477,
          2.0280967,
          0.21198456,
          2.1799033,
          -19.549414,
          -10.602409,
          21.951542,
          1.2633772,
          -0.085837856,
          1.7025386,
          2.7231772,
          -2.0285099,
          -5.6852603,
          13.67647,
          0.93411833,
          -1.3841265,
          -5.5330577,
          -3.7752597,
          1.2318314,
          3.6755364,
          -0.85331875,
          -4.8971243,
          -0.5649422,
          0.48629838,
          -0.8668486,
          10.160423,
          0.8736246,
          0.24810015,
          21.23015,
          0.227901,
          4.039039,
          -2.0351758,
          -5.184981,
          10.0525255,
          1.0791371,
          -1.2106081,
          0.47050816,
          -0.009020731,
          3.4971101,
          -1.6175063,
          -0.9691729,
          -17.388676,
          4.186026,
          0.5894502,
          6.760818,
          1.553232,
          -2.966312,
          -25.602585,
          4.447697,
          -0.93769544,
          -1.1091958,
          0.5560865,
          -11.530861,
          -0.8953046,
          0.38851047,
          -11.272773,
          6.5697026,
          -0.69158727,
          -0.4097525,
          1.0630962,
          -2.5131524,
          6.11655,
          -3.4335763,
          -12.342367,
          -2.2593327,
          5.1524997,
          48.245296,
          -5.3611426,
          15.631135,
          5.640584,
          3.955383,
          6.7156405,
          -22.823814,
          -12.559507,
          2.4611752,
          34.604523,
          -1.090459,
          2.406967,
          4.730612,
          -1.4078583,
          5.6409783,
          -5.659865,
          -6.7428956,
          -0.58635134,
          5.904735,
          -4.184874,
          -4.62089,
          1.0107973,
          1.8856273,
          0.19332214,
          -7.858461,
          -3.2165618,
          -0.37364823,
          -2.9106605,
          -1.7648844,
          1.4723417,
          2.3790507,
          62.336597,
          2.844657,
          -2.241387,
          -13.644093,
          2.9017155,
          -0.2674178,
          -7.040664,
          -0.025694981,
          0.4820966,
          5.798314,
          -12.28507,
          6.602314,
          -0.107910484,
          -1.2965971,
          2.9164803,
          1.75918,
          7.2495356,
          -0.83054644,
          -3.2191122,
          -7.2113395,
          -2.4894462,
          -0.62946445,
          -9.403097,
          6.0234623,
          1.2947317,
          -0.29991692,
          -9.654907,
          10.44793,
          0.035533622,
          35.092094,
          -0.6550719,
          -3.0785959,
          -3.73375,
          -4.824313,
          0.49048388,
          1.7144998,
          0.98899347,
          22.12949,
          -6.6506257,
          0.80224586,
          1.6406779,
          4.6053643,
          0.60006,
          -4.0082135,
          -0.54673654,
          -1.0591817,
          9.747942,
          -3.142456,
          -0.66916794,
          2.4789252,
          -0.10747896,
          -0.02518095,
          -7.760697,
          0.08030833,
          5.434084,
          9.44475,
          0.23373935,
          4.9036446,
          1.1078053,
          -1.7858326,
          -1.6297894,
          2.9341867,
          0.4100474,
          -3.6374054,
          2.1699264,
          0.34927893,
          9.065475,
          -1.424313,
          5.903383,
          6.4592433,
          -2.7878757,
          -5.2422595,
          -4.7103314,
          22.479334,
          1.4126782,
          -0.11608049,
          -5.4178476,
          1.9200908,
          0.3335002,
          1.06072,
          1.2896713,
          -6.4928517,
          16.403921,
          -5.8703732,
          -3.8688467,
          -0.2814327,
          1.6774415,
          1.4823,
          -0.48468083,
          22.211775,
          -0.67259485,
          -7.8149323,
          -4.767854,
          5.2417173,
          -0.62961704,
          -1.9848286,
          -3.0788145,
          3.3100278,
          1.1194818,
          2.7967374,
          2.1374183,
          5.012428,
          -0.025880322,
          -0.8887885,
          -1.6494683,
          -3.7599277,
          -3.8636894,
          -0.06008102,
          0.5700723,
          0.5395814,
          1.1115203,
          -14.421114,
          4.70924,
          8.202382,
          3.0634615,
          -1.2434603,
          6.4892607,
          0.24270557,
          1.4924487,
          -8.02551,
          -0.8316453,
          0.50382215,
          0.6797344,
          -3.020787,
          -4.642813,
          -10.427842,
          -2.9967785,
          -4.9312167,
          -3.395631,
          3.0683508,
          1.871108,
          -2.1136725,
          -1.7044551,
          7.870501,
          -1.1701764,
          10.79756,
          1.9535285,
          1.2109736,
          1.5496687,
          0.22540261,
          1.967507,
          0.8745026,
          -8.697765,
          11.686407,
          -0.002499625,
          -9.1422,
          -3.7868907,
          -1.5379562,
          -1.6642178,
          0.7550277,
          -0.1153215,
          34.92739,
          1.0205204,
          -12.132079,
          -0.28002822,
          -3.049701,
          9.364666,
          14.391327,
          2.968485,
          -13.508599,
          -0.27627927,
          -0.11150958,
          -3.2354012,
          -1.1233344,
          3.8480866,
          4.446239,
          -1.7590095,
          9.38954,
          9.330807,
          -5.574889,
          0.698853,
          10.5189,
          -1.7178445,
          -2.3309681,
          11.068323,
          -1.3613364,
          0.8076803,
          -4.345371,
          -3.9050095,
          2.1862173,
          -2.5868723,
          -7.9807105,
          -3.7428207,
          13.81249,
          -3.853246,
          0.74993384,
          -8.383884,
          12.430834,
          1.654138,
          -0.49093652,
          4.545476,
          1.4168761,
          -7.645304,
          0.68956274,
          12.014021,
          8.960934,
          -2.8475661,
          3.9459417,
          10.876339,
          -7.265506,
          10.166834,
          1.717693,
          9.587887,
          2.1684237,
          24.38068,
          0.543049,
          7.5771136,
          0.026861742,
          -0.9365917,
          -1.4921818,
          2.5939023,
          -10.384701,
          -14.101915,
          -1.9974922,
          11.951048,
          -8.042865,
          6.4636326,
          -11.136732,
          -0.22316973,
          -3.5213559,
          3.712086,
          23.090256,
          -5.795087,
          0.22183631,
          -10.921816,
          2.77444,
          1.7141403,
          9.242275,
          1.3825907,
          -7.993919,
          1.4696163,
          5.947248,
          11.018503,
          2.5357342,
          0.9145346,
          0.86284786,
          -9.952319,
          -4.454435,
          -3.3490431,
          -6.2164493,
          -0.8249338,
          -0.9318933,
          2.48614,
          -0.7189538,
          0.5229515,
          0.15095551,
          0.50705975,
          -1.4838014,
          2.576074,
          -2.0471046,
          -0.5650905,
          -1.7399092,
          14.816354,
          1.5521657,
          2.2400289,
          -2.0880911,
          -1.7705666,
          -7.676782,
          0.40838933,
          0.008571163,
          -8.762058,
          -7.5210776,
          -4.4751387,
          -1.1850737,
          -6.072672,
          12.317819,
          -8.224521,
          -0.505891,
          -1.9463168,
          2.4837081,
          14.040651,
          0.6743786,
          -0.2599572,
          0.6929742,
          -4.55166,
          -5.281548,
          4.030382,
          -8.387568,
          -0.12111996,
          0.74272954,
          -2.3498762,
          2.620048,
          8.468392,
          5.5541053,
          22.920803,
          -2.2797291,
          -1.8626406,
          2.0182786,
          -9.18898,
          0.9512127,
          0.7200596,
          0.50593406,
          4.729024,
          -1.7818813,
          -11.777356,
          -0.366131,
          0.33521768,
          -8.112635,
          -2.1551414,
          3.3778472,
          -0.5623225,
          -1.2223307,
          0.2600189,
          -10.32919,
          -1.3371931,
          -3.3092544,
          1.2203399,
          5.9959245,
          -3.141936,
          -1.5101506,
          6.019066,
          10.556398,
          0.16289963,
          5.624355,
          8.593989,
          -0.27902752,
          -0.8201634,
          1.8029459,
          -5.454307,
          -7.6049786,
          0.010250881,
          -3.9058404,
          -4.26625,
          -0.5237649,
          1.0534257,
          -0.7166883,
          3.5567172,
          -0.96113116,
          -0.082465276,
          -3.84353,
          -1.6709436,
          9.492264,
          4.222271,
          -0.567743,
          -1.1139439,
          -6.087382,
          5.799518,
          -5.024582,
          -4.450726,
          0.3907076,
          -18.637318,
          29.883768,
          -11.984419,
          -0.016498797,
          3.010886,
          -2.4936826,
          0.20376518,
          -1.5429815,
          -0.9217023,
          -9.440027,
          -7.6316056,
          0.14578941,
          -0.44679034,
          -0.8728251,
          -8.902793,
          0.11416331,
          1.4065112,
          -10.675396,
          0.18206963,
          -7.395389,
          -5.5784135,
          0.32282096,
          -1.3542267,
          1.9304743,
          0.34180355,
          -7.2443194,
          -1.2082248,
          0.5554348,
          -6.307813,
          -8.591024,
          -5.951343,
          0.39325225,
          15.188078,
          -2.898413,
          0.089414254
         ],
         "y": [
          0.42407632,
          -3.197262,
          5.980605,
          -2.0643039,
          4.3745914,
          -4.891763,
          -4.145906,
          0.89211935,
          2.8873658,
          -0.70969,
          -1.7806512,
          -2.8682284,
          -8.282606,
          0.46271586,
          1.4792473,
          0.68305445,
          4.374953,
          -7.1871624,
          7.732297,
          5.4960103,
          4.3706107,
          -4.8603086,
          -0.68045163,
          1.8086098,
          6.053113,
          0.9378034,
          -2.1783636,
          -1.5493977,
          -33.960785,
          -1.9030627,
          -2.759596,
          -12.002571,
          -2.8574746,
          3.0193245,
          -4.2682557,
          5.8957434,
          -3.485932,
          -1.8090477,
          -1.6571094,
          -0.8037257,
          1.3595994,
          -11.296097,
          2.2035084,
          0.09962245,
          -1.2851409,
          -2.9455462,
          3.4135983,
          0.14018273,
          -1.9518436,
          5.334235,
          -0.29058167,
          0.6074935,
          2.9908178,
          -2.1441896,
          5.364346,
          -3.556778,
          -3.0680091,
          -0.4782211,
          -3.5510895,
          -7.0739155,
          -2.624432,
          -1.9083774,
          -1.079806,
          -0.8470958,
          -0.807914,
          0.693386,
          1.7929434,
          0.44477537,
          1.1310519,
          0.2140317,
          0.3745287,
          -3.7126458,
          -4.4664288,
          0.7747634,
          1.5149384,
          -7.955329,
          -1.8250891,
          1.0850079,
          -1.8603185,
          -0.94515234,
          3.1759884,
          6.996132,
          0.09552004,
          0.5053269,
          -1.61464,
          -2.887889,
          -6.753925,
          1.5299064,
          12.340443,
          -1.341653,
          1.8558549,
          -1.1904384,
          7.9260225,
          0.9160022,
          -0.7661911,
          0.49854764,
          -0.92471564,
          -11.081643,
          -1.3555251,
          -13.26047,
          -0.1362983,
          0.7377163,
          6.2539053,
          -1.9966644,
          0.62754005,
          6.083319,
          -1.4551765,
          -1.4306023,
          -2.247462,
          0.001675535,
          -0.09159208,
          -3.8618205,
          -1.0496311,
          -4.2813807,
          -3.0517397,
          -2.9357886,
          2.6959078,
          5.932984,
          -1.8539165,
          4.552159,
          4.2046337,
          -2.1553457,
          -0.76553136,
          -4.4758315,
          -0.7818967,
          -7.7865505,
          0.8425099,
          -3.9473195,
          -1.2267574,
          -2.2543437,
          -9.811594,
          -3.066095,
          2.9583938,
          -0.49439713,
          3.248798,
          -2.6003704,
          -12.029014,
          -3.0837843,
          -0.76946175,
          -6.1514683,
          -4.82127,
          -3.4508345,
          1.6217308,
          -1.2236801,
          -3.984769,
          2.6478357,
          0.2620605,
          1.7335901,
          4.8371,
          2.5565464,
          -0.12472937,
          1.4951288,
          -1.0050203,
          7.5460944,
          0.26216498,
          5.0925264,
          5.0119762,
          2.0459151,
          -4.7471433,
          11.245354,
          -0.4436576,
          -3.438986,
          0.17866626,
          -3.6089113,
          -5.8429894,
          -1.7807535,
          -3.3879397,
          -1.992539,
          -0.47768697,
          5.0275235,
          -20.856218,
          -3.5336804,
          -5.111514,
          -2.718259,
          3.2383177,
          -2.014587,
          -0.6146004,
          3.5394046,
          -16.490261,
          -1.406757,
          -15.982751,
          -1.8472221,
          -1.2551669,
          -0.5860484,
          -3.0074232,
          7.7466993,
          1.6137009,
          -3.4839127,
          -10.553914,
          -2.2174094,
          0.8512955,
          2.6078246,
          -3.9920347,
          3.6711457,
          -3.2297127,
          5.9560585,
          -4.633578,
          -0.4309439,
          -4.510802,
          -6.4895177,
          0.542628,
          -5.783544,
          -28.414719,
          1.0003475,
          0.9132212,
          -1.1038424,
          3.7387674,
          -0.31899074,
          -0.08050833,
          -0.9253962,
          1.7410697,
          2.9891045,
          -1.9123021,
          2.3867643,
          -3.2746665,
          3.879092,
          -3.244067,
          -1.2031358,
          -3.6247685,
          -0.24463984,
          -3.494973,
          4.5255346,
          -3.7654393,
          -1.1298194,
          4.4630895,
          -3.0731347,
          -8.376374,
          0.16653183,
          -0.026611052,
          -0.42044473,
          -9.7882185,
          8.985702,
          2.6799068,
          3.9522302,
          0.115076,
          0.022398196,
          -1.0165018,
          -1.3021735,
          6.550525,
          -0.8123383,
          -11.235148,
          -1.7588799,
          -3.2262466,
          4.370974,
          -0.80996734,
          -10.790521,
          3.391587,
          -2.3193061,
          0.7012729,
          14.794758,
          1.6124662,
          3.1424606,
          -1.9671985,
          4.7694006,
          -2.0896983,
          6.6869545,
          -1.1835488,
          0.039866082,
          -2.0834455,
          -4.2104797,
          0.89163315,
          4.2408676,
          0.21840426,
          -4.719619,
          4.9155145,
          -0.73107094,
          8.628371,
          0.78385717,
          -0.7389543,
          -2.0850964,
          4.5389485,
          -5.3046713,
          12.121016,
          -0.4976708,
          -2.4194205,
          15.457217,
          10.320081,
          6.0797524,
          -2.399031,
          0.89357877,
          3.160563,
          12.503005,
          -2.97608,
          0.40023455,
          -13.983857,
          3.684098,
          -2.8817875,
          -0.20199737,
          -1.9561714,
          -1.4307895,
          5.2375717,
          -10.687718,
          0.0903089,
          -3.3249316,
          -2.3835304,
          4.7380514,
          -3.293347,
          -1.9626149,
          -3.395375,
          4.8875837,
          -0.38891557,
          -1.577788,
          6.8878355,
          -10.257382,
          -1.2757888,
          -0.15113035,
          -16.184376,
          -4.397895,
          -2.9258993,
          -0.6383172,
          7.2386446,
          1.0039781,
          -3.3172338,
          3.4130805,
          -1.3668762,
          4.4393673,
          -0.4490845,
          0.9841393,
          6.188399,
          1.8834038,
          0.15673283,
          5.4121895,
          14.724302,
          -2.325329,
          -1.1307019,
          -4.644156,
          -2.6396487,
          -1.0400952,
          -2.933298,
          2.0482962,
          1.1689962,
          -0.64735186,
          -0.8007959,
          0.64685804,
          1.773172,
          -9.075891,
          -4.0792127,
          -25.35642,
          -6.1892643,
          1.3153251,
          3.1617556,
          -1.3514196,
          -2.3397615,
          3.8230321,
          12.733095,
          0.34032893,
          1.269969,
          0.5423525,
          -2.051855,
          -1.3032329,
          -3.597172,
          1.4610292,
          -23.807846,
          39.28995,
          -3.4901574,
          -1.2142824,
          -2.921066,
          3.639186,
          13.863263,
          -1.040915,
          -3.7962182,
          -2.9510093,
          -3.8464794,
          2.6378348,
          1.8617939,
          -5.459225,
          -3.1995318,
          6.412334,
          -0.0726072,
          0.41642258,
          -1.2940784,
          -4.4681244,
          0.9793349,
          0.6268188,
          -0.71799296,
          61.35402,
          -3.3434532,
          0.28512084,
          0.39886442,
          -4.8258204,
          -0.7726761,
          6.514842,
          0.33825493,
          8.081794,
          -1.4671922,
          0.41474774,
          0.33106828,
          -3.0009875,
          -0.00081831217,
          -2.2180593,
          0.19386938,
          3.4491217,
          3.122881,
          1.9871875,
          5.1544714,
          -0.3497248,
          -0.2450186,
          0.8288313,
          -4.4072266,
          -1.054393,
          3.2711418,
          -1.1148124,
          -18.037437,
          6.5662327,
          -4.9082046,
          -3.5633233,
          2.156968,
          1.4318888,
          2.2610676,
          0.18675253,
          -0.91307867,
          -1.3979373,
          -13.31485,
          -2.8744013,
          -4.4088287,
          0.6805301,
          3.2255766,
          -3.74378,
          2.8379898,
          -4.250212,
          -0.86524725,
          -6.439333,
          4.660871,
          0.6011381,
          -5.604353,
          0.7485313,
          6.6177044,
          3.619136,
          -2.9365785,
          -0.65417206,
          -5.1120586,
          0.8103219,
          5.36914,
          3.7473633,
          5.2610893,
          3.794266,
          -0.6245141,
          -4.635991,
          3.992106,
          -3.6323602,
          -0.7934177,
          6.1485333,
          0.16876364,
          -5.0093966,
          -3.6167526,
          -0.2848493,
          -1.3343172,
          0.5778286,
          -14.663819,
          4.98789,
          -1.59333,
          -0.3324999,
          1.3922956,
          -2.514078,
          2.8591685,
          -4.0602627,
          0.4500288,
          2.0342596,
          1.4211698,
          4.5471153,
          -1.9778811,
          -3.6286662,
          -0.02099917,
          2.4810033,
          -21.37951,
          -0.33814386,
          0.4440874,
          5.4345818,
          4.1843634,
          -0.6458078,
          5.247336,
          4.379947,
          -1.6781026,
          -1.3055717,
          -1.4050875,
          -2.5026643,
          1.633958,
          -1.1366233,
          2.8841517,
          0.48286277,
          5.386713,
          -3.6413016,
          2.510632,
          4.906831,
          5.8527374,
          -2.1140635,
          -2.528734,
          5.0852823,
          2.7435827,
          -0.18458542,
          9.258397,
          -2.1551695,
          -2.9973323,
          -1.393359,
          -1.761072,
          -2.4197664,
          -0.7750245,
          1.4177893,
          5.5679173,
          -1.408053,
          -0.92586887,
          1.4969933,
          2.4214265,
          1.0243387,
          -0.33463934,
          1.8981719,
          -5.648823,
          -3.6588569,
          -2.4046235,
          -1.269667,
          0.20975643,
          -4.021096,
          4.0216074,
          0.80118084,
          1.6397785,
          -1.0191553,
          -1.817897,
          1.0268145,
          -10.478686,
          5.0001593,
          2.0254412,
          -1.3069501,
          -0.7439538,
          0.6134935,
          -3.1626017,
          8.969219,
          -4.790396,
          -1.0075897,
          -3.9904525,
          8.147834,
          0.44054407,
          -8.535782,
          -19.674038,
          -2.0120184,
          -2.9404185,
          3.2862823,
          -0.54252124,
          -1.8714638,
          0.15862918,
          -0.18201634,
          5.745284,
          7.7481294,
          1.856742,
          -11.129059,
          1.9572383,
          -1.5560614,
          -7.5198784,
          7.5624666,
          1.1600648,
          -7.3976564,
          4.0844893,
          5.236001,
          1.5571991,
          -0.8690896,
          -0.33579755,
          0.83164895,
          2.7077358,
          -3.0690453,
          -11.2099495,
          4.931239,
          4.275078,
          -2.0683353,
          -12.3612795,
          -2.1762478,
          0.33588168,
          -1.0292417,
          -1.9920644,
          5.253296,
          0.6970135,
          -5.007408,
          22.035162,
          4.8389926,
          -2.0555017,
          -7.3539066,
          2.0363405,
          -11.618899,
          -4.0786753,
          -8.031261,
          1.41039,
          8.82385,
          -1.6234894,
          -1.406742,
          -1.4853413,
          0.3383001,
          -0.57656825,
          -2.6878555,
          -2.4242177,
          -3.1980736,
          3.9375112,
          -7.8752117,
          -1.227246,
          -3.7686002,
          3.326125,
          1.1989785,
          3.8556097,
          18.648966,
          -22.369387,
          -2.3628938,
          10.788285,
          4.5469317,
          14.884559,
          -1.7115133,
          -7.5854053,
          -0.59013534,
          -2.2482524,
          -0.6055691,
          4.711919,
          -4.03458,
          -0.41430414,
          -0.3246257,
          -1.1327131,
          0.17684111,
          1.390079,
          4.3790445,
          0.5436878,
          -2.2389839,
          1.6531725,
          -0.48283753,
          -1.0604081,
          -1.5480967,
          5.1977596,
          4.5831833,
          5.2713246,
          8.264539,
          6.595637,
          4.291688,
          -3.5024226,
          -13.939171,
          -3.454841,
          0.12909451,
          -0.34253326,
          -1.4996084,
          -1.5942641,
          -2.1761253,
          2.9488761,
          2.4897585,
          -2.028057,
          -9.377821,
          -1.1062485,
          -0.5199971,
          1.150694,
          5.099536,
          -2.1999123,
          0.22515678,
          -1.7810448,
          -11.242881,
          -0.30473042,
          0.32864332,
          0.85914004,
          2.470781,
          0.25444686,
          21.515442,
          -6.531862,
          6.573367,
          -1.1831094,
          4.063131,
          -0.27387342,
          -0.28622892,
          -4.0083055,
          -13.30745,
          -0.43006802,
          4.1423707,
          1.5360541,
          4.722902,
          -2.9972045,
          -1.4321568,
          2.0172012,
          -1.473536,
          0.93098783,
          -3.8628652,
          -0.5188422,
          -4.255019,
          0.48253953,
          -5.3183727,
          2.9491186,
          -1.8462207,
          -1.6150929,
          3.9959366,
          1.8583822,
          1.4236532,
          0.45049843,
          -1.2254001,
          0.63800716,
          1.1929651,
          -5.3348174,
          3.630955,
          -6.842099,
          -1.0469158,
          14.109229,
          -10.99838,
          4.708267,
          0.4081341,
          -1.4903069,
          -3.0055616,
          -0.43171766,
          -3.4903977,
          1.9046311,
          -4.7627673,
          6.225902,
          -2.7693691,
          -1.8156496,
          -1.6383418,
          -1.3309516,
          -1.7970587,
          -3.4540045,
          0.3939225,
          -12.071149,
          -3.040207,
          4.9853187,
          0.90797913,
          -0.9597579,
          -0.7549077,
          -0.72989154,
          2.8794134,
          -1.8600405,
          -1.0154035,
          13.01382,
          -0.93929553,
          -3.0247571,
          6.4540224,
          1.3976694,
          0.39692888,
          -2.7515228,
          -1.4469122,
          1.0108011,
          -0.25268623,
          -1.568168,
          3.3693933,
          -0.54412365,
          -0.6598768,
          0.75446784,
          -1.2256719,
          2.5927362,
          -1.5947415,
          4.8466606,
          1.1014837,
          3.8590834,
          -4.0955544,
          -11.500471,
          -0.16887057,
          0.13091436,
          -0.101963855,
          -0.8217794,
          -0.40144864,
          0.09055426,
          6.002897,
          0.6538491,
          2.698692,
          4.3259397,
          -1.4226025
         ],
         "z": [
          1.3517463,
          0.98070496,
          -1.8597491,
          3.0269854,
          -1.0134227,
          4.235422,
          -4.1904364,
          -1.4648902,
          -2.109979,
          -13.469399,
          -0.5945576,
          -1.9208951,
          3.9704273,
          -1.8687888,
          1.4397805,
          4.1666884,
          -2.6630416,
          2.6377563,
          0.77931565,
          -3.280426,
          -2.1238685,
          11.480585,
          5.2214327,
          -1.5889568,
          5.853738,
          4.173187,
          -2.542381,
          -2.674916,
          -4.706303,
          -0.39135328,
          0.990836,
          7.71881,
          2.6190155,
          -2.7432597,
          3.874687,
          -2.2064788,
          1.187213,
          1.4735526,
          -1.041862,
          3.5834916,
          -1.4706903,
          -7.1344047,
          -2.7691662,
          -0.08882595,
          -6.09277,
          6.29806,
          -4.518017,
          4.2215643,
          -3.2372377,
          3.7188513,
          -2.0109918,
          4.774262,
          6.141312,
          0.42092034,
          -0.10872799,
          1.4145948,
          -0.512797,
          -5.081954,
          2.916843,
          0.14376758,
          -2.601619,
          -0.13961972,
          4.4587784,
          1.8385465,
          -1.6587806,
          7.567857,
          0.13729213,
          -3.236646,
          2.076163,
          -0.69354445,
          2.644679,
          2.161239,
          -3.7187123,
          -3.5172207,
          2.4457905,
          9.68793,
          -2.42559,
          2.942814,
          -0.8535772,
          -2.461089,
          6.293563,
          -4.935028,
          8.37345,
          -2.6532557,
          -9.500579,
          5.279919,
          6.544297,
          -1.0960823,
          -2.3846526,
          2.2572334,
          -7.653734,
          3.4452517,
          -18.431293,
          2.6933603,
          2.9275384,
          -0.31581023,
          1.6647995,
          21.430471,
          1.2451856,
          4.2523527,
          1.3874477,
          2.2811687,
          -4.0486264,
          7.2417545,
          -2.8666368,
          -3.2111778,
          4.0842867,
          0.29742262,
          4.5374093,
          -0.5079764,
          -1.6781254,
          -3.0082903,
          -5.471939,
          -1.25457,
          2.578773,
          2.9291728,
          2.9653149,
          -2.3622816,
          5.1459827,
          -3.311434,
          -4.764583,
          -0.9278133,
          2.0280151,
          -4.029228,
          -4.0476084,
          2.4352221,
          -1.9880924,
          3.724106,
          -5.2199535,
          0.8288874,
          -14.882124,
          1.4342078,
          -1.9359686,
          -2.0154831,
          -1.8203961,
          1.698211,
          2.7467048,
          -2.4598389,
          1.0863098,
          -6.606228,
          0.14312528,
          -1.320828,
          0.9277681,
          2.4822962,
          -6.3226314,
          -2.367091,
          3.4848764,
          1.391927,
          -14.647229,
          2.6827924,
          4.9034944,
          7.7304153,
          0.33626702,
          -0.5076935,
          4.338992,
          -3.508847,
          61.302387,
          -5.277333,
          7.385067,
          -0.80430305,
          -2.8923976,
          -1.8806729,
          -0.5463548,
          -0.37392616,
          -2.8109343,
          -0.6486963,
          1.9365298,
          2.0625484,
          -1.1216074,
          -2.3583503,
          -59.9073,
          -0.52659786,
          -8.389721,
          3.6686795,
          -3.0908985,
          -2.619235,
          -0.79853547,
          6.9407372,
          -0.8358898,
          1.3486692,
          -0.54687846,
          -1.9402788,
          1.1336896,
          -4.0179467,
          3.7542584,
          -0.8017771,
          6.0082197,
          -0.6332578,
          1.9960887,
          3.4649599,
          -13.062102,
          -0.13836065,
          0.45110986,
          -10.063203,
          3.5550992,
          4.938516,
          -2.0878363,
          -2.0702317,
          4.2045345,
          -6.0656195,
          7.396121,
          7.7553473,
          40.57994,
          -1.2764018,
          -3.8588984,
          1.1979661,
          -4.9027405,
          4.674963,
          -4.8523664,
          -2.0768123,
          6.1824074,
          -3.4649305,
          3.550197,
          -3.2401686,
          -3.4012015,
          -1.6506677,
          -2.055148,
          1.6043833,
          -0.70409864,
          2.9068627,
          7.3082595,
          -3.1255176,
          -0.83627874,
          4.3395076,
          -1.3662528,
          0.26145062,
          5.0566354,
          1.6633335,
          -1.328967,
          -4.9512787,
          5.2179646,
          -3.3333411,
          2.1961362,
          -1.928203,
          -0.3446411,
          5.068365,
          -4.543513,
          1.5465279,
          -2.5649822,
          3.6542776,
          1.4465117,
          -0.6000322,
          3.7435982,
          -2.7329383,
          0.2728561,
          22.10328,
          0.19510941,
          4.3236294,
          0.6457522,
          6.1715393,
          0.48484257,
          -5.7583394,
          5.1685295,
          -2.8417907,
          -1.5186759,
          -6.196609,
          4.008232,
          -0.71775675,
          -0.6172532,
          5.950523,
          1.5789403,
          4.2476964,
          2.0214217,
          5.4192314,
          -2.8397996,
          1.879677,
          17.602737,
          -0.75604,
          4.655165,
          0.18533657,
          -3.8403175,
          -4.8946476,
          -5.20712,
          -2.6491501,
          2.4925363,
          7.731985,
          -0.8074568,
          -7.086195,
          3.3656197,
          4.8970647,
          -3.3170655,
          -6.5715036,
          -0.8403276,
          -2.2571857,
          6.26203,
          -1.3823676,
          1.5831536,
          5.1165943,
          -0.23092155,
          -2.3817518,
          -3.8752205,
          3.9284136,
          -0.69693327,
          4.735422,
          -0.40541962,
          -4.2694616,
          3.7100563,
          1.436409,
          -2.3787916,
          -2.6751945,
          2.9926066,
          2.0774589,
          -0.34366065,
          2.31028,
          3.2815537,
          4.431654,
          5.274912,
          1.4111061,
          -2.120272,
          4.3615537,
          -2.1255958,
          5.343218,
          3.8240068,
          -3.585549,
          3.034691,
          -3.8024871,
          -4.546583,
          -0.654185,
          -2.2070255,
          1.9575574,
          -11.894858,
          0.6104412,
          -16.49265,
          -1.2074884,
          -4.0661354,
          -1.2632017,
          -2.9293344,
          -1.1080525,
          -2.5352235,
          1.909753,
          -2.9960234,
          -0.18158321,
          2.8124564,
          1.6460747,
          2.958236,
          23.827068,
          2.8325093,
          23.581556,
          7.766245,
          3.415772,
          -0.28754416,
          4.313382,
          -5.8724895,
          6.0430117,
          18.106112,
          -3.1432142,
          8.194667,
          3.5685759,
          1.6919773,
          1.7899511,
          0.070981726,
          2.3450978,
          21.862705,
          39.023655,
          -2.6508505,
          -0.5064033,
          -2.6241884,
          -1.9137528,
          14.086345,
          -4.2278514,
          0.026057852,
          2.427028,
          -3.5737102,
          -7.3357487,
          -2.606093,
          10.707862,
          2.090546,
          -2.1439497,
          0.07220729,
          -2.046993,
          9.327391,
          8.449356,
          0.37028638,
          5.1905727,
          4.9424233,
          -15.450674,
          -3.5299494,
          -1.7170033,
          7.226431,
          -2.625038,
          0.13121192,
          -3.8676312,
          -0.5512264,
          -3.3028543,
          -6.3632956,
          -14.839371,
          -0.1874695,
          3.920483,
          -1.5403056,
          -2.0754154,
          -8.564036,
          7.4267263,
          -2.977235,
          -1.1866288,
          -4.6246862,
          10.603338,
          -0.8451864,
          -1.3073952,
          -3.8091352,
          -0.2298025,
          -3.7005768,
          2.0823674,
          -0.33997467,
          -0.6301616,
          0.40401027,
          7.7755938,
          -0.76104355,
          -8.257226,
          -2.3672493,
          3.7577686,
          1.5027026,
          3.978823,
          8.819535,
          2.383065,
          5.114584,
          2.624584,
          6.5266333,
          3.2214,
          -6.1440477,
          2.7759955,
          3.205783,
          -6.2958994,
          -4.4125423,
          -0.5283628,
          -5.156305,
          -0.11911015,
          0.63459057,
          -8.321902,
          2.7703574,
          4.2923784,
          0.52064943,
          0.72347546,
          8.025782,
          -2.7325182,
          -1.2130517,
          -1.657995,
          1.6581047,
          2.0957103,
          -4.7122364,
          -3.4409935,
          3.9680274,
          0.5409297,
          7.185007,
          -5.181473,
          -3.4789724,
          -3.327263,
          0.66063,
          -2.117671,
          9.0707,
          -2.0169284,
          4.090241,
          -4.2242985,
          1.8747847,
          2.0965283,
          2.300961,
          2.6637616,
          -5.0490303,
          5.955995,
          -3.2089531,
          -3.942092,
          -1.5132439,
          -1.8876575,
          0.6518815,
          -1.856852,
          7.364002,
          -1.5555451,
          -0.60835767,
          -3.6579835,
          3.642623,
          3.8312569,
          -4.492178,
          -1.8750226,
          -0.900964,
          -2.446586,
          -1.3891553,
          -0.8852023,
          -7.013343,
          -0.9617197,
          -2.2028205,
          -1.8255453,
          -4.4944544,
          -6.1475754,
          3.3028307,
          -1.2675604,
          -1.0788019,
          -2.1573215,
          3.959416,
          7.7698183,
          3.08516,
          3.1938074,
          -20.543905,
          -0.25007293,
          2.8391554,
          5.738409,
          -6.4184346,
          3.7278345,
          8.017873,
          1.0866935,
          -3.651384,
          0.23056515,
          4.2578063,
          -2.413147,
          -2.4451416,
          2.388734,
          -3.7842453,
          2.3525653,
          -4.992774,
          7.952898,
          2.1416278,
          -0.65810597,
          -0.60444957,
          2.0273468,
          -18.331636,
          4.1003027,
          3.619595,
          4.1774116,
          2.2519772,
          4.1999283,
          2.794538,
          -2.4788425,
          -0.39650306,
          2.924086,
          7.958761,
          -1.7972115,
          2.1269054,
          -3.6029854,
          -0.90729856,
          -1.1089107,
          2.5484278,
          -15.566163,
          -2.1715791,
          2.7282174,
          -2.5232618,
          1.2200307,
          2.9925504,
          -2.8825815,
          1.4724236,
          4.730091,
          -0.1533771,
          -11.027494,
          5.3481627,
          -2.4931269,
          6.173872,
          3.2766504,
          -9.220625,
          3.7395766,
          3.48546,
          -1.7654234,
          -1.714179,
          5.1352735,
          -2.875983,
          -3.1933653,
          -1.8412156,
          1.478934,
          2.458028,
          -2.4094284,
          -0.8306435,
          -3.9803407,
          1.3695097,
          -5.753133,
          -1.9045272,
          4.9687634,
          5.6828756,
          -2.9308865,
          -0.25744048,
          6.243164,
          3.3250926,
          -5.5319815,
          0.13794385,
          -2.2141287,
          -23.995884,
          -2.6830263,
          2.0321329,
          -7.736921,
          0.8413698,
          1.0690871,
          -2.7182434,
          2.488278,
          2.5697553,
          -26.183105,
          2.973028,
          -5.9871197,
          8.610618,
          -0.011500107,
          -1.0417093,
          -3.7238462,
          3.46566,
          3.0432718,
          -3.773998,
          5.851516,
          -0.7970916,
          0.19661216,
          2.6731513,
          -0.1689783,
          -5.4877486,
          32.928288,
          1.5418909,
          -0.38846776,
          -3.3420944,
          6.8204756,
          -5.3500843,
          -1.0286068,
          5.288404,
          0.03829713,
          3.2232358,
          -1.5386151,
          6.167943,
          1.3603076,
          3.5637472,
          1.2578888,
          4.429185,
          2.344368,
          1.5530977,
          -2.3828008,
          -4.695853,
          3.6648939,
          0.17487714,
          5.185425,
          -2.268021,
          2.837201,
          1.0271112,
          -2.026977,
          -0.47514707,
          4.5082884,
          -2.28983,
          -1.6866183,
          3.2718437,
          6.1834927,
          3.285457,
          5.078296,
          6.504154,
          4.545842,
          -6.42377,
          3.0289333,
          -2.255192,
          -0.03478308,
          3.785908,
          10.432132,
          -0.008047761,
          3.1676042,
          6.122088,
          -7.2442293,
          -1.3431089,
          -2.1772354,
          -1.8522819,
          6.9512944,
          5.9034023,
          -0.17970057,
          3.2004144,
          -8.036209,
          -2.3537576,
          38.380047,
          32.703396,
          -2.6455247,
          1.8563302,
          -1.7876401,
          4.365327,
          1.396625,
          -2.952311,
          8.87276,
          -2.1570911,
          -2.2416031,
          1.8111858,
          -9.15791,
          2.6287363,
          1.7131677,
          1.6833203,
          1.9101869,
          -0.23328905,
          4.877873,
          2.0394557,
          0.6684995,
          1.9054409,
          9.655141,
          3.1916301,
          2.3381493,
          -3.4289315,
          -1.9087193,
          2.2877672,
          3.4111044,
          -3.6238654,
          4.605646,
          1.1250532,
          -2.6401303,
          6.8026586,
          4.331146,
          4.719311,
          0.14293955,
          6.031382,
          -2.254836,
          -2.042065,
          -0.527489,
          -0.26075205,
          -7.662858,
          4.0821805,
          7.88371,
          -2.3481486,
          7.5430975,
          -1.5935113,
          1.9888813,
          2.5605595,
          0.9711515,
          -1.7032304,
          -0.43673986,
          2.7954445,
          -1.5103279,
          1.540563,
          -5.3395586,
          -3.8679278,
          0.1888314,
          2.7244062,
          1.7685416,
          1.2071836,
          -0.7149817,
          4.384932,
          0.21228145,
          -8.488022,
          4.5764637,
          2.220066,
          3.5251963,
          -4.8721285,
          3.548745,
          4.637521,
          1.9086751,
          -2.2599409,
          3.7327466,
          2.6435223,
          -2.9350007,
          -0.9697449,
          -2.0430753,
          5.294683,
          -0.69923866,
          3.0128212,
          3.979884,
          -6.604195,
          0.95390403,
          1.9624327,
          3.8507407,
          22.245811,
          2.9396293,
          -4.820737,
          -7.8935285,
          3.2453156,
          -4.204949,
          -1.064516,
          -4.893277,
          2.4992197,
          -12.512763,
          -2.6536803,
          -0.81629246
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "color"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "embeddings = pd.DataFrame(embeddings, columns=['x', 'y', 'z'])\n",
    "fig = px.scatter_3d(embeddings, x='x', y='y', z='z', color=y_train)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": [
          4.287951,
          -1.1600686,
          9.499558,
          -3.0714738,
          -0.040431067,
          25.986683,
          -0.5051758,
          -0.970113,
          -9.080223,
          -6.7368407,
          -1.9323648,
          6.7574296,
          4.0461593,
          2.5734737,
          1.811037,
          -5.738848,
          2.6231964,
          2.2008502,
          2.8231783,
          16.65605,
          -0.7836806,
          3.6567478,
          -4.56033,
          -9.790928,
          -2.781248,
          -0.3884526,
          1.4269961,
          -4.430948,
          2.1530244,
          -1.6390067,
          -2.983824,
          -5.089475,
          10.835842,
          -0.70170254,
          1.0953032,
          9.637753,
          21.313337,
          1.7863714,
          13.5014515,
          -8.2721195,
          -0.39492768,
          1.0829349,
          0.8194753,
          7.256929,
          6.4139094,
          -13.559926,
          11.205189,
          -7.7344527,
          -5.9898663,
          4.1775885,
          2.210305,
          7.079375,
          8.710136,
          1.7466111,
          5.012854,
          0.009911403,
          -6.7737556,
          11.069716,
          1.2487763,
          -19.762867,
          -6.156942,
          -10.135038,
          1.8795046,
          -13.926403,
          8.962745,
          -2.6670573,
          -0.5014428,
          3.3395526,
          7.3676925,
          2.8383334,
          2.0280967,
          1.2633772,
          -3.7752597,
          -0.5649422,
          0.48629838,
          10.160423,
          0.227901,
          10.0525255,
          -2.966312,
          -11.272773,
          6.5697026,
          6.11655,
          34.604523,
          -1.090459,
          -4.184874,
          62.336597,
          -13.644093,
          -0.025694981,
          6.602314,
          -2.4894462,
          -0.62946445,
          -0.29991692,
          35.092094,
          -4.824313,
          1.7144998,
          0.60006,
          -7.760697,
          4.9036446,
          -3.6374054,
          9.065475,
          -4.7103314,
          -5.4178476,
          -6.4928517,
          16.403921,
          -5.8703732,
          -3.8688467,
          22.211775,
          5.2417173,
          1.1194818,
          -0.8887885,
          -1.6494683,
          -0.06008102,
          0.5700723,
          8.202382,
          3.0634615,
          -1.2434603,
          0.24270557,
          -8.02551,
          0.6797344,
          -3.020787,
          -3.395631,
          -2.1136725,
          -1.7044551,
          7.870501,
          -1.1701764,
          1.9535285,
          1.2109736,
          1.5496687,
          1.967507,
          0.8745026,
          11.686407,
          -12.132079,
          -0.28002822,
          -0.11150958,
          4.446239,
          -2.3309681,
          -1.3613364,
          -3.9050095,
          2.1862173,
          -7.9807105,
          0.74993384,
          1.4168761,
          0.68956274,
          8.960934,
          -2.8475661,
          -7.265506,
          10.166834,
          0.543049,
          -0.9365917,
          -14.101915,
          -8.042865,
          -11.136732,
          -3.5213559,
          -7.993919,
          5.947248,
          11.018503,
          2.5357342,
          -9.952319,
          -4.454435,
          -0.8249338,
          -0.7189538,
          0.5229515,
          -2.0471046,
          -0.5650905,
          -7.676782,
          -8.762058,
          12.317819,
          -8.224521,
          14.040651,
          0.6929742,
          -2.3498762,
          8.468392,
          5.5541053,
          -9.18898,
          0.9512127,
          4.729024,
          -1.7818813,
          0.33521768,
          3.3778472,
          -10.32919,
          5.9959245,
          -3.141936,
          -0.8201634,
          1.8029459,
          -5.454307,
          -7.6049786,
          1.0534257,
          -0.7166883,
          -1.6709436,
          -0.567743,
          -6.087382,
          5.799518,
          -5.024582,
          0.3907076,
          29.883768,
          -9.440027,
          -7.6316056,
          -0.8728251,
          -5.5784135,
          -6.307813,
          -5.951343,
          15.188078,
          -2.898413
         ],
         "y": [
          0.42407632,
          -4.145906,
          -8.282606,
          5.4960103,
          0.9378034,
          -33.960785,
          -1.9030627,
          3.0193245,
          0.09962245,
          -1.2851409,
          -1.9518436,
          5.334235,
          2.9908178,
          -2.1441896,
          -3.556778,
          -7.0739155,
          -2.624432,
          -1.9083774,
          -0.8470958,
          0.693386,
          1.7929434,
          1.0850079,
          1.8558549,
          0.7377163,
          6.083319,
          -2.9357886,
          5.932984,
          4.2046337,
          -2.1553457,
          -4.4758315,
          -1.2267574,
          -2.2543437,
          -3.066095,
          3.248798,
          -2.6003704,
          -6.1514683,
          4.8371,
          2.5565464,
          1.4951288,
          0.26216498,
          0.17866626,
          -1.7807535,
          -0.6146004,
          3.5394046,
          -1.406757,
          -0.5860484,
          -10.553914,
          0.8512955,
          -3.9920347,
          5.9560585,
          -6.4895177,
          -1.1038424,
          1.7410697,
          -3.2746665,
          -3.6247685,
          -3.494973,
          -3.7654393,
          -8.376374,
          8.985702,
          2.6799068,
          6.550525,
          -0.8123383,
          -1.7588799,
          -3.2262466,
          0.7012729,
          3.1424606,
          4.7694006,
          -2.0896983,
          -0.73107094,
          15.457217,
          0.89357877,
          3.684098,
          4.7380514,
          -0.38891557,
          -1.577788,
          -10.257382,
          -4.397895,
          1.0039781,
          -1.1307019,
          0.64685804,
          1.773172,
          1.3153251,
          39.28995,
          -3.4901574,
          2.6378348,
          61.35402,
          0.39886442,
          0.33825493,
          0.33106828,
          -0.3497248,
          -0.2450186,
          3.2711418,
          -4.9082046,
          2.2610676,
          -0.91307867,
          -3.74378,
          3.619136,
          5.36914,
          3.992106,
          6.1485333,
          0.5778286,
          -0.3324999,
          0.4500288,
          2.0342596,
          1.4211698,
          4.5471153,
          -21.37951,
          4.1843634,
          -1.3055717,
          2.8841517,
          0.48286277,
          2.510632,
          4.906831,
          2.7435827,
          -0.18458542,
          9.258397,
          -2.9973323,
          -1.761072,
          1.4177893,
          5.5679173,
          1.0243387,
          -5.648823,
          -3.6588569,
          -2.4046235,
          -1.269667,
          -4.021096,
          4.0216074,
          0.80118084,
          -1.0191553,
          -1.817897,
          -10.478686,
          -3.9904525,
          8.147834,
          -0.54252124,
          5.745284,
          1.1600648,
          4.0844893,
          -0.8690896,
          -0.33579755,
          2.7077358,
          4.275078,
          -1.9920644,
          0.6970135,
          22.035162,
          4.8389926,
          2.0363405,
          -11.618899,
          -1.6234894,
          0.3383001,
          -3.1980736,
          -1.227246,
          3.326125,
          3.8556097,
          -2.2482524,
          4.711919,
          -4.03458,
          -0.41430414,
          0.17684111,
          1.390079,
          -2.2389839,
          -1.0604081,
          -1.5480967,
          6.595637,
          4.291688,
          -1.5942641,
          2.4897585,
          1.150694,
          5.099536,
          -11.242881,
          0.85914004,
          4.063131,
          -0.28622892,
          -4.0083055,
          4.722902,
          -2.9972045,
          -1.473536,
          0.93098783,
          -4.255019,
          2.9491186,
          1.8583822,
          0.63800716,
          1.1929651,
          0.4081341,
          -1.4903069,
          -3.0055616,
          -0.43171766,
          -2.7693691,
          -1.8156496,
          0.3939225,
          4.9853187,
          -0.9597579,
          -0.7549077,
          -0.72989154,
          -1.8600405,
          13.01382,
          1.0108011,
          -0.25268623,
          -0.54412365,
          1.1014837,
          -0.40144864,
          6.002897,
          2.698692,
          4.3259397
         ],
         "z": [
          1.3517463,
          -4.1904364,
          3.9704273,
          -3.280426,
          4.173187,
          -4.706303,
          -0.39135328,
          -2.7432597,
          -0.08882595,
          -6.09277,
          -3.2372377,
          3.7188513,
          6.141312,
          0.42092034,
          1.4145948,
          0.14376758,
          -2.601619,
          -0.13961972,
          1.8385465,
          7.567857,
          0.13729213,
          2.942814,
          -7.653734,
          2.2811687,
          -3.2111778,
          2.9291728,
          -2.3622816,
          -4.764583,
          -0.9278133,
          -4.029228,
          -5.2199535,
          0.8288874,
          1.4342078,
          -1.8203961,
          1.698211,
          -6.606228,
          -14.647229,
          2.6827924,
          7.7304153,
          4.338992,
          -0.5463548,
          -0.6486963,
          -0.79853547,
          6.9407372,
          1.3486692,
          -4.0179467,
          1.9960887,
          -13.062102,
          0.45110986,
          4.938516,
          -6.0656195,
          1.1979661,
          6.1824074,
          -3.4012015,
          -0.70409864,
          7.3082595,
          -0.83627874,
          5.0566354,
          -3.3333411,
          2.1961362,
          -2.5649822,
          3.6542776,
          -0.6000322,
          3.7435982,
          0.6457522,
          -5.7583394,
          -2.8417907,
          -1.5186759,
          1.879677,
          7.731985,
          4.8970647,
          -1.3823676,
          -4.2694616,
          2.9926066,
          2.0774589,
          2.31028,
          1.4111061,
          5.343218,
          -4.0661354,
          1.6460747,
          2.958236,
          3.415772,
          39.023655,
          -2.6508505,
          -7.3357487,
          -15.450674,
          7.226431,
          -0.5512264,
          -0.1874695,
          10.603338,
          -0.8451864,
          -3.7005768,
          0.40401027,
          -2.3672493,
          1.5027026,
          3.2214,
          -8.321902,
          8.025782,
          -4.7122364,
          0.5409297,
          -2.117671,
          -4.2242985,
          -5.0490303,
          5.955995,
          -3.2089531,
          -3.942092,
          7.364002,
          3.642623,
          -2.446586,
          -2.2028205,
          -1.8255453,
          3.3028307,
          -1.2675604,
          3.08516,
          3.1938074,
          -20.543905,
          2.8391554,
          -6.4184346,
          1.0866935,
          -3.651384,
          2.388734,
          -4.992774,
          7.952898,
          2.1416278,
          -0.65810597,
          2.0273468,
          -18.331636,
          4.1003027,
          4.1774116,
          2.2519772,
          2.794538,
          2.5484278,
          -15.566163,
          1.4724236,
          5.3481627,
          -1.714179,
          -2.875983,
          1.478934,
          2.458028,
          -0.8306435,
          -1.9045272,
          3.3250926,
          0.13794385,
          -23.995884,
          -2.6830263,
          0.8413698,
          1.0690871,
          2.973028,
          -0.011500107,
          3.0432718,
          -0.7970916,
          2.6731513,
          -5.4877486,
          3.2232358,
          6.167943,
          1.3603076,
          3.5637472,
          2.344368,
          1.5530977,
          3.6648939,
          -2.268021,
          2.837201,
          -2.28983,
          -1.6866183,
          -6.42377,
          -0.03478308,
          6.122088,
          -7.2442293,
          6.9512944,
          3.2004144,
          -1.7876401,
          1.396625,
          -2.952311,
          -9.15791,
          2.6287363,
          1.9101869,
          -0.23328905,
          0.6684995,
          3.1916301,
          2.2877672,
          1.1250532,
          -2.6401303,
          -0.527489,
          -0.26075205,
          -7.662858,
          4.0821805,
          1.9888813,
          2.5605595,
          -1.5103279,
          -3.8679278,
          2.7244062,
          1.7685416,
          1.2071836,
          4.384932,
          -8.488022,
          -2.2599409,
          3.7327466,
          -0.9697449,
          0.95390403,
          -4.204949,
          -4.893277,
          -12.512763,
          -2.6536803
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "embeddings_true = pd.DataFrame(embeddings[y_train.reset_index(drop=True)==1], columns=['x', 'y', 'z'])\n",
    "fig = px.scatter_3d(embeddings_true, x='x', y='y', z='z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": [
          -1.4952854,
          -3.2481709,
          0.87749285,
          0.7549774,
          -2.6163917,
          -2.6952825,
          -0.36918807,
          -7.265085,
          0.5408441,
          1.8831073,
          -1.9575778,
          -0.40476048,
          0.33270442,
          -2.2652025,
          -17.833694,
          -0.9189444,
          0.69634455,
          -0.6948983,
          -0.53021175,
          -2.7520485,
          4.602511,
          1.4092907,
          3.1483238,
          -4.8941603,
          21.000446,
          -0.65192306,
          -2.3982432,
          0.31457043,
          -0.3558455,
          19.876701,
          0.4331792,
          -0.14528514,
          -2.491812,
          30.9831,
          -5.4524956,
          -14.77405,
          -4.3878026,
          -1.5540409,
          0.6325548,
          1.1276635,
          3.8768308,
          -5.7499547,
          -7.1672597,
          0.9721976,
          0.7633139,
          -1.7843903,
          -12.341051,
          -14.826872,
          -1.2393985,
          -0.5901276,
          -0.34978598,
          5.850782,
          -3.0865142,
          -12.070817,
          -2.833855,
          0.8648567,
          2.7895036,
          -2.301537,
          5.8502903,
          -6.99537,
          -0.97639924,
          -2.3329608,
          4.8880305,
          -11.897135,
          10.684074,
          -3.5805094,
          3.8433225,
          -0.62022096,
          -0.30511945,
          -0.33269125,
          -8.341213,
          -0.56553686,
          -1.5330069,
          -2.0714233,
          9.984911,
          -5.4185987,
          11.126329,
          1.0345435,
          -2.3102913,
          1.2988795,
          -2.8799675,
          -7.1016626,
          -5.6590543,
          0.27555168,
          -1.252178,
          -2.8300574,
          4.391653,
          -6.133842,
          -8.327718,
          -0.38218743,
          -11.907013,
          0.072448894,
          -2.2447615,
          0.83725196,
          -3.0046096,
          10.096773,
          -2.1017015,
          -2.1056664,
          -9.012543,
          -0.5795164,
          1.7427853,
          9.161869,
          1.6673399,
          2.1169531,
          -7.3146696,
          -0.14643718,
          -5.3582606,
          0.65340334,
          -3.0865672,
          -0.12145053,
          2.3177912,
          0.40353775,
          0.5742815,
          -1.4266859,
          0.60808283,
          -4.1317387,
          15.125644,
          -1.6943684,
          -4.4973755,
          0.0355068,
          -1.94179,
          4.466417,
          3.2162523,
          -6.2260885,
          -0.63408715,
          0.65573305,
          0.38955653,
          1.6949968,
          29.154024,
          -7.3098946,
          10.272687,
          -13.705675,
          -1.3295584,
          1.2527705,
          10.410362,
          10.593718,
          1.6360003,
          -4.6697693,
          -1.3359771,
          0.85523546,
          5.2810493,
          3.3293474,
          -1.1107866,
          -1.9895233,
          -8.495467,
          -1.1439722,
          -7.247497,
          -1.8903122,
          -2.061108,
          10.020908,
          -1.9948925,
          -22.409843,
          -2.7838643,
          -5.299454,
          -2.4564362,
          -9.3158,
          -5.5079865,
          0.91982603,
          -0.27688533,
          -0.6014184,
          -1.1331402,
          -0.28631568,
          -1.721635,
          -4.0843782,
          2.5225723,
          0.40089792,
          -1.0678449,
          0.26509327,
          -6.162402,
          6.0142484,
          -0.5166182,
          -3.8878772,
          12.441004,
          0.79187745,
          1.287362,
          -9.273627,
          -3.218527,
          -2.9944036,
          12.580105,
          -2.158083,
          0.92010754,
          2.5582535,
          -8.450991,
          -2.616626,
          5.3383102,
          -0.7527381,
          -10.465766,
          -3.9061134,
          -11.405582,
          -0.33538073,
          -0.51895106,
          2.5939748,
          -21.362972,
          3.8922746,
          -7.6801744,
          -3.430998,
          0.014953211,
          4.476423,
          -8.749844,
          1.4848903,
          2.5650008,
          -0.021710917,
          7.9625115,
          1.8006166,
          -10.797541,
          -0.2286561,
          -0.66672736,
          -8.309927,
          0.33914477,
          0.21198456,
          2.1799033,
          -19.549414,
          -10.602409,
          21.951542,
          -0.085837856,
          1.7025386,
          2.7231772,
          -2.0285099,
          -5.6852603,
          13.67647,
          0.93411833,
          -1.3841265,
          -5.5330577,
          1.2318314,
          3.6755364,
          -0.85331875,
          -4.8971243,
          -0.8668486,
          0.8736246,
          0.24810015,
          21.23015,
          4.039039,
          -2.0351758,
          -5.184981,
          1.0791371,
          -1.2106081,
          0.47050816,
          -0.009020731,
          3.4971101,
          -1.6175063,
          -0.9691729,
          -17.388676,
          4.186026,
          0.5894502,
          6.760818,
          1.553232,
          -25.602585,
          4.447697,
          -0.93769544,
          -1.1091958,
          0.5560865,
          -11.530861,
          -0.8953046,
          0.38851047,
          -0.69158727,
          -0.4097525,
          1.0630962,
          -2.5131524,
          -3.4335763,
          -12.342367,
          -2.2593327,
          5.1524997,
          48.245296,
          -5.3611426,
          15.631135,
          5.640584,
          3.955383,
          6.7156405,
          -22.823814,
          -12.559507,
          2.4611752,
          2.406967,
          4.730612,
          -1.4078583,
          5.6409783,
          -5.659865,
          -6.7428956,
          -0.58635134,
          5.904735,
          -4.62089,
          1.0107973,
          1.8856273,
          0.19332214,
          -7.858461,
          -3.2165618,
          -0.37364823,
          -2.9106605,
          -1.7648844,
          1.4723417,
          2.3790507,
          2.844657,
          -2.241387,
          2.9017155,
          -0.2674178,
          -7.040664,
          0.4820966,
          5.798314,
          -12.28507,
          -0.107910484,
          -1.2965971,
          2.9164803,
          1.75918,
          7.2495356,
          -0.83054644,
          -3.2191122,
          -7.2113395,
          -9.403097,
          6.0234623,
          1.2947317,
          -9.654907,
          10.44793,
          0.035533622,
          -0.6550719,
          -3.0785959,
          -3.73375,
          0.49048388,
          0.98899347,
          22.12949,
          -6.6506257,
          0.80224586,
          1.6406779,
          4.6053643,
          -4.0082135,
          -0.54673654,
          -1.0591817,
          9.747942,
          -3.142456,
          -0.66916794,
          2.4789252,
          -0.10747896,
          -0.02518095,
          0.08030833,
          5.434084,
          9.44475,
          0.23373935,
          1.1078053,
          -1.7858326,
          -1.6297894,
          2.9341867,
          0.4100474,
          2.1699264,
          0.34927893,
          -1.424313,
          5.903383,
          6.4592433,
          -2.7878757,
          -5.2422595,
          22.479334,
          1.4126782,
          -0.11608049,
          1.9200908,
          0.3335002,
          1.06072,
          1.2896713,
          -0.2814327,
          1.6774415,
          1.4823,
          -0.48468083,
          -0.67259485,
          -7.8149323,
          -4.767854,
          -0.62961704,
          -1.9848286,
          -3.0788145,
          3.3100278,
          2.7967374,
          2.1374183,
          5.012428,
          -0.025880322,
          -3.7599277,
          -3.8636894,
          0.5395814,
          1.1115203,
          -14.421114,
          4.70924,
          6.4892607,
          1.4924487,
          -0.8316453,
          0.50382215,
          -4.642813,
          -10.427842,
          -2.9967785,
          -4.9312167,
          3.0683508,
          1.871108,
          10.79756,
          0.22540261,
          -8.697765,
          -0.002499625,
          -9.1422,
          -3.7868907,
          -1.5379562,
          -1.6642178,
          0.7550277,
          -0.1153215,
          34.92739,
          1.0205204,
          -3.049701,
          9.364666,
          14.391327,
          2.968485,
          -13.508599,
          -0.27627927,
          -3.2354012,
          -1.1233344,
          3.8480866,
          -1.7590095,
          9.38954,
          9.330807,
          -5.574889,
          0.698853,
          10.5189,
          -1.7178445,
          11.068323,
          0.8076803,
          -4.345371,
          -2.5868723,
          -3.7428207,
          13.81249,
          -3.853246,
          -8.383884,
          12.430834,
          1.654138,
          -0.49093652,
          4.545476,
          -7.645304,
          12.014021,
          3.9459417,
          10.876339,
          1.717693,
          9.587887,
          2.1684237,
          24.38068,
          7.5771136,
          0.026861742,
          -1.4921818,
          2.5939023,
          -10.384701,
          -1.9974922,
          11.951048,
          6.4636326,
          -0.22316973,
          3.712086,
          23.090256,
          -5.795087,
          0.22183631,
          -10.921816,
          2.77444,
          1.7141403,
          9.242275,
          1.3825907,
          1.4696163,
          0.9145346,
          0.86284786,
          -3.3490431,
          -6.2164493,
          -0.9318933,
          2.48614,
          0.15095551,
          0.50705975,
          -1.4838014,
          2.576074,
          -1.7399092,
          14.816354,
          1.5521657,
          2.2400289,
          -2.0880911,
          -1.7705666,
          0.40838933,
          0.008571163,
          -7.5210776,
          -4.4751387,
          -1.1850737,
          -6.072672,
          -0.505891,
          -1.9463168,
          2.4837081,
          0.6743786,
          -0.2599572,
          -4.55166,
          -5.281548,
          4.030382,
          -8.387568,
          -0.12111996,
          0.74272954,
          2.620048,
          22.920803,
          -2.2797291,
          -1.8626406,
          2.0182786,
          0.7200596,
          0.50593406,
          -11.777356,
          -0.366131,
          -8.112635,
          -2.1551414,
          -0.5623225,
          -1.2223307,
          0.2600189,
          -1.3371931,
          -3.3092544,
          1.2203399,
          -1.5101506,
          6.019066,
          10.556398,
          0.16289963,
          5.624355,
          8.593989,
          -0.27902752,
          0.010250881,
          -3.9058404,
          -4.26625,
          -0.5237649,
          3.5567172,
          -0.96113116,
          -0.082465276,
          -3.84353,
          9.492264,
          4.222271,
          -1.1139439,
          -4.450726,
          -18.637318,
          -11.984419,
          -0.016498797,
          3.010886,
          -2.4936826,
          0.20376518,
          -1.5429815,
          -0.9217023,
          0.14578941,
          -0.44679034,
          -8.902793,
          0.11416331,
          1.4065112,
          -10.675396,
          0.18206963,
          -7.395389,
          0.32282096,
          -1.3542267,
          1.9304743,
          0.34180355,
          -7.2443194,
          -1.2082248,
          0.5554348,
          -8.591024,
          0.39325225,
          0.089414254
         ],
         "y": [
          -3.197262,
          5.980605,
          -2.0643039,
          4.3745914,
          -4.891763,
          0.89211935,
          2.8873658,
          -0.70969,
          -1.7806512,
          -2.8682284,
          0.46271586,
          1.4792473,
          0.68305445,
          4.374953,
          -7.1871624,
          7.732297,
          4.3706107,
          -4.8603086,
          -0.68045163,
          1.8086098,
          6.053113,
          -2.1783636,
          -1.5493977,
          -2.759596,
          -12.002571,
          -2.8574746,
          -4.2682557,
          5.8957434,
          -3.485932,
          -1.8090477,
          -1.6571094,
          -0.8037257,
          1.3595994,
          -11.296097,
          2.2035084,
          -2.9455462,
          3.4135983,
          0.14018273,
          -0.29058167,
          0.6074935,
          5.364346,
          -3.0680091,
          -0.4782211,
          -3.5510895,
          -1.079806,
          -0.807914,
          0.44477537,
          1.1310519,
          0.2140317,
          0.3745287,
          -3.7126458,
          -4.4664288,
          0.7747634,
          1.5149384,
          -7.955329,
          -1.8250891,
          -1.8603185,
          -0.94515234,
          3.1759884,
          6.996132,
          0.09552004,
          0.5053269,
          -1.61464,
          -2.887889,
          -6.753925,
          1.5299064,
          12.340443,
          -1.341653,
          -1.1904384,
          7.9260225,
          0.9160022,
          -0.7661911,
          0.49854764,
          -0.92471564,
          -11.081643,
          -1.3555251,
          -13.26047,
          -0.1362983,
          6.2539053,
          -1.9966644,
          0.62754005,
          -1.4551765,
          -1.4306023,
          -2.247462,
          0.001675535,
          -0.09159208,
          -3.8618205,
          -1.0496311,
          -4.2813807,
          -3.0517397,
          2.6959078,
          -1.8539165,
          4.552159,
          -0.76553136,
          -0.7818967,
          -7.7865505,
          0.8425099,
          -3.9473195,
          -9.811594,
          2.9583938,
          -0.49439713,
          -12.029014,
          -3.0837843,
          -0.76946175,
          -4.82127,
          -3.4508345,
          1.6217308,
          -1.2236801,
          -3.984769,
          2.6478357,
          0.2620605,
          1.7335901,
          -0.12472937,
          -1.0050203,
          7.5460944,
          5.0925264,
          5.0119762,
          2.0459151,
          -4.7471433,
          11.245354,
          -0.4436576,
          -3.438986,
          -3.6089113,
          -5.8429894,
          -3.3879397,
          -1.992539,
          -0.47768697,
          5.0275235,
          -20.856218,
          -3.5336804,
          -5.111514,
          -2.718259,
          3.2383177,
          -2.014587,
          -16.490261,
          -15.982751,
          -1.8472221,
          -1.2551669,
          -3.0074232,
          7.7466993,
          1.6137009,
          -3.4839127,
          -2.2174094,
          2.6078246,
          3.6711457,
          -3.2297127,
          -4.633578,
          -0.4309439,
          -4.510802,
          0.542628,
          -5.783544,
          -28.414719,
          1.0003475,
          0.9132212,
          3.7387674,
          -0.31899074,
          -0.08050833,
          -0.9253962,
          2.9891045,
          -1.9123021,
          2.3867643,
          3.879092,
          -3.244067,
          -1.2031358,
          -0.24463984,
          4.5255346,
          -1.1298194,
          4.4630895,
          -3.0731347,
          0.16653183,
          -0.026611052,
          -0.42044473,
          -9.7882185,
          3.9522302,
          0.115076,
          0.022398196,
          -1.0165018,
          -1.3021735,
          -11.235148,
          4.370974,
          -0.80996734,
          -10.790521,
          3.391587,
          -2.3193061,
          14.794758,
          1.6124662,
          -1.9671985,
          6.6869545,
          -1.1835488,
          0.039866082,
          -2.0834455,
          -4.2104797,
          0.89163315,
          4.2408676,
          0.21840426,
          -4.719619,
          4.9155145,
          8.628371,
          0.78385717,
          -0.7389543,
          -2.0850964,
          4.5389485,
          -5.3046713,
          12.121016,
          -0.4976708,
          -2.4194205,
          10.320081,
          6.0797524,
          -2.399031,
          3.160563,
          12.503005,
          -2.97608,
          0.40023455,
          -13.983857,
          -2.8817875,
          -0.20199737,
          -1.9561714,
          -1.4307895,
          5.2375717,
          -10.687718,
          0.0903089,
          -3.3249316,
          -2.3835304,
          -3.293347,
          -1.9626149,
          -3.395375,
          4.8875837,
          6.8878355,
          -1.2757888,
          -0.15113035,
          -16.184376,
          -2.9258993,
          -0.6383172,
          7.2386446,
          -3.3172338,
          3.4130805,
          -1.3668762,
          4.4393673,
          -0.4490845,
          0.9841393,
          6.188399,
          1.8834038,
          0.15673283,
          5.4121895,
          14.724302,
          -2.325329,
          -4.644156,
          -2.6396487,
          -1.0400952,
          -2.933298,
          2.0482962,
          1.1689962,
          -0.64735186,
          -0.8007959,
          -9.075891,
          -4.0792127,
          -25.35642,
          -6.1892643,
          3.1617556,
          -1.3514196,
          -2.3397615,
          3.8230321,
          12.733095,
          0.34032893,
          1.269969,
          0.5423525,
          -2.051855,
          -1.3032329,
          -3.597172,
          1.4610292,
          -23.807846,
          -1.2142824,
          -2.921066,
          3.639186,
          13.863263,
          -1.040915,
          -3.7962182,
          -2.9510093,
          -3.8464794,
          1.8617939,
          -5.459225,
          -3.1995318,
          6.412334,
          -0.0726072,
          0.41642258,
          -1.2940784,
          -4.4681244,
          0.9793349,
          0.6268188,
          -0.71799296,
          -3.3434532,
          0.28512084,
          -4.8258204,
          -0.7726761,
          6.514842,
          8.081794,
          -1.4671922,
          0.41474774,
          -3.0009875,
          -0.00081831217,
          -2.2180593,
          0.19386938,
          3.4491217,
          3.122881,
          1.9871875,
          5.1544714,
          0.8288313,
          -4.4072266,
          -1.054393,
          -1.1148124,
          -18.037437,
          6.5662327,
          -3.5633233,
          2.156968,
          1.4318888,
          0.18675253,
          -1.3979373,
          -13.31485,
          -2.8744013,
          -4.4088287,
          0.6805301,
          3.2255766,
          2.8379898,
          -4.250212,
          -0.86524725,
          -6.439333,
          4.660871,
          0.6011381,
          -5.604353,
          0.7485313,
          6.6177044,
          -2.9365785,
          -0.65417206,
          -5.1120586,
          0.8103219,
          3.7473633,
          5.2610893,
          3.794266,
          -0.6245141,
          -4.635991,
          -3.6323602,
          -0.7934177,
          0.16876364,
          -5.0093966,
          -3.6167526,
          -0.2848493,
          -1.3343172,
          -14.663819,
          4.98789,
          -1.59333,
          1.3922956,
          -2.514078,
          2.8591685,
          -4.0602627,
          -1.9778811,
          -3.6286662,
          -0.02099917,
          2.4810033,
          -0.33814386,
          0.4440874,
          5.4345818,
          -0.6458078,
          5.247336,
          4.379947,
          -1.6781026,
          -1.4050875,
          -2.5026643,
          1.633958,
          -1.1366233,
          5.386713,
          -3.6413016,
          5.8527374,
          -2.1140635,
          -2.528734,
          5.0852823,
          -2.1551695,
          -1.393359,
          -2.4197664,
          -0.7750245,
          -1.408053,
          -0.92586887,
          1.4969933,
          2.4214265,
          -0.33463934,
          1.8981719,
          0.20975643,
          1.6397785,
          1.0268145,
          5.0001593,
          2.0254412,
          -1.3069501,
          -0.7439538,
          0.6134935,
          -3.1626017,
          8.969219,
          -4.790396,
          -1.0075897,
          0.44054407,
          -8.535782,
          -19.674038,
          -2.0120184,
          -2.9404185,
          3.2862823,
          -1.8714638,
          0.15862918,
          -0.18201634,
          7.7481294,
          1.856742,
          -11.129059,
          1.9572383,
          -1.5560614,
          -7.5198784,
          7.5624666,
          -7.3976564,
          5.236001,
          1.5571991,
          0.83164895,
          -3.0690453,
          -11.2099495,
          4.931239,
          -2.0683353,
          -12.3612795,
          -2.1762478,
          0.33588168,
          -1.0292417,
          5.253296,
          -5.007408,
          -2.0555017,
          -7.3539066,
          -4.0786753,
          -8.031261,
          1.41039,
          8.82385,
          -1.406742,
          -1.4853413,
          -0.57656825,
          -2.6878555,
          -2.4242177,
          3.9375112,
          -7.8752117,
          -3.7686002,
          1.1989785,
          18.648966,
          -22.369387,
          -2.3628938,
          10.788285,
          4.5469317,
          14.884559,
          -1.7115133,
          -7.5854053,
          -0.59013534,
          -0.6055691,
          -0.3246257,
          -1.1327131,
          4.3790445,
          0.5436878,
          1.6531725,
          -0.48283753,
          5.1977596,
          4.5831833,
          5.2713246,
          8.264539,
          -3.5024226,
          -13.939171,
          -3.454841,
          0.12909451,
          -0.34253326,
          -1.4996084,
          -2.1761253,
          2.9488761,
          -2.028057,
          -9.377821,
          -1.1062485,
          -0.5199971,
          -2.1999123,
          0.22515678,
          -1.7810448,
          -0.30473042,
          0.32864332,
          2.470781,
          0.25444686,
          21.515442,
          -6.531862,
          6.573367,
          -1.1831094,
          -0.27387342,
          -13.30745,
          -0.43006802,
          4.1423707,
          1.5360541,
          -1.4321568,
          2.0172012,
          -3.8628652,
          -0.5188422,
          0.48253953,
          -5.3183727,
          -1.8462207,
          -1.6150929,
          3.9959366,
          1.4236532,
          0.45049843,
          -1.2254001,
          -5.3348174,
          3.630955,
          -6.842099,
          -1.0469158,
          14.109229,
          -10.99838,
          4.708267,
          -3.4903977,
          1.9046311,
          -4.7627673,
          6.225902,
          -1.6383418,
          -1.3309516,
          -1.7970587,
          -3.4540045,
          -12.071149,
          -3.040207,
          0.90797913,
          2.8794134,
          -1.0154035,
          -0.93929553,
          -3.0247571,
          6.4540224,
          1.3976694,
          0.39692888,
          -2.7515228,
          -1.4469122,
          -1.568168,
          3.3693933,
          -0.6598768,
          0.75446784,
          -1.2256719,
          2.5927362,
          -1.5947415,
          4.8466606,
          3.8590834,
          -4.0955544,
          -11.500471,
          -0.16887057,
          0.13091436,
          -0.101963855,
          -0.8217794,
          0.09055426,
          0.6538491,
          -1.4226025
         ],
         "z": [
          0.98070496,
          -1.8597491,
          3.0269854,
          -1.0134227,
          4.235422,
          -1.4648902,
          -2.109979,
          -13.469399,
          -0.5945576,
          -1.9208951,
          -1.8687888,
          1.4397805,
          4.1666884,
          -2.6630416,
          2.6377563,
          0.77931565,
          -2.1238685,
          11.480585,
          5.2214327,
          -1.5889568,
          5.853738,
          -2.542381,
          -2.674916,
          0.990836,
          7.71881,
          2.6190155,
          3.874687,
          -2.2064788,
          1.187213,
          1.4735526,
          -1.041862,
          3.5834916,
          -1.4706903,
          -7.1344047,
          -2.7691662,
          6.29806,
          -4.518017,
          4.2215643,
          -2.0109918,
          4.774262,
          -0.10872799,
          -0.512797,
          -5.081954,
          2.916843,
          4.4587784,
          -1.6587806,
          -3.236646,
          2.076163,
          -0.69354445,
          2.644679,
          2.161239,
          -3.7187123,
          -3.5172207,
          2.4457905,
          9.68793,
          -2.42559,
          -0.8535772,
          -2.461089,
          6.293563,
          -4.935028,
          8.37345,
          -2.6532557,
          -9.500579,
          5.279919,
          6.544297,
          -1.0960823,
          -2.3846526,
          2.2572334,
          3.4452517,
          -18.431293,
          2.6933603,
          2.9275384,
          -0.31581023,
          1.6647995,
          21.430471,
          1.2451856,
          4.2523527,
          1.3874477,
          -4.0486264,
          7.2417545,
          -2.8666368,
          4.0842867,
          0.29742262,
          4.5374093,
          -0.5079764,
          -1.6781254,
          -3.0082903,
          -5.471939,
          -1.25457,
          2.578773,
          2.9653149,
          5.1459827,
          -3.311434,
          2.0280151,
          -4.0476084,
          2.4352221,
          -1.9880924,
          3.724106,
          -14.882124,
          -1.9359686,
          -2.0154831,
          2.7467048,
          -2.4598389,
          1.0863098,
          0.14312528,
          -1.320828,
          0.9277681,
          2.4822962,
          -6.3226314,
          -2.367091,
          3.4848764,
          1.391927,
          4.9034944,
          0.33626702,
          -0.5076935,
          -3.508847,
          61.302387,
          -5.277333,
          7.385067,
          -0.80430305,
          -2.8923976,
          -1.8806729,
          -0.37392616,
          -2.8109343,
          1.9365298,
          2.0625484,
          -1.1216074,
          -2.3583503,
          -59.9073,
          -0.52659786,
          -8.389721,
          3.6686795,
          -3.0908985,
          -2.619235,
          -0.8358898,
          -0.54687846,
          -1.9402788,
          1.1336896,
          3.7542584,
          -0.8017771,
          6.0082197,
          -0.6332578,
          3.4649599,
          -0.13836065,
          -10.063203,
          3.5550992,
          -2.0878363,
          -2.0702317,
          4.2045345,
          7.396121,
          7.7553473,
          40.57994,
          -1.2764018,
          -3.8588984,
          -4.9027405,
          4.674963,
          -4.8523664,
          -2.0768123,
          -3.4649305,
          3.550197,
          -3.2401686,
          -1.6506677,
          -2.055148,
          1.6043833,
          2.9068627,
          -3.1255176,
          4.3395076,
          -1.3662528,
          0.26145062,
          1.6633335,
          -1.328967,
          -4.9512787,
          5.2179646,
          -1.928203,
          -0.3446411,
          5.068365,
          -4.543513,
          1.5465279,
          1.4465117,
          -2.7329383,
          0.2728561,
          22.10328,
          0.19510941,
          4.3236294,
          6.1715393,
          0.48484257,
          5.1685295,
          -6.196609,
          4.008232,
          -0.71775675,
          -0.6172532,
          5.950523,
          1.5789403,
          4.2476964,
          2.0214217,
          5.4192314,
          -2.8397996,
          17.602737,
          -0.75604,
          4.655165,
          0.18533657,
          -3.8403175,
          -4.8946476,
          -5.20712,
          -2.6491501,
          2.4925363,
          -0.8074568,
          -7.086195,
          3.3656197,
          -3.3170655,
          -6.5715036,
          -0.8403276,
          -2.2571857,
          6.26203,
          1.5831536,
          5.1165943,
          -0.23092155,
          -2.3817518,
          -3.8752205,
          3.9284136,
          -0.69693327,
          4.735422,
          -0.40541962,
          3.7100563,
          1.436409,
          -2.3787916,
          -2.6751945,
          -0.34366065,
          3.2815537,
          4.431654,
          5.274912,
          -2.120272,
          4.3615537,
          -2.1255958,
          3.8240068,
          -3.585549,
          3.034691,
          -3.8024871,
          -4.546583,
          -0.654185,
          -2.2070255,
          1.9575574,
          -11.894858,
          0.6104412,
          -16.49265,
          -1.2074884,
          -1.2632017,
          -2.9293344,
          -1.1080525,
          -2.5352235,
          1.909753,
          -2.9960234,
          -0.18158321,
          2.8124564,
          23.827068,
          2.8325093,
          23.581556,
          7.766245,
          -0.28754416,
          4.313382,
          -5.8724895,
          6.0430117,
          18.106112,
          -3.1432142,
          8.194667,
          3.5685759,
          1.6919773,
          1.7899511,
          0.070981726,
          2.3450978,
          21.862705,
          -0.5064033,
          -2.6241884,
          -1.9137528,
          14.086345,
          -4.2278514,
          0.026057852,
          2.427028,
          -3.5737102,
          -2.606093,
          10.707862,
          2.090546,
          -2.1439497,
          0.07220729,
          -2.046993,
          9.327391,
          8.449356,
          0.37028638,
          5.1905727,
          4.9424233,
          -3.5299494,
          -1.7170033,
          -2.625038,
          0.13121192,
          -3.8676312,
          -3.3028543,
          -6.3632956,
          -14.839371,
          3.920483,
          -1.5403056,
          -2.0754154,
          -8.564036,
          7.4267263,
          -2.977235,
          -1.1866288,
          -4.6246862,
          -1.3073952,
          -3.8091352,
          -0.2298025,
          2.0823674,
          -0.33997467,
          -0.6301616,
          7.7755938,
          -0.76104355,
          -8.257226,
          3.7577686,
          3.978823,
          8.819535,
          2.383065,
          5.114584,
          2.624584,
          6.5266333,
          -6.1440477,
          2.7759955,
          3.205783,
          -6.2958994,
          -4.4125423,
          -0.5283628,
          -5.156305,
          -0.11911015,
          0.63459057,
          2.7703574,
          4.2923784,
          0.52064943,
          0.72347546,
          -2.7325182,
          -1.2130517,
          -1.657995,
          1.6581047,
          2.0957103,
          -3.4409935,
          3.9680274,
          7.185007,
          -5.181473,
          -3.4789724,
          -3.327263,
          0.66063,
          9.0707,
          -2.0169284,
          4.090241,
          1.8747847,
          2.0965283,
          2.300961,
          2.6637616,
          -1.5132439,
          -1.8876575,
          0.6518815,
          -1.856852,
          -1.5555451,
          -0.60835767,
          -3.6579835,
          3.8312569,
          -4.492178,
          -1.8750226,
          -0.900964,
          -1.3891553,
          -0.8852023,
          -7.013343,
          -0.9617197,
          -4.4944544,
          -6.1475754,
          -1.0788019,
          -2.1573215,
          3.959416,
          7.7698183,
          -0.25007293,
          5.738409,
          3.7278345,
          8.017873,
          0.23056515,
          4.2578063,
          -2.413147,
          -2.4451416,
          -3.7842453,
          2.3525653,
          -0.60444957,
          3.619595,
          4.1999283,
          -2.4788425,
          -0.39650306,
          2.924086,
          7.958761,
          -1.7972115,
          2.1269054,
          -3.6029854,
          -0.90729856,
          -1.1089107,
          -2.1715791,
          2.7282174,
          -2.5232618,
          1.2200307,
          2.9925504,
          -2.8825815,
          4.730091,
          -0.1533771,
          -11.027494,
          -2.4931269,
          6.173872,
          3.2766504,
          -9.220625,
          3.7395766,
          3.48546,
          -1.7654234,
          5.1352735,
          -3.1933653,
          -1.8412156,
          -2.4094284,
          -3.9803407,
          1.3695097,
          -5.753133,
          4.9687634,
          5.6828756,
          -2.9308865,
          -0.25744048,
          6.243164,
          -5.5319815,
          -2.2141287,
          2.0321329,
          -7.736921,
          -2.7182434,
          2.488278,
          2.5697553,
          -26.183105,
          -5.9871197,
          8.610618,
          -1.0417093,
          -3.7238462,
          3.46566,
          -3.773998,
          5.851516,
          0.19661216,
          -0.1689783,
          32.928288,
          1.5418909,
          -0.38846776,
          -3.3420944,
          6.8204756,
          -5.3500843,
          -1.0286068,
          5.288404,
          0.03829713,
          -1.5386151,
          1.2578888,
          4.429185,
          -2.3828008,
          -4.695853,
          0.17487714,
          5.185425,
          1.0271112,
          -2.026977,
          -0.47514707,
          4.5082884,
          3.2718437,
          6.1834927,
          3.285457,
          5.078296,
          6.504154,
          4.545842,
          3.0289333,
          -2.255192,
          3.785908,
          10.432132,
          -0.008047761,
          3.1676042,
          -1.3431089,
          -2.1772354,
          -1.8522819,
          5.9034023,
          -0.17970057,
          -8.036209,
          -2.3537576,
          38.380047,
          32.703396,
          -2.6455247,
          1.8563302,
          4.365327,
          8.87276,
          -2.1570911,
          -2.2416031,
          1.8111858,
          1.7131677,
          1.6833203,
          4.877873,
          2.0394557,
          1.9054409,
          9.655141,
          2.3381493,
          -3.4289315,
          -1.9087193,
          3.4111044,
          -3.6238654,
          4.605646,
          6.8026586,
          4.331146,
          4.719311,
          0.14293955,
          6.031382,
          -2.254836,
          -2.042065,
          7.88371,
          -2.3481486,
          7.5430975,
          -1.5935113,
          0.9711515,
          -1.7032304,
          -0.43673986,
          2.7954445,
          1.540563,
          -5.3395586,
          0.1888314,
          -0.7149817,
          0.21228145,
          4.5764637,
          2.220066,
          3.5251963,
          -4.8721285,
          3.548745,
          4.637521,
          1.9086751,
          2.6435223,
          -2.9350007,
          -2.0430753,
          5.294683,
          -0.69923866,
          3.0128212,
          3.979884,
          -6.604195,
          1.9624327,
          3.8507407,
          22.245811,
          2.9396293,
          -4.820737,
          -7.8935285,
          3.2453156,
          -1.064516,
          2.4992197,
          -0.81629246
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "title": {
           "text": "z"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "embeddings_false = pd.DataFrame(embeddings[y_train.reset_index(drop=True)==0], columns=['x', 'y', 'z'])\n",
    "fig = px.scatter_3d(embeddings_false, x='x', y='y', z='z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions with t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot t-SNE output\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_tsne['tsne0'], X_tsne['tsne1'], c=y_train, cmap='coolwarm', alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE visualization of Encoded Data')\n",
    "plt.xlabel('t-SNE feature 1')\n",
    "plt.ylabel('t-SNE feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Use Case Test</b>\n",
    "\n",
    "We check whether the autoencoder will be usefull for our use case.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a86d59830b810a15b9f5839d803d2d4",
     "grade": true,
     "grade_id": "ex7",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5813001252774422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipe_steps=[('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler()), ('classifier', MLPClassifier(max_iter=250, early_stopping=True))]\n",
    "\n",
    "pipe = Pipeline(steps=pipe_steps)\n",
    "params = {\n",
    "    'classifier__hidden_layer_sizes': [(100,), (50, 50), (25, 25, 25)],\n",
    "    'classifier__activation': ['relu', 'tanh', 'logistic'],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "    'classifier__learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=3, scoring='roc_auc')\n",
    "grid.fit(embeddings, y_train)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "An autoencoder aims to reduce dimensionality while minimizing information loss.\n",
    "\n",
    "### Metrics\n",
    "An MSE of 0.64 suggests the encoding isn't perfect, indicating some loss of information.\n",
    "\n",
    "### Graphical Analysis\n",
    "Visualization reveals that the 'true' class is more compact, whereas the 'false' class tends to be more dispersed. This pattern is consistent across multiple runs, showing that the autoencoder captures class-specific distinctions effectively.\n",
    "\n",
    "### Test Use Case\n",
    "Applying an MLP Classifier to the encoded data yielded a slight drop in 'roc_auc' validation scores (unbalanced dataset) compared to the unencoded data. However, when the data is encoded into four dimensions, the scores improve, the dimensionality of the encoding might be too strong depending on the use case as it doesn't only get rid of noise but also usefull information.\n",
    "\n",
    "### Conclusion\n",
    "The MSE of 0.64, while indicating some information loss, does not significantly hinder the utility of the autoencoder for certain applications. The visualization supports that the encoding retains some class distinctions, proving beneficial for dimensionality reduction. The lower score without the encoding suggest a trade-off between reducing dimensions and maintaining enough information for effective model performance. Ultimately, the autoencoder reduces data complexity efficiently, but the optimal number of retained dimensions requires careful consideration to maximize practical utility for the specific use case.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session I.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
